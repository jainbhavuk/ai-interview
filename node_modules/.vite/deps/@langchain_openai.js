import {
  $ZodAny,
  $ZodArray,
  $ZodBase64,
  $ZodBase64URL,
  $ZodBigInt,
  $ZodBigIntFormat,
  $ZodBoolean,
  $ZodCIDRv4,
  $ZodCIDRv6,
  $ZodCUID,
  $ZodCUID2,
  $ZodCatch,
  $ZodCheck,
  $ZodCodec,
  $ZodCustom,
  $ZodCustomStringFormat,
  $ZodDate,
  $ZodDefault,
  $ZodDiscriminatedUnion,
  $ZodE164,
  $ZodEmail,
  $ZodEmoji,
  $ZodEncodeError,
  $ZodEnum,
  $ZodError,
  $ZodExactOptional,
  $ZodFile,
  $ZodFunction,
  $ZodGUID,
  $ZodIPv4,
  $ZodIPv6,
  $ZodISODate,
  $ZodISODateTime,
  $ZodISODuration,
  $ZodISOTime,
  $ZodIntersection,
  $ZodJWT,
  $ZodKSUID,
  $ZodLazy,
  $ZodLiteral,
  $ZodMAC,
  $ZodMap,
  $ZodNaN,
  $ZodNanoID,
  $ZodNever,
  $ZodNonOptional,
  $ZodNull,
  $ZodNullable,
  $ZodNumber,
  $ZodNumberFormat,
  $ZodObjectJIT,
  $ZodOptional,
  $ZodPipe,
  $ZodPrefault,
  $ZodPromise,
  $ZodReadonly,
  $ZodRecord,
  $ZodSet,
  $ZodString,
  $ZodStringFormat,
  $ZodSuccess,
  $ZodSymbol,
  $ZodTemplateLiteral,
  $ZodTransform,
  $ZodTuple,
  $ZodType,
  $ZodULID,
  $ZodURL,
  $ZodUUID,
  $ZodUndefined,
  $ZodUnion,
  $ZodUnknown,
  $ZodVoid,
  $ZodXID,
  $ZodXor,
  $brand,
  $constructor,
  $input,
  $output,
  AIMessage,
  AIMessageChunk,
  AsyncCaller,
  AsyncLocalStorageProviderSingleton,
  CallbackManager,
  ChatGenerationChunk,
  ChatMessage,
  ChatMessageChunk,
  ContextOverflowError,
  FunctionMessageChunk,
  GenerationChunk,
  HumanMessage,
  HumanMessageChunk,
  ModelAbortError,
  NEVER,
  RUN_KEY,
  Runnable,
  RunnableAssign,
  RunnableBinding,
  RunnableEach,
  RunnableLambda,
  RunnableMap,
  RunnableParallel,
  RunnablePick,
  RunnableRetry,
  RunnableSequence,
  RunnableToolLike,
  RunnableWithFallbacks,
  Serializable,
  SystemMessageChunk,
  TimePrecision,
  ToolInputParsingException,
  ToolMessage,
  ToolMessageChunk,
  ZodFirstPartyTypeKind,
  __exportAll,
  _any,
  _array,
  _base64,
  _base64url,
  _bigint,
  _boolean,
  _cidrv4,
  _cidrv6,
  _coerceToDict,
  _coerceToRunnable,
  _coercedBigint,
  _coercedBoolean,
  _coercedDate,
  _coercedNumber,
  _coercedString,
  _configHasToolCallId,
  _cuid,
  _cuid2,
  _custom,
  _date,
  _decode,
  _decodeAsync,
  _e164,
  _email,
  _emoji,
  _encode,
  _encodeAsync,
  _endsWith,
  _file,
  _float32,
  _float64,
  _gt,
  _gte,
  _guid,
  _includes,
  _int,
  _int32,
  _int64,
  _ipv4,
  _ipv6,
  _isToolCall,
  _isoDate,
  _isoDateTime,
  _isoDuration,
  _isoTime,
  _jwt,
  _ksuid,
  _length,
  _lowercase,
  _lt,
  _lte,
  _mac,
  _maxLength,
  _maxSize,
  _mime,
  _minLength,
  _minSize,
  _multipleOf,
  _nan,
  _nanoid,
  _negative,
  _never,
  _nonnegative,
  _nonpositive,
  _normalize,
  _null,
  _number,
  _overwrite,
  _parse,
  _parseAsync,
  _positive,
  _property,
  _refine,
  _regex,
  _safeDecode,
  _safeDecodeAsync,
  _safeEncode,
  _safeEncodeAsync,
  _safeParse,
  _safeParseAsync,
  _size,
  _slugify,
  _startsWith,
  _string,
  _stringFormat,
  _stringbool,
  _superRefine,
  _symbol,
  _toLowerCase,
  _toUpperCase,
  _trim,
  _uint32,
  _uint64,
  _ulid,
  _undefined,
  _unknown,
  _uppercase,
  _url,
  _uuid,
  _uuidv4,
  _uuidv6,
  _uuidv7,
  _void,
  _xid,
  addLangChainErrorFields,
  anyProcessor,
  applyPatch,
  arrayProcessor,
  bigintProcessor,
  booleanProcessor,
  callbackHandlerPrefersStreaming,
  catchProcessor,
  clone,
  coerceMessageLikeToMessage,
  compare,
  concat,
  config,
  consumeAsyncGenerator,
  convertToChunk,
  convertToOpenAIImageBlock,
  convertToProviderContentBlock,
  core_exports,
  createStandardJSONSchemaMethod,
  createToJSONSchemaMethod,
  customProcessor,
  dateProcessor,
  deepCompareStrict,
  defaultProcessor,
  describe,
  en_default,
  ensureConfig,
  enumProcessor,
  extendInteropZodObject,
  external_exports,
  fileProcessor,
  flattenError,
  formatError,
  functionProcessor,
  getAbortSignalError,
  getBufferString,
  getCallbackManagerForConfig,
  getEnv,
  getEnvironmentVariable,
  getInteropZodDefaultGetter,
  getInteropZodObjectShape,
  getSchemaDescription,
  globalRegistry,
  iife,
  interopParse,
  interopParseAsync,
  interopSafeParse,
  interopSafeParseAsync,
  interopZodObjectMakeFieldsOptional,
  interopZodObjectPartial,
  interopZodObjectPassthrough,
  interopZodObjectStrict,
  interopZodTransformInputSchema,
  intersectionProcessor,
  isAIMessage,
  isAIMessageChunk,
  isAsyncGenerator,
  isBase64ContentBlock,
  isBaseMessage,
  isBaseMessageChunk,
  isDataContentBlock,
  isDirectToolOutput,
  isInteropZodError,
  isInteropZodLiteral,
  isInteropZodObject,
  isInteropZodSchema,
  isShapelessZodSchema,
  isSimpleStringZodSchema,
  isURLContentBlock,
  isZodArrayV4,
  isZodLiteralV3,
  isZodLiteralV4,
  isZodNullableV4,
  isZodObjectV3,
  isZodObjectV4,
  isZodOptionalV4,
  isZodSchema,
  isZodSchemaV3,
  isZodSchemaV4,
  jsonStringifyReplacer,
  lazyProcessor,
  literalProcessor,
  locales_exports,
  mapProcessor,
  mapStoredMessageToChatMessage,
  mergeConfigs,
  meta,
  nanProcessor,
  neverProcessor,
  nonoptionalProcessor,
  nullProcessor,
  nullableProcessor,
  numberProcessor,
  objectProcessor,
  optionalProcessor,
  parse,
  parseBase64DataUrl,
  parseCallbackConfigArg,
  parseJsonMarkdown,
  parseMimeType,
  parsePartialJson,
  patchConfig,
  pickRunnableConfigKeys,
  pipeProcessor,
  prefaultProcessor,
  prettifyError,
  promiseProcessor,
  raceWithSignal,
  readonlyProcessor,
  recordProcessor,
  regexes_exports,
  registry,
  setProcessor,
  stringProcessor,
  successProcessor,
  symbolProcessor,
  templateLiteralProcessor,
  toJSONSchema,
  toJsonSchema,
  transformProcessor,
  treeifyError,
  tupleProcessor,
  undefinedProcessor,
  unionProcessor,
  unknownProcessor,
  util_exports,
  validate,
  validatesOnlyStrings,
  voidProcessor
} from "./chunk-P3WRLCCB.js";
import {
  __commonJS,
  __export,
  __toESM
} from "./chunk-G3PMV62Z.js";

// node_modules/.pnpm/base64-js@1.5.1/node_modules/base64-js/index.js
var require_base64_js = __commonJS({
  "node_modules/.pnpm/base64-js@1.5.1/node_modules/base64-js/index.js"(exports) {
    "use strict";
    exports.byteLength = byteLength;
    exports.toByteArray = toByteArray;
    exports.fromByteArray = fromByteArray;
    var lookup = [];
    var revLookup = [];
    var Arr = typeof Uint8Array !== "undefined" ? Uint8Array : Array;
    var code = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    for (i = 0, len = code.length; i < len; ++i) {
      lookup[i] = code[i];
      revLookup[code.charCodeAt(i)] = i;
    }
    var i;
    var len;
    revLookup["-".charCodeAt(0)] = 62;
    revLookup["_".charCodeAt(0)] = 63;
    function getLens(b64) {
      var len2 = b64.length;
      if (len2 % 4 > 0) {
        throw new Error("Invalid string. Length must be a multiple of 4");
      }
      var validLen = b64.indexOf("=");
      if (validLen === -1) validLen = len2;
      var placeHoldersLen = validLen === len2 ? 0 : 4 - validLen % 4;
      return [validLen, placeHoldersLen];
    }
    function byteLength(b64) {
      var lens = getLens(b64);
      var validLen = lens[0];
      var placeHoldersLen = lens[1];
      return (validLen + placeHoldersLen) * 3 / 4 - placeHoldersLen;
    }
    function _byteLength(b64, validLen, placeHoldersLen) {
      return (validLen + placeHoldersLen) * 3 / 4 - placeHoldersLen;
    }
    function toByteArray(b64) {
      var tmp;
      var lens = getLens(b64);
      var validLen = lens[0];
      var placeHoldersLen = lens[1];
      var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen));
      var curByte = 0;
      var len2 = placeHoldersLen > 0 ? validLen - 4 : validLen;
      var i2;
      for (i2 = 0; i2 < len2; i2 += 4) {
        tmp = revLookup[b64.charCodeAt(i2)] << 18 | revLookup[b64.charCodeAt(i2 + 1)] << 12 | revLookup[b64.charCodeAt(i2 + 2)] << 6 | revLookup[b64.charCodeAt(i2 + 3)];
        arr[curByte++] = tmp >> 16 & 255;
        arr[curByte++] = tmp >> 8 & 255;
        arr[curByte++] = tmp & 255;
      }
      if (placeHoldersLen === 2) {
        tmp = revLookup[b64.charCodeAt(i2)] << 2 | revLookup[b64.charCodeAt(i2 + 1)] >> 4;
        arr[curByte++] = tmp & 255;
      }
      if (placeHoldersLen === 1) {
        tmp = revLookup[b64.charCodeAt(i2)] << 10 | revLookup[b64.charCodeAt(i2 + 1)] << 4 | revLookup[b64.charCodeAt(i2 + 2)] >> 2;
        arr[curByte++] = tmp >> 8 & 255;
        arr[curByte++] = tmp & 255;
      }
      return arr;
    }
    function tripletToBase64(num) {
      return lookup[num >> 18 & 63] + lookup[num >> 12 & 63] + lookup[num >> 6 & 63] + lookup[num & 63];
    }
    function encodeChunk(uint8, start, end) {
      var tmp;
      var output = [];
      for (var i2 = start; i2 < end; i2 += 3) {
        tmp = (uint8[i2] << 16 & 16711680) + (uint8[i2 + 1] << 8 & 65280) + (uint8[i2 + 2] & 255);
        output.push(tripletToBase64(tmp));
      }
      return output.join("");
    }
    function fromByteArray(uint8) {
      var tmp;
      var len2 = uint8.length;
      var extraBytes = len2 % 3;
      var parts = [];
      var maxChunkLength = 16383;
      for (var i2 = 0, len22 = len2 - extraBytes; i2 < len22; i2 += maxChunkLength) {
        parts.push(encodeChunk(uint8, i2, i2 + maxChunkLength > len22 ? len22 : i2 + maxChunkLength));
      }
      if (extraBytes === 1) {
        tmp = uint8[len2 - 1];
        parts.push(
          lookup[tmp >> 2] + lookup[tmp << 4 & 63] + "=="
        );
      } else if (extraBytes === 2) {
        tmp = (uint8[len2 - 2] << 8) + uint8[len2 - 1];
        parts.push(
          lookup[tmp >> 10] + lookup[tmp >> 4 & 63] + lookup[tmp << 2 & 63] + "="
        );
      }
      return parts.join("");
    }
  }
});

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/utils/errors.js
function addLangChainErrorFields2(error, lc_error_code) {
  error.lc_error_code = lc_error_code;
  error.message = `${error.message}

Troubleshooting URL: https://docs.langchain.com/oss/javascript/langchain/errors/${lc_error_code}/
`;
  return error;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/tslib.mjs
function __classPrivateFieldSet(receiver, state, value, kind, f) {
  if (kind === "m")
    throw new TypeError("Private method is not writable");
  if (kind === "a" && !f)
    throw new TypeError("Private accessor was defined without a setter");
  if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver))
    throw new TypeError("Cannot write private member to an object whose class did not declare it");
  return kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
}
function __classPrivateFieldGet(receiver, state, kind, f) {
  if (kind === "a" && !f)
    throw new TypeError("Private accessor was defined without a getter");
  if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver))
    throw new TypeError("Cannot read private member from an object whose class did not declare it");
  return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/utils/uuid.mjs
var uuid4 = function() {
  const { crypto: crypto2 } = globalThis;
  if (crypto2?.randomUUID) {
    uuid4 = crypto2.randomUUID.bind(crypto2);
    return crypto2.randomUUID();
  }
  const u8 = new Uint8Array(1);
  const randomByte = crypto2 ? () => crypto2.getRandomValues(u8)[0] : () => Math.random() * 255 & 255;
  return "10000000-1000-4000-8000-100000000000".replace(/[018]/g, (c) => (+c ^ randomByte() & 15 >> +c / 4).toString(16));
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/errors.mjs
function isAbortError(err) {
  return typeof err === "object" && err !== null && // Spec-compliant fetch implementations
  ("name" in err && err.name === "AbortError" || // Expo fetch
  "message" in err && String(err.message).includes("FetchRequestCanceledException"));
}
var castToError = (err) => {
  if (err instanceof Error)
    return err;
  if (typeof err === "object" && err !== null) {
    try {
      if (Object.prototype.toString.call(err) === "[object Error]") {
        const error = new Error(err.message, err.cause ? { cause: err.cause } : {});
        if (err.stack)
          error.stack = err.stack;
        if (err.cause && !error.cause)
          error.cause = err.cause;
        if (err.name)
          error.name = err.name;
        return error;
      }
    } catch {
    }
    try {
      return new Error(JSON.stringify(err));
    } catch {
    }
  }
  return new Error(err);
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/core/error.mjs
var OpenAIError = class extends Error {
};
var APIError = class _APIError extends OpenAIError {
  constructor(status, error, message, headers) {
    super(`${_APIError.makeMessage(status, error, message)}`);
    this.status = status;
    this.headers = headers;
    this.requestID = headers?.get("x-request-id");
    this.error = error;
    const data = error;
    this.code = data?.["code"];
    this.param = data?.["param"];
    this.type = data?.["type"];
  }
  static makeMessage(status, error, message) {
    const msg = error?.message ? typeof error.message === "string" ? error.message : JSON.stringify(error.message) : error ? JSON.stringify(error) : message;
    if (status && msg) {
      return `${status} ${msg}`;
    }
    if (status) {
      return `${status} status code (no body)`;
    }
    if (msg) {
      return msg;
    }
    return "(no status code or body)";
  }
  static generate(status, errorResponse, message, headers) {
    if (!status || !headers) {
      return new APIConnectionError({ message, cause: castToError(errorResponse) });
    }
    const error = errorResponse?.["error"];
    if (status === 400) {
      return new BadRequestError(status, error, message, headers);
    }
    if (status === 401) {
      return new AuthenticationError(status, error, message, headers);
    }
    if (status === 403) {
      return new PermissionDeniedError(status, error, message, headers);
    }
    if (status === 404) {
      return new NotFoundError(status, error, message, headers);
    }
    if (status === 409) {
      return new ConflictError(status, error, message, headers);
    }
    if (status === 422) {
      return new UnprocessableEntityError(status, error, message, headers);
    }
    if (status === 429) {
      return new RateLimitError(status, error, message, headers);
    }
    if (status >= 500) {
      return new InternalServerError(status, error, message, headers);
    }
    return new _APIError(status, error, message, headers);
  }
};
var APIUserAbortError = class extends APIError {
  constructor({ message } = {}) {
    super(void 0, void 0, message || "Request was aborted.", void 0);
  }
};
var APIConnectionError = class extends APIError {
  constructor({ message, cause }) {
    super(void 0, void 0, message || "Connection error.", void 0);
    if (cause)
      this.cause = cause;
  }
};
var APIConnectionTimeoutError = class extends APIConnectionError {
  constructor({ message } = {}) {
    super({ message: message ?? "Request timed out." });
  }
};
var BadRequestError = class extends APIError {
};
var AuthenticationError = class extends APIError {
};
var PermissionDeniedError = class extends APIError {
};
var NotFoundError = class extends APIError {
};
var ConflictError = class extends APIError {
};
var UnprocessableEntityError = class extends APIError {
};
var RateLimitError = class extends APIError {
};
var InternalServerError = class extends APIError {
};
var LengthFinishReasonError = class extends OpenAIError {
  constructor() {
    super(`Could not parse response content as the length limit was reached`);
  }
};
var ContentFilterFinishReasonError = class extends OpenAIError {
  constructor() {
    super(`Could not parse response content as the request was rejected by the content filter`);
  }
};
var InvalidWebhookSignatureError = class extends Error {
  constructor(message) {
    super(message);
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/utils/values.mjs
var startsWithSchemeRegexp = /^[a-z][a-z0-9+.-]*:/i;
var isAbsoluteURL = (url2) => {
  return startsWithSchemeRegexp.test(url2);
};
var isArray = (val) => (isArray = Array.isArray, isArray(val));
var isReadonlyArray = isArray;
function maybeObj(x) {
  if (typeof x !== "object") {
    return {};
  }
  return x ?? {};
}
function isEmptyObj(obj) {
  if (!obj)
    return true;
  for (const _k in obj)
    return false;
  return true;
}
function hasOwn(obj, key) {
  return Object.prototype.hasOwnProperty.call(obj, key);
}
function isObj(obj) {
  return obj != null && typeof obj === "object" && !Array.isArray(obj);
}
var validatePositiveInteger = (name, n) => {
  if (typeof n !== "number" || !Number.isInteger(n)) {
    throw new OpenAIError(`${name} must be an integer`);
  }
  if (n < 0) {
    throw new OpenAIError(`${name} must be a positive integer`);
  }
  return n;
};
var safeJSON = (text) => {
  try {
    return JSON.parse(text);
  } catch (err) {
    return void 0;
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/utils/sleep.mjs
var sleep = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/version.mjs
var VERSION = "6.25.0";

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/detect-platform.mjs
var isRunningInBrowser = () => {
  return (
    // @ts-ignore
    typeof window !== "undefined" && // @ts-ignore
    typeof window.document !== "undefined" && // @ts-ignore
    typeof navigator !== "undefined"
  );
};
function getDetectedPlatform() {
  if (typeof Deno !== "undefined" && Deno.build != null) {
    return "deno";
  }
  if (typeof EdgeRuntime !== "undefined") {
    return "edge";
  }
  if (Object.prototype.toString.call(typeof globalThis.process !== "undefined" ? globalThis.process : 0) === "[object process]") {
    return "node";
  }
  return "unknown";
}
var getPlatformProperties = () => {
  const detectedPlatform = getDetectedPlatform();
  if (detectedPlatform === "deno") {
    return {
      "X-Stainless-Lang": "js",
      "X-Stainless-Package-Version": VERSION,
      "X-Stainless-OS": normalizePlatform(Deno.build.os),
      "X-Stainless-Arch": normalizeArch(Deno.build.arch),
      "X-Stainless-Runtime": "deno",
      "X-Stainless-Runtime-Version": typeof Deno.version === "string" ? Deno.version : Deno.version?.deno ?? "unknown"
    };
  }
  if (typeof EdgeRuntime !== "undefined") {
    return {
      "X-Stainless-Lang": "js",
      "X-Stainless-Package-Version": VERSION,
      "X-Stainless-OS": "Unknown",
      "X-Stainless-Arch": `other:${EdgeRuntime}`,
      "X-Stainless-Runtime": "edge",
      "X-Stainless-Runtime-Version": globalThis.process.version
    };
  }
  if (detectedPlatform === "node") {
    return {
      "X-Stainless-Lang": "js",
      "X-Stainless-Package-Version": VERSION,
      "X-Stainless-OS": normalizePlatform(globalThis.process.platform ?? "unknown"),
      "X-Stainless-Arch": normalizeArch(globalThis.process.arch ?? "unknown"),
      "X-Stainless-Runtime": "node",
      "X-Stainless-Runtime-Version": globalThis.process.version ?? "unknown"
    };
  }
  const browserInfo = getBrowserInfo();
  if (browserInfo) {
    return {
      "X-Stainless-Lang": "js",
      "X-Stainless-Package-Version": VERSION,
      "X-Stainless-OS": "Unknown",
      "X-Stainless-Arch": "unknown",
      "X-Stainless-Runtime": `browser:${browserInfo.browser}`,
      "X-Stainless-Runtime-Version": browserInfo.version
    };
  }
  return {
    "X-Stainless-Lang": "js",
    "X-Stainless-Package-Version": VERSION,
    "X-Stainless-OS": "Unknown",
    "X-Stainless-Arch": "unknown",
    "X-Stainless-Runtime": "unknown",
    "X-Stainless-Runtime-Version": "unknown"
  };
};
function getBrowserInfo() {
  if (typeof navigator === "undefined" || !navigator) {
    return null;
  }
  const browserPatterns = [
    { key: "edge", pattern: /Edge(?:\W+(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "ie", pattern: /MSIE(?:\W+(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "ie", pattern: /Trident(?:.*rv\:(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "chrome", pattern: /Chrome(?:\W+(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "firefox", pattern: /Firefox(?:\W+(\d+)\.(\d+)(?:\.(\d+))?)?/ },
    { key: "safari", pattern: /(?:Version\W+(\d+)\.(\d+)(?:\.(\d+))?)?(?:\W+Mobile\S*)?\W+Safari/ }
  ];
  for (const { key, pattern } of browserPatterns) {
    const match = pattern.exec(navigator.userAgent);
    if (match) {
      const major = match[1] || 0;
      const minor = match[2] || 0;
      const patch = match[3] || 0;
      return { browser: key, version: `${major}.${minor}.${patch}` };
    }
  }
  return null;
}
var normalizeArch = (arch) => {
  if (arch === "x32")
    return "x32";
  if (arch === "x86_64" || arch === "x64")
    return "x64";
  if (arch === "arm")
    return "arm";
  if (arch === "aarch64" || arch === "arm64")
    return "arm64";
  if (arch)
    return `other:${arch}`;
  return "unknown";
};
var normalizePlatform = (platform) => {
  platform = platform.toLowerCase();
  if (platform.includes("ios"))
    return "iOS";
  if (platform === "android")
    return "Android";
  if (platform === "darwin")
    return "MacOS";
  if (platform === "win32")
    return "Windows";
  if (platform === "freebsd")
    return "FreeBSD";
  if (platform === "openbsd")
    return "OpenBSD";
  if (platform === "linux")
    return "Linux";
  if (platform)
    return `Other:${platform}`;
  return "Unknown";
};
var _platformHeaders;
var getPlatformHeaders = () => {
  return _platformHeaders ?? (_platformHeaders = getPlatformProperties());
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/shims.mjs
function getDefaultFetch() {
  if (typeof fetch !== "undefined") {
    return fetch;
  }
  throw new Error("`fetch` is not defined as a global; Either pass `fetch` to the client, `new OpenAI({ fetch })` or polyfill the global, `globalThis.fetch = fetch`");
}
function makeReadableStream(...args) {
  const ReadableStream2 = globalThis.ReadableStream;
  if (typeof ReadableStream2 === "undefined") {
    throw new Error("`ReadableStream` is not defined as a global; You will need to polyfill it, `globalThis.ReadableStream = ReadableStream`");
  }
  return new ReadableStream2(...args);
}
function ReadableStreamFrom(iterable) {
  let iter = Symbol.asyncIterator in iterable ? iterable[Symbol.asyncIterator]() : iterable[Symbol.iterator]();
  return makeReadableStream({
    start() {
    },
    async pull(controller) {
      const { done, value } = await iter.next();
      if (done) {
        controller.close();
      } else {
        controller.enqueue(value);
      }
    },
    async cancel() {
      await iter.return?.();
    }
  });
}
function ReadableStreamToAsyncIterable(stream) {
  if (stream[Symbol.asyncIterator])
    return stream;
  const reader = stream.getReader();
  return {
    async next() {
      try {
        const result = await reader.read();
        if (result?.done)
          reader.releaseLock();
        return result;
      } catch (e) {
        reader.releaseLock();
        throw e;
      }
    },
    async return() {
      const cancelPromise = reader.cancel();
      reader.releaseLock();
      await cancelPromise;
      return { done: true, value: void 0 };
    },
    [Symbol.asyncIterator]() {
      return this;
    }
  };
}
async function CancelReadableStream(stream) {
  if (stream === null || typeof stream !== "object")
    return;
  if (stream[Symbol.asyncIterator]) {
    await stream[Symbol.asyncIterator]().return?.();
    return;
  }
  const reader = stream.getReader();
  const cancelPromise = reader.cancel();
  reader.releaseLock();
  await cancelPromise;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/request-options.mjs
var FallbackEncoder = ({ headers, body }) => {
  return {
    bodyHeaders: {
      "content-type": "application/json"
    },
    body: JSON.stringify(body)
  };
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/qs/formats.mjs
var default_format = "RFC3986";
var default_formatter = (v) => String(v);
var formatters = {
  RFC1738: (v) => String(v).replace(/%20/g, "+"),
  RFC3986: default_formatter
};
var RFC1738 = "RFC1738";

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/qs/utils.mjs
var has = (obj, key) => (has = Object.hasOwn ?? Function.prototype.call.bind(Object.prototype.hasOwnProperty), has(obj, key));
var hex_table = (() => {
  const array2 = [];
  for (let i = 0; i < 256; ++i) {
    array2.push("%" + ((i < 16 ? "0" : "") + i.toString(16)).toUpperCase());
  }
  return array2;
})();
var limit = 1024;
var encode = (str2, _defaultEncoder, charset, _kind, format) => {
  if (str2.length === 0) {
    return str2;
  }
  let string3 = str2;
  if (typeof str2 === "symbol") {
    string3 = Symbol.prototype.toString.call(str2);
  } else if (typeof str2 !== "string") {
    string3 = String(str2);
  }
  if (charset === "iso-8859-1") {
    return escape(string3).replace(/%u[0-9a-f]{4}/gi, function($0) {
      return "%26%23" + parseInt($0.slice(2), 16) + "%3B";
    });
  }
  let out = "";
  for (let j = 0; j < string3.length; j += limit) {
    const segment = string3.length >= limit ? string3.slice(j, j + limit) : string3;
    const arr = [];
    for (let i = 0; i < segment.length; ++i) {
      let c = segment.charCodeAt(i);
      if (c === 45 || // -
      c === 46 || // .
      c === 95 || // _
      c === 126 || // ~
      c >= 48 && c <= 57 || // 0-9
      c >= 65 && c <= 90 || // a-z
      c >= 97 && c <= 122 || // A-Z
      format === RFC1738 && (c === 40 || c === 41)) {
        arr[arr.length] = segment.charAt(i);
        continue;
      }
      if (c < 128) {
        arr[arr.length] = hex_table[c];
        continue;
      }
      if (c < 2048) {
        arr[arr.length] = hex_table[192 | c >> 6] + hex_table[128 | c & 63];
        continue;
      }
      if (c < 55296 || c >= 57344) {
        arr[arr.length] = hex_table[224 | c >> 12] + hex_table[128 | c >> 6 & 63] + hex_table[128 | c & 63];
        continue;
      }
      i += 1;
      c = 65536 + ((c & 1023) << 10 | segment.charCodeAt(i) & 1023);
      arr[arr.length] = hex_table[240 | c >> 18] + hex_table[128 | c >> 12 & 63] + hex_table[128 | c >> 6 & 63] + hex_table[128 | c & 63];
    }
    out += arr.join("");
  }
  return out;
};
function is_buffer(obj) {
  if (!obj || typeof obj !== "object") {
    return false;
  }
  return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));
}
function maybe_map(val, fn) {
  if (isArray(val)) {
    const mapped = [];
    for (let i = 0; i < val.length; i += 1) {
      mapped.push(fn(val[i]));
    }
    return mapped;
  }
  return fn(val);
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/qs/stringify.mjs
var array_prefix_generators = {
  brackets(prefix) {
    return String(prefix) + "[]";
  },
  comma: "comma",
  indices(prefix, key) {
    return String(prefix) + "[" + key + "]";
  },
  repeat(prefix) {
    return String(prefix);
  }
};
var push_to_array = function(arr, value_or_array) {
  Array.prototype.push.apply(arr, isArray(value_or_array) ? value_or_array : [value_or_array]);
};
var toISOString;
var defaults = {
  addQueryPrefix: false,
  allowDots: false,
  allowEmptyArrays: false,
  arrayFormat: "indices",
  charset: "utf-8",
  charsetSentinel: false,
  delimiter: "&",
  encode: true,
  encodeDotInKeys: false,
  encoder: encode,
  encodeValuesOnly: false,
  format: default_format,
  formatter: default_formatter,
  /** @deprecated */
  indices: false,
  serializeDate(date4) {
    return (toISOString ?? (toISOString = Function.prototype.call.bind(Date.prototype.toISOString)))(date4);
  },
  skipNulls: false,
  strictNullHandling: false
};
function is_non_nullish_primitive(v) {
  return typeof v === "string" || typeof v === "number" || typeof v === "boolean" || typeof v === "symbol" || typeof v === "bigint";
}
var sentinel = {};
function inner_stringify(object2, prefix, generateArrayPrefix, commaRoundTrip, allowEmptyArrays, strictNullHandling, skipNulls, encodeDotInKeys, encoder, filter, sort, allowDots, serializeDate, format, formatter, encodeValuesOnly, charset, sideChannel) {
  let obj = object2;
  let tmp_sc = sideChannel;
  let step = 0;
  let find_flag = false;
  while ((tmp_sc = tmp_sc.get(sentinel)) !== void 0 && !find_flag) {
    const pos = tmp_sc.get(object2);
    step += 1;
    if (typeof pos !== "undefined") {
      if (pos === step) {
        throw new RangeError("Cyclic object value");
      } else {
        find_flag = true;
      }
    }
    if (typeof tmp_sc.get(sentinel) === "undefined") {
      step = 0;
    }
  }
  if (typeof filter === "function") {
    obj = filter(prefix, obj);
  } else if (obj instanceof Date) {
    obj = serializeDate?.(obj);
  } else if (generateArrayPrefix === "comma" && isArray(obj)) {
    obj = maybe_map(obj, function(value) {
      if (value instanceof Date) {
        return serializeDate?.(value);
      }
      return value;
    });
  }
  if (obj === null) {
    if (strictNullHandling) {
      return encoder && !encodeValuesOnly ? (
        // @ts-expect-error
        encoder(prefix, defaults.encoder, charset, "key", format)
      ) : prefix;
    }
    obj = "";
  }
  if (is_non_nullish_primitive(obj) || is_buffer(obj)) {
    if (encoder) {
      const key_value = encodeValuesOnly ? prefix : encoder(prefix, defaults.encoder, charset, "key", format);
      return [
        formatter?.(key_value) + "=" + // @ts-expect-error
        formatter?.(encoder(obj, defaults.encoder, charset, "value", format))
      ];
    }
    return [formatter?.(prefix) + "=" + formatter?.(String(obj))];
  }
  const values = [];
  if (typeof obj === "undefined") {
    return values;
  }
  let obj_keys;
  if (generateArrayPrefix === "comma" && isArray(obj)) {
    if (encodeValuesOnly && encoder) {
      obj = maybe_map(obj, encoder);
    }
    obj_keys = [{ value: obj.length > 0 ? obj.join(",") || null : void 0 }];
  } else if (isArray(filter)) {
    obj_keys = filter;
  } else {
    const keys = Object.keys(obj);
    obj_keys = sort ? keys.sort(sort) : keys;
  }
  const encoded_prefix = encodeDotInKeys ? String(prefix).replace(/\./g, "%2E") : String(prefix);
  const adjusted_prefix = commaRoundTrip && isArray(obj) && obj.length === 1 ? encoded_prefix + "[]" : encoded_prefix;
  if (allowEmptyArrays && isArray(obj) && obj.length === 0) {
    return adjusted_prefix + "[]";
  }
  for (let j = 0; j < obj_keys.length; ++j) {
    const key = obj_keys[j];
    const value = (
      // @ts-ignore
      typeof key === "object" && typeof key.value !== "undefined" ? key.value : obj[key]
    );
    if (skipNulls && value === null) {
      continue;
    }
    const encoded_key = allowDots && encodeDotInKeys ? key.replace(/\./g, "%2E") : key;
    const key_prefix = isArray(obj) ? typeof generateArrayPrefix === "function" ? generateArrayPrefix(adjusted_prefix, encoded_key) : adjusted_prefix : adjusted_prefix + (allowDots ? "." + encoded_key : "[" + encoded_key + "]");
    sideChannel.set(object2, step);
    const valueSideChannel = /* @__PURE__ */ new WeakMap();
    valueSideChannel.set(sentinel, sideChannel);
    push_to_array(values, inner_stringify(
      value,
      key_prefix,
      generateArrayPrefix,
      commaRoundTrip,
      allowEmptyArrays,
      strictNullHandling,
      skipNulls,
      encodeDotInKeys,
      // @ts-ignore
      generateArrayPrefix === "comma" && encodeValuesOnly && isArray(obj) ? null : encoder,
      filter,
      sort,
      allowDots,
      serializeDate,
      format,
      formatter,
      encodeValuesOnly,
      charset,
      valueSideChannel
    ));
  }
  return values;
}
function normalize_stringify_options(opts = defaults) {
  if (typeof opts.allowEmptyArrays !== "undefined" && typeof opts.allowEmptyArrays !== "boolean") {
    throw new TypeError("`allowEmptyArrays` option can only be `true` or `false`, when provided");
  }
  if (typeof opts.encodeDotInKeys !== "undefined" && typeof opts.encodeDotInKeys !== "boolean") {
    throw new TypeError("`encodeDotInKeys` option can only be `true` or `false`, when provided");
  }
  if (opts.encoder !== null && typeof opts.encoder !== "undefined" && typeof opts.encoder !== "function") {
    throw new TypeError("Encoder has to be a function.");
  }
  const charset = opts.charset || defaults.charset;
  if (typeof opts.charset !== "undefined" && opts.charset !== "utf-8" && opts.charset !== "iso-8859-1") {
    throw new TypeError("The charset option must be either utf-8, iso-8859-1, or undefined");
  }
  let format = default_format;
  if (typeof opts.format !== "undefined") {
    if (!has(formatters, opts.format)) {
      throw new TypeError("Unknown format option provided.");
    }
    format = opts.format;
  }
  const formatter = formatters[format];
  let filter = defaults.filter;
  if (typeof opts.filter === "function" || isArray(opts.filter)) {
    filter = opts.filter;
  }
  let arrayFormat;
  if (opts.arrayFormat && opts.arrayFormat in array_prefix_generators) {
    arrayFormat = opts.arrayFormat;
  } else if ("indices" in opts) {
    arrayFormat = opts.indices ? "indices" : "repeat";
  } else {
    arrayFormat = defaults.arrayFormat;
  }
  if ("commaRoundTrip" in opts && typeof opts.commaRoundTrip !== "boolean") {
    throw new TypeError("`commaRoundTrip` must be a boolean, or absent");
  }
  const allowDots = typeof opts.allowDots === "undefined" ? !!opts.encodeDotInKeys === true ? true : defaults.allowDots : !!opts.allowDots;
  return {
    addQueryPrefix: typeof opts.addQueryPrefix === "boolean" ? opts.addQueryPrefix : defaults.addQueryPrefix,
    // @ts-ignore
    allowDots,
    allowEmptyArrays: typeof opts.allowEmptyArrays === "boolean" ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,
    arrayFormat,
    charset,
    charsetSentinel: typeof opts.charsetSentinel === "boolean" ? opts.charsetSentinel : defaults.charsetSentinel,
    commaRoundTrip: !!opts.commaRoundTrip,
    delimiter: typeof opts.delimiter === "undefined" ? defaults.delimiter : opts.delimiter,
    encode: typeof opts.encode === "boolean" ? opts.encode : defaults.encode,
    encodeDotInKeys: typeof opts.encodeDotInKeys === "boolean" ? opts.encodeDotInKeys : defaults.encodeDotInKeys,
    encoder: typeof opts.encoder === "function" ? opts.encoder : defaults.encoder,
    encodeValuesOnly: typeof opts.encodeValuesOnly === "boolean" ? opts.encodeValuesOnly : defaults.encodeValuesOnly,
    filter,
    format,
    formatter,
    serializeDate: typeof opts.serializeDate === "function" ? opts.serializeDate : defaults.serializeDate,
    skipNulls: typeof opts.skipNulls === "boolean" ? opts.skipNulls : defaults.skipNulls,
    // @ts-ignore
    sort: typeof opts.sort === "function" ? opts.sort : null,
    strictNullHandling: typeof opts.strictNullHandling === "boolean" ? opts.strictNullHandling : defaults.strictNullHandling
  };
}
function stringify(object2, opts = {}) {
  let obj = object2;
  const options = normalize_stringify_options(opts);
  let obj_keys;
  let filter;
  if (typeof options.filter === "function") {
    filter = options.filter;
    obj = filter("", obj);
  } else if (isArray(options.filter)) {
    filter = options.filter;
    obj_keys = filter;
  }
  const keys = [];
  if (typeof obj !== "object" || obj === null) {
    return "";
  }
  const generateArrayPrefix = array_prefix_generators[options.arrayFormat];
  const commaRoundTrip = generateArrayPrefix === "comma" && options.commaRoundTrip;
  if (!obj_keys) {
    obj_keys = Object.keys(obj);
  }
  if (options.sort) {
    obj_keys.sort(options.sort);
  }
  const sideChannel = /* @__PURE__ */ new WeakMap();
  for (let i = 0; i < obj_keys.length; ++i) {
    const key = obj_keys[i];
    if (options.skipNulls && obj[key] === null) {
      continue;
    }
    push_to_array(keys, inner_stringify(
      obj[key],
      key,
      // @ts-expect-error
      generateArrayPrefix,
      commaRoundTrip,
      options.allowEmptyArrays,
      options.strictNullHandling,
      options.skipNulls,
      options.encodeDotInKeys,
      options.encode ? options.encoder : null,
      options.filter,
      options.sort,
      options.allowDots,
      options.serializeDate,
      options.format,
      options.formatter,
      options.encodeValuesOnly,
      options.charset,
      sideChannel
    ));
  }
  const joined = keys.join(options.delimiter);
  let prefix = options.addQueryPrefix === true ? "?" : "";
  if (options.charsetSentinel) {
    if (options.charset === "iso-8859-1") {
      prefix += "utf8=%26%2310003%3B&";
    } else {
      prefix += "utf8=%E2%9C%93&";
    }
  }
  return joined.length > 0 ? prefix + joined : "";
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/utils/bytes.mjs
function concatBytes(buffers) {
  let length = 0;
  for (const buffer of buffers) {
    length += buffer.length;
  }
  const output = new Uint8Array(length);
  let index = 0;
  for (const buffer of buffers) {
    output.set(buffer, index);
    index += buffer.length;
  }
  return output;
}
var encodeUTF8_;
function encodeUTF8(str2) {
  let encoder;
  return (encodeUTF8_ ?? (encoder = new globalThis.TextEncoder(), encodeUTF8_ = encoder.encode.bind(encoder)))(str2);
}
var decodeUTF8_;
function decodeUTF8(bytes) {
  let decoder;
  return (decodeUTF8_ ?? (decoder = new globalThis.TextDecoder(), decodeUTF8_ = decoder.decode.bind(decoder)))(bytes);
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/decoders/line.mjs
var _LineDecoder_buffer;
var _LineDecoder_carriageReturnIndex;
var LineDecoder = class {
  constructor() {
    _LineDecoder_buffer.set(this, void 0);
    _LineDecoder_carriageReturnIndex.set(this, void 0);
    __classPrivateFieldSet(this, _LineDecoder_buffer, new Uint8Array(), "f");
    __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, "f");
  }
  decode(chunk) {
    if (chunk == null) {
      return [];
    }
    const binaryChunk = chunk instanceof ArrayBuffer ? new Uint8Array(chunk) : typeof chunk === "string" ? encodeUTF8(chunk) : chunk;
    __classPrivateFieldSet(this, _LineDecoder_buffer, concatBytes([__classPrivateFieldGet(this, _LineDecoder_buffer, "f"), binaryChunk]), "f");
    const lines = [];
    let patternIndex;
    while ((patternIndex = findNewlineIndex(__classPrivateFieldGet(this, _LineDecoder_buffer, "f"), __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, "f"))) != null) {
      if (patternIndex.carriage && __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, "f") == null) {
        __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, patternIndex.index, "f");
        continue;
      }
      if (__classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, "f") != null && (patternIndex.index !== __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, "f") + 1 || patternIndex.carriage)) {
        lines.push(decodeUTF8(__classPrivateFieldGet(this, _LineDecoder_buffer, "f").subarray(0, __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, "f") - 1)));
        __classPrivateFieldSet(this, _LineDecoder_buffer, __classPrivateFieldGet(this, _LineDecoder_buffer, "f").subarray(__classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, "f")), "f");
        __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, "f");
        continue;
      }
      const endIndex = __classPrivateFieldGet(this, _LineDecoder_carriageReturnIndex, "f") !== null ? patternIndex.preceding - 1 : patternIndex.preceding;
      const line = decodeUTF8(__classPrivateFieldGet(this, _LineDecoder_buffer, "f").subarray(0, endIndex));
      lines.push(line);
      __classPrivateFieldSet(this, _LineDecoder_buffer, __classPrivateFieldGet(this, _LineDecoder_buffer, "f").subarray(patternIndex.index), "f");
      __classPrivateFieldSet(this, _LineDecoder_carriageReturnIndex, null, "f");
    }
    return lines;
  }
  flush() {
    if (!__classPrivateFieldGet(this, _LineDecoder_buffer, "f").length) {
      return [];
    }
    return this.decode("\n");
  }
};
_LineDecoder_buffer = /* @__PURE__ */ new WeakMap(), _LineDecoder_carriageReturnIndex = /* @__PURE__ */ new WeakMap();
LineDecoder.NEWLINE_CHARS = /* @__PURE__ */ new Set(["\n", "\r"]);
LineDecoder.NEWLINE_REGEXP = /\r\n|[\n\r]/g;
function findNewlineIndex(buffer, startIndex) {
  const newline = 10;
  const carriage = 13;
  for (let i = startIndex ?? 0; i < buffer.length; i++) {
    if (buffer[i] === newline) {
      return { preceding: i, index: i + 1, carriage: false };
    }
    if (buffer[i] === carriage) {
      return { preceding: i, index: i + 1, carriage: true };
    }
  }
  return null;
}
function findDoubleNewlineIndex(buffer) {
  const newline = 10;
  const carriage = 13;
  for (let i = 0; i < buffer.length - 1; i++) {
    if (buffer[i] === newline && buffer[i + 1] === newline) {
      return i + 2;
    }
    if (buffer[i] === carriage && buffer[i + 1] === carriage) {
      return i + 2;
    }
    if (buffer[i] === carriage && buffer[i + 1] === newline && i + 3 < buffer.length && buffer[i + 2] === carriage && buffer[i + 3] === newline) {
      return i + 4;
    }
  }
  return -1;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/utils/log.mjs
var levelNumbers = {
  off: 0,
  error: 200,
  warn: 300,
  info: 400,
  debug: 500
};
var parseLogLevel = (maybeLevel, sourceName, client) => {
  if (!maybeLevel) {
    return void 0;
  }
  if (hasOwn(levelNumbers, maybeLevel)) {
    return maybeLevel;
  }
  loggerFor(client).warn(`${sourceName} was set to ${JSON.stringify(maybeLevel)}, expected one of ${JSON.stringify(Object.keys(levelNumbers))}`);
  return void 0;
};
function noop() {
}
function makeLogFn(fnLevel, logger, logLevel) {
  if (!logger || levelNumbers[fnLevel] > levelNumbers[logLevel]) {
    return noop;
  } else {
    return logger[fnLevel].bind(logger);
  }
}
var noopLogger = {
  error: noop,
  warn: noop,
  info: noop,
  debug: noop
};
var cachedLoggers = /* @__PURE__ */ new WeakMap();
function loggerFor(client) {
  const logger = client.logger;
  const logLevel = client.logLevel ?? "off";
  if (!logger) {
    return noopLogger;
  }
  const cachedLogger = cachedLoggers.get(logger);
  if (cachedLogger && cachedLogger[0] === logLevel) {
    return cachedLogger[1];
  }
  const levelLogger = {
    error: makeLogFn("error", logger, logLevel),
    warn: makeLogFn("warn", logger, logLevel),
    info: makeLogFn("info", logger, logLevel),
    debug: makeLogFn("debug", logger, logLevel)
  };
  cachedLoggers.set(logger, [logLevel, levelLogger]);
  return levelLogger;
}
var formatRequestDetails = (details) => {
  if (details.options) {
    details.options = { ...details.options };
    delete details.options["headers"];
  }
  if (details.headers) {
    details.headers = Object.fromEntries((details.headers instanceof Headers ? [...details.headers] : Object.entries(details.headers)).map(([name, value]) => [
      name,
      name.toLowerCase() === "authorization" || name.toLowerCase() === "cookie" || name.toLowerCase() === "set-cookie" ? "***" : value
    ]));
  }
  if ("retryOfRequestLogID" in details) {
    if (details.retryOfRequestLogID) {
      details.retryOf = details.retryOfRequestLogID;
    }
    delete details.retryOfRequestLogID;
  }
  return details;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/core/streaming.mjs
var _Stream_client;
var Stream = class _Stream {
  constructor(iterator, controller, client) {
    this.iterator = iterator;
    _Stream_client.set(this, void 0);
    this.controller = controller;
    __classPrivateFieldSet(this, _Stream_client, client, "f");
  }
  static fromSSEResponse(response, controller, client, synthesizeEventData) {
    let consumed = false;
    const logger = client ? loggerFor(client) : console;
    async function* iterator() {
      if (consumed) {
        throw new OpenAIError("Cannot iterate over a consumed stream, use `.tee()` to split the stream.");
      }
      consumed = true;
      let done = false;
      try {
        for await (const sse of _iterSSEMessages(response, controller)) {
          if (done)
            continue;
          if (sse.data.startsWith("[DONE]")) {
            done = true;
            continue;
          }
          if (sse.event === null || !sse.event.startsWith("thread.")) {
            let data;
            try {
              data = JSON.parse(sse.data);
            } catch (e) {
              logger.error(`Could not parse message into JSON:`, sse.data);
              logger.error(`From chunk:`, sse.raw);
              throw e;
            }
            if (data && data.error) {
              throw new APIError(void 0, data.error, void 0, response.headers);
            }
            yield synthesizeEventData ? { event: sse.event, data } : data;
          } else {
            let data;
            try {
              data = JSON.parse(sse.data);
            } catch (e) {
              console.error(`Could not parse message into JSON:`, sse.data);
              console.error(`From chunk:`, sse.raw);
              throw e;
            }
            if (sse.event == "error") {
              throw new APIError(void 0, data.error, data.message, void 0);
            }
            yield { event: sse.event, data };
          }
        }
        done = true;
      } catch (e) {
        if (isAbortError(e))
          return;
        throw e;
      } finally {
        if (!done)
          controller.abort();
      }
    }
    return new _Stream(iterator, controller, client);
  }
  /**
   * Generates a Stream from a newline-separated ReadableStream
   * where each item is a JSON value.
   */
  static fromReadableStream(readableStream, controller, client) {
    let consumed = false;
    async function* iterLines() {
      const lineDecoder = new LineDecoder();
      const iter = ReadableStreamToAsyncIterable(readableStream);
      for await (const chunk of iter) {
        for (const line of lineDecoder.decode(chunk)) {
          yield line;
        }
      }
      for (const line of lineDecoder.flush()) {
        yield line;
      }
    }
    async function* iterator() {
      if (consumed) {
        throw new OpenAIError("Cannot iterate over a consumed stream, use `.tee()` to split the stream.");
      }
      consumed = true;
      let done = false;
      try {
        for await (const line of iterLines()) {
          if (done)
            continue;
          if (line)
            yield JSON.parse(line);
        }
        done = true;
      } catch (e) {
        if (isAbortError(e))
          return;
        throw e;
      } finally {
        if (!done)
          controller.abort();
      }
    }
    return new _Stream(iterator, controller, client);
  }
  [(_Stream_client = /* @__PURE__ */ new WeakMap(), Symbol.asyncIterator)]() {
    return this.iterator();
  }
  /**
   * Splits the stream into two streams which can be
   * independently read from at different speeds.
   */
  tee() {
    const left = [];
    const right = [];
    const iterator = this.iterator();
    const teeIterator = (queue) => {
      return {
        next: () => {
          if (queue.length === 0) {
            const result = iterator.next();
            left.push(result);
            right.push(result);
          }
          return queue.shift();
        }
      };
    };
    return [
      new _Stream(() => teeIterator(left), this.controller, __classPrivateFieldGet(this, _Stream_client, "f")),
      new _Stream(() => teeIterator(right), this.controller, __classPrivateFieldGet(this, _Stream_client, "f"))
    ];
  }
  /**
   * Converts this stream to a newline-separated ReadableStream of
   * JSON stringified values in the stream
   * which can be turned back into a Stream with `Stream.fromReadableStream()`.
   */
  toReadableStream() {
    const self = this;
    let iter;
    return makeReadableStream({
      async start() {
        iter = self[Symbol.asyncIterator]();
      },
      async pull(ctrl) {
        try {
          const { value, done } = await iter.next();
          if (done)
            return ctrl.close();
          const bytes = encodeUTF8(JSON.stringify(value) + "\n");
          ctrl.enqueue(bytes);
        } catch (err) {
          ctrl.error(err);
        }
      },
      async cancel() {
        await iter.return?.();
      }
    });
  }
};
async function* _iterSSEMessages(response, controller) {
  if (!response.body) {
    controller.abort();
    if (typeof globalThis.navigator !== "undefined" && globalThis.navigator.product === "ReactNative") {
      throw new OpenAIError(`The default react-native fetch implementation does not support streaming. Please use expo/fetch: https://docs.expo.dev/versions/latest/sdk/expo/#expofetch-api`);
    }
    throw new OpenAIError(`Attempted to iterate over a response with no body`);
  }
  const sseDecoder = new SSEDecoder();
  const lineDecoder = new LineDecoder();
  const iter = ReadableStreamToAsyncIterable(response.body);
  for await (const sseChunk of iterSSEChunks(iter)) {
    for (const line of lineDecoder.decode(sseChunk)) {
      const sse = sseDecoder.decode(line);
      if (sse)
        yield sse;
    }
  }
  for (const line of lineDecoder.flush()) {
    const sse = sseDecoder.decode(line);
    if (sse)
      yield sse;
  }
}
async function* iterSSEChunks(iterator) {
  let data = new Uint8Array();
  for await (const chunk of iterator) {
    if (chunk == null) {
      continue;
    }
    const binaryChunk = chunk instanceof ArrayBuffer ? new Uint8Array(chunk) : typeof chunk === "string" ? encodeUTF8(chunk) : chunk;
    let newData = new Uint8Array(data.length + binaryChunk.length);
    newData.set(data);
    newData.set(binaryChunk, data.length);
    data = newData;
    let patternIndex;
    while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {
      yield data.slice(0, patternIndex);
      data = data.slice(patternIndex);
    }
  }
  if (data.length > 0) {
    yield data;
  }
}
var SSEDecoder = class {
  constructor() {
    this.event = null;
    this.data = [];
    this.chunks = [];
  }
  decode(line) {
    if (line.endsWith("\r")) {
      line = line.substring(0, line.length - 1);
    }
    if (!line) {
      if (!this.event && !this.data.length)
        return null;
      const sse = {
        event: this.event,
        data: this.data.join("\n"),
        raw: this.chunks
      };
      this.event = null;
      this.data = [];
      this.chunks = [];
      return sse;
    }
    this.chunks.push(line);
    if (line.startsWith(":")) {
      return null;
    }
    let [fieldname, _, value] = partition(line, ":");
    if (value.startsWith(" ")) {
      value = value.substring(1);
    }
    if (fieldname === "event") {
      this.event = value;
    } else if (fieldname === "data") {
      this.data.push(value);
    }
    return null;
  }
};
function partition(str2, delimiter) {
  const index = str2.indexOf(delimiter);
  if (index !== -1) {
    return [str2.substring(0, index), delimiter, str2.substring(index + delimiter.length)];
  }
  return [str2, "", ""];
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/parse.mjs
async function defaultParseResponse(client, props) {
  const { response, requestLogID, retryOfRequestLogID, startTime } = props;
  const body = await (async () => {
    if (props.options.stream) {
      loggerFor(client).debug("response", response.status, response.url, response.headers, response.body);
      if (props.options.__streamClass) {
        return props.options.__streamClass.fromSSEResponse(response, props.controller, client, props.options.__synthesizeEventData);
      }
      return Stream.fromSSEResponse(response, props.controller, client, props.options.__synthesizeEventData);
    }
    if (response.status === 204) {
      return null;
    }
    if (props.options.__binaryResponse) {
      return response;
    }
    const contentType = response.headers.get("content-type");
    const mediaType = contentType?.split(";")[0]?.trim();
    const isJSON = mediaType?.includes("application/json") || mediaType?.endsWith("+json");
    if (isJSON) {
      const contentLength = response.headers.get("content-length");
      if (contentLength === "0") {
        return void 0;
      }
      const json2 = await response.json();
      return addRequestID(json2, response);
    }
    const text = await response.text();
    return text;
  })();
  loggerFor(client).debug(`[${requestLogID}] response parsed`, formatRequestDetails({
    retryOfRequestLogID,
    url: response.url,
    status: response.status,
    body,
    durationMs: Date.now() - startTime
  }));
  return body;
}
function addRequestID(value, response) {
  if (!value || typeof value !== "object" || Array.isArray(value)) {
    return value;
  }
  return Object.defineProperty(value, "_request_id", {
    value: response.headers.get("x-request-id"),
    enumerable: false
  });
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/core/api-promise.mjs
var _APIPromise_client;
var APIPromise = class _APIPromise extends Promise {
  constructor(client, responsePromise, parseResponse2 = defaultParseResponse) {
    super((resolve) => {
      resolve(null);
    });
    this.responsePromise = responsePromise;
    this.parseResponse = parseResponse2;
    _APIPromise_client.set(this, void 0);
    __classPrivateFieldSet(this, _APIPromise_client, client, "f");
  }
  _thenUnwrap(transform2) {
    return new _APIPromise(__classPrivateFieldGet(this, _APIPromise_client, "f"), this.responsePromise, async (client, props) => addRequestID(transform2(await this.parseResponse(client, props), props), props.response));
  }
  /**
   * Gets the raw `Response` instance instead of parsing the response
   * data.
   *
   * If you want to parse the response body but still get the `Response`
   * instance, you can use {@link withResponse()}.
   *
   *  Getting the wrong TypeScript type for `Response`?
   * Try setting `"moduleResolution": "NodeNext"` or add `"lib": ["DOM"]`
   * to your `tsconfig.json`.
   */
  asResponse() {
    return this.responsePromise.then((p) => p.response);
  }
  /**
   * Gets the parsed response data, the raw `Response` instance and the ID of the request,
   * returned via the X-Request-ID header which is useful for debugging requests and reporting
   * issues to OpenAI.
   *
   * If you just want to get the raw `Response` instance without parsing it,
   * you can use {@link asResponse()}.
   *
   *  Getting the wrong TypeScript type for `Response`?
   * Try setting `"moduleResolution": "NodeNext"` or add `"lib": ["DOM"]`
   * to your `tsconfig.json`.
   */
  async withResponse() {
    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);
    return { data, response, request_id: response.headers.get("x-request-id") };
  }
  parse() {
    if (!this.parsedPromise) {
      this.parsedPromise = this.responsePromise.then((data) => this.parseResponse(__classPrivateFieldGet(this, _APIPromise_client, "f"), data));
    }
    return this.parsedPromise;
  }
  then(onfulfilled, onrejected) {
    return this.parse().then(onfulfilled, onrejected);
  }
  catch(onrejected) {
    return this.parse().catch(onrejected);
  }
  finally(onfinally) {
    return this.parse().finally(onfinally);
  }
};
_APIPromise_client = /* @__PURE__ */ new WeakMap();

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/core/pagination.mjs
var _AbstractPage_client;
var AbstractPage = class {
  constructor(client, response, body, options) {
    _AbstractPage_client.set(this, void 0);
    __classPrivateFieldSet(this, _AbstractPage_client, client, "f");
    this.options = options;
    this.response = response;
    this.body = body;
  }
  hasNextPage() {
    const items = this.getPaginatedItems();
    if (!items.length)
      return false;
    return this.nextPageRequestOptions() != null;
  }
  async getNextPage() {
    const nextOptions = this.nextPageRequestOptions();
    if (!nextOptions) {
      throw new OpenAIError("No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.");
    }
    return await __classPrivateFieldGet(this, _AbstractPage_client, "f").requestAPIList(this.constructor, nextOptions);
  }
  async *iterPages() {
    let page = this;
    yield page;
    while (page.hasNextPage()) {
      page = await page.getNextPage();
      yield page;
    }
  }
  async *[(_AbstractPage_client = /* @__PURE__ */ new WeakMap(), Symbol.asyncIterator)]() {
    for await (const page of this.iterPages()) {
      for (const item of page.getPaginatedItems()) {
        yield item;
      }
    }
  }
};
var PagePromise = class extends APIPromise {
  constructor(client, request, Page2) {
    super(client, request, async (client2, props) => new Page2(client2, props.response, await defaultParseResponse(client2, props), props.options));
  }
  /**
   * Allow auto-paginating iteration on an unawaited list call, eg:
   *
   *    for await (const item of client.items.list()) {
   *      console.log(item)
   *    }
   */
  async *[Symbol.asyncIterator]() {
    const page = await this;
    for await (const item of page) {
      yield item;
    }
  }
};
var Page = class extends AbstractPage {
  constructor(client, response, body, options) {
    super(client, response, body, options);
    this.data = body.data || [];
    this.object = body.object;
  }
  getPaginatedItems() {
    return this.data ?? [];
  }
  nextPageRequestOptions() {
    return null;
  }
};
var CursorPage = class extends AbstractPage {
  constructor(client, response, body, options) {
    super(client, response, body, options);
    this.data = body.data || [];
    this.has_more = body.has_more || false;
  }
  getPaginatedItems() {
    return this.data ?? [];
  }
  hasNextPage() {
    if (this.has_more === false) {
      return false;
    }
    return super.hasNextPage();
  }
  nextPageRequestOptions() {
    const data = this.getPaginatedItems();
    const id = data[data.length - 1]?.id;
    if (!id) {
      return null;
    }
    return {
      ...this.options,
      query: {
        ...maybeObj(this.options.query),
        after: id
      }
    };
  }
};
var ConversationCursorPage = class extends AbstractPage {
  constructor(client, response, body, options) {
    super(client, response, body, options);
    this.data = body.data || [];
    this.has_more = body.has_more || false;
    this.last_id = body.last_id || "";
  }
  getPaginatedItems() {
    return this.data ?? [];
  }
  hasNextPage() {
    if (this.has_more === false) {
      return false;
    }
    return super.hasNextPage();
  }
  nextPageRequestOptions() {
    const cursor = this.last_id;
    if (!cursor) {
      return null;
    }
    return {
      ...this.options,
      query: {
        ...maybeObj(this.options.query),
        after: cursor
      }
    };
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/uploads.mjs
var checkFileSupport = () => {
  if (typeof File === "undefined") {
    const { process: process2 } = globalThis;
    const isOldNode = typeof process2?.versions?.node === "string" && parseInt(process2.versions.node.split(".")) < 20;
    throw new Error("`File` is not defined as a global, which is required for file uploads." + (isOldNode ? " Update to Node 20 LTS or newer, or set `globalThis.File` to `import('node:buffer').File`." : ""));
  }
};
function makeFile(fileBits, fileName, options) {
  checkFileSupport();
  return new File(fileBits, fileName ?? "unknown_file", options);
}
function getName(value) {
  return (typeof value === "object" && value !== null && ("name" in value && value.name && String(value.name) || "url" in value && value.url && String(value.url) || "filename" in value && value.filename && String(value.filename) || "path" in value && value.path && String(value.path)) || "").split(/[\\/]/).pop() || void 0;
}
var isAsyncIterable = (value) => value != null && typeof value === "object" && typeof value[Symbol.asyncIterator] === "function";
var maybeMultipartFormRequestOptions = async (opts, fetch2) => {
  if (!hasUploadableValue(opts.body))
    return opts;
  return { ...opts, body: await createForm(opts.body, fetch2) };
};
var multipartFormRequestOptions = async (opts, fetch2) => {
  return { ...opts, body: await createForm(opts.body, fetch2) };
};
var supportsFormDataMap = /* @__PURE__ */ new WeakMap();
function supportsFormData(fetchObject) {
  const fetch2 = typeof fetchObject === "function" ? fetchObject : fetchObject.fetch;
  const cached = supportsFormDataMap.get(fetch2);
  if (cached)
    return cached;
  const promise2 = (async () => {
    try {
      const FetchResponse = "Response" in fetch2 ? fetch2.Response : (await fetch2("data:,")).constructor;
      const data = new FormData();
      if (data.toString() === await new FetchResponse(data).text()) {
        return false;
      }
      return true;
    } catch {
      return true;
    }
  })();
  supportsFormDataMap.set(fetch2, promise2);
  return promise2;
}
var createForm = async (body, fetch2) => {
  if (!await supportsFormData(fetch2)) {
    throw new TypeError("The provided fetch function does not support file uploads with the current global FormData class.");
  }
  const form = new FormData();
  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));
  return form;
};
var isNamedBlob = (value) => value instanceof Blob && "name" in value;
var isUploadable = (value) => typeof value === "object" && value !== null && (value instanceof Response || isAsyncIterable(value) || isNamedBlob(value));
var hasUploadableValue = (value) => {
  if (isUploadable(value))
    return true;
  if (Array.isArray(value))
    return value.some(hasUploadableValue);
  if (value && typeof value === "object") {
    for (const k in value) {
      if (hasUploadableValue(value[k]))
        return true;
    }
  }
  return false;
};
var addFormValue = async (form, key, value) => {
  if (value === void 0)
    return;
  if (value == null) {
    throw new TypeError(`Received null for "${key}"; to pass null in FormData, you must use the string 'null'`);
  }
  if (typeof value === "string" || typeof value === "number" || typeof value === "boolean") {
    form.append(key, String(value));
  } else if (value instanceof Response) {
    form.append(key, makeFile([await value.blob()], getName(value)));
  } else if (isAsyncIterable(value)) {
    form.append(key, makeFile([await new Response(ReadableStreamFrom(value)).blob()], getName(value)));
  } else if (isNamedBlob(value)) {
    form.append(key, value, getName(value));
  } else if (Array.isArray(value)) {
    await Promise.all(value.map((entry) => addFormValue(form, key + "[]", entry)));
  } else if (typeof value === "object") {
    await Promise.all(Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)));
  } else {
    throw new TypeError(`Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`);
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/to-file.mjs
var isBlobLike = (value) => value != null && typeof value === "object" && typeof value.size === "number" && typeof value.type === "string" && typeof value.text === "function" && typeof value.slice === "function" && typeof value.arrayBuffer === "function";
var isFileLike = (value) => value != null && typeof value === "object" && typeof value.name === "string" && typeof value.lastModified === "number" && isBlobLike(value);
var isResponseLike = (value) => value != null && typeof value === "object" && typeof value.url === "string" && typeof value.blob === "function";
async function toFile(value, name, options) {
  checkFileSupport();
  value = await value;
  if (isFileLike(value)) {
    if (value instanceof File) {
      return value;
    }
    return makeFile([await value.arrayBuffer()], value.name);
  }
  if (isResponseLike(value)) {
    const blob = await value.blob();
    name || (name = new URL(value.url).pathname.split(/[\\/]/).pop());
    return makeFile(await getBytes(blob), name, options);
  }
  const parts = await getBytes(value);
  name || (name = getName(value));
  if (!options?.type) {
    const type = parts.find((part) => typeof part === "object" && "type" in part && part.type);
    if (typeof type === "string") {
      options = { ...options, type };
    }
  }
  return makeFile(parts, name, options);
}
async function getBytes(value) {
  let parts = [];
  if (typeof value === "string" || ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.
  value instanceof ArrayBuffer) {
    parts.push(value);
  } else if (isBlobLike(value)) {
    parts.push(value instanceof Blob ? value : await value.arrayBuffer());
  } else if (isAsyncIterable(value)) {
    for await (const chunk of value) {
      parts.push(...await getBytes(chunk));
    }
  } else {
    const constructor = value?.constructor?.name;
    throw new Error(`Unexpected data type: ${typeof value}${constructor ? `; constructor: ${constructor}` : ""}${propsForError(value)}`);
  }
  return parts;
}
function propsForError(value) {
  if (typeof value !== "object" || value === null)
    return "";
  const props = Object.getOwnPropertyNames(value);
  return `; props: [${props.map((p) => `"${p}"`).join(", ")}]`;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/core/resource.mjs
var APIResource = class {
  constructor(client) {
    this._client = client;
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/utils/path.mjs
function encodeURIPath(str2) {
  return str2.replace(/[^A-Za-z0-9\-._~!$&'()*+,;=:@]+/g, encodeURIComponent);
}
var EMPTY = Object.freeze(/* @__PURE__ */ Object.create(null));
var createPathTagFunction = (pathEncoder = encodeURIPath) => function path2(statics, ...params) {
  if (statics.length === 1)
    return statics[0];
  let postPath = false;
  const invalidSegments = [];
  const path3 = statics.reduce((previousValue, currentValue, index) => {
    if (/[?#]/.test(currentValue)) {
      postPath = true;
    }
    const value = params[index];
    let encoded = (postPath ? encodeURIComponent : pathEncoder)("" + value);
    if (index !== params.length && (value == null || typeof value === "object" && // handle values from other realms
    value.toString === Object.getPrototypeOf(Object.getPrototypeOf(value.hasOwnProperty ?? EMPTY) ?? EMPTY)?.toString)) {
      encoded = value + "";
      invalidSegments.push({
        start: previousValue.length + currentValue.length,
        length: encoded.length,
        error: `Value of type ${Object.prototype.toString.call(value).slice(8, -1)} is not a valid path parameter`
      });
    }
    return previousValue + currentValue + (index === params.length ? "" : encoded);
  }, "");
  const pathOnly = path3.split(/[?#]/, 1)[0];
  const invalidSegmentPattern = new RegExp("(?<=^|\\/)(?:\\.|%2e){1,2}(?=\\/|$)", "gi");
  let match;
  while ((match = invalidSegmentPattern.exec(pathOnly)) !== null) {
    invalidSegments.push({
      start: match.index,
      length: match[0].length,
      error: `Value "${match[0]}" can't be safely passed as a path parameter`
    });
  }
  invalidSegments.sort((a, b) => a.start - b.start);
  if (invalidSegments.length > 0) {
    let lastEnd = 0;
    const underline = invalidSegments.reduce((acc, segment) => {
      const spaces = " ".repeat(segment.start - lastEnd);
      const arrows = "^".repeat(segment.length);
      lastEnd = segment.start + segment.length;
      return acc + spaces + arrows;
    }, "");
    throw new OpenAIError(`Path parameters result in path with invalid segments:
${invalidSegments.map((e) => e.error).join("\n")}
${path3}
${underline}`);
  }
  return path3;
};
var path = createPathTagFunction(encodeURIPath);

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/chat/completions/messages.mjs
var Messages = class extends APIResource {
  /**
   * Get the messages in a stored chat completion. Only Chat Completions that have
   * been created with the `store` parameter set to `true` will be returned.
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const chatCompletionStoreMessage of client.chat.completions.messages.list(
   *   'completion_id',
   * )) {
   *   // ...
   * }
   * ```
   */
  list(completionID, query = {}, options) {
    return this._client.getAPIList(path`/chat/completions/${completionID}/messages`, CursorPage, { query, ...options });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/parser.mjs
function isChatCompletionFunctionTool(tool2) {
  return tool2 !== void 0 && "function" in tool2 && tool2.function !== void 0;
}
function makeParseableResponseFormat(response_format, parser) {
  const obj = { ...response_format };
  Object.defineProperties(obj, {
    $brand: {
      value: "auto-parseable-response-format",
      enumerable: false
    },
    $parseRaw: {
      value: parser,
      enumerable: false
    }
  });
  return obj;
}
function isAutoParsableResponseFormat(response_format) {
  return response_format?.["$brand"] === "auto-parseable-response-format";
}
function isAutoParsableTool(tool2) {
  return tool2?.["$brand"] === "auto-parseable-tool";
}
function maybeParseChatCompletion(completion, params) {
  if (!params || !hasAutoParseableInput(params)) {
    return {
      ...completion,
      choices: completion.choices.map((choice) => {
        assertToolCallsAreChatCompletionFunctionToolCalls(choice.message.tool_calls);
        return {
          ...choice,
          message: {
            ...choice.message,
            parsed: null,
            ...choice.message.tool_calls ? {
              tool_calls: choice.message.tool_calls
            } : void 0
          }
        };
      })
    };
  }
  return parseChatCompletion(completion, params);
}
function parseChatCompletion(completion, params) {
  const choices = completion.choices.map((choice) => {
    if (choice.finish_reason === "length") {
      throw new LengthFinishReasonError();
    }
    if (choice.finish_reason === "content_filter") {
      throw new ContentFilterFinishReasonError();
    }
    assertToolCallsAreChatCompletionFunctionToolCalls(choice.message.tool_calls);
    return {
      ...choice,
      message: {
        ...choice.message,
        ...choice.message.tool_calls ? {
          tool_calls: choice.message.tool_calls?.map((toolCall) => parseToolCall(params, toolCall)) ?? void 0
        } : void 0,
        parsed: choice.message.content && !choice.message.refusal ? parseResponseFormat(params, choice.message.content) : null
      }
    };
  });
  return { ...completion, choices };
}
function parseResponseFormat(params, content) {
  if (params.response_format?.type !== "json_schema") {
    return null;
  }
  if (params.response_format?.type === "json_schema") {
    if ("$parseRaw" in params.response_format) {
      const response_format = params.response_format;
      return response_format.$parseRaw(content);
    }
    return JSON.parse(content);
  }
  return null;
}
function parseToolCall(params, toolCall) {
  const inputTool = params.tools?.find((inputTool2) => isChatCompletionFunctionTool(inputTool2) && inputTool2.function?.name === toolCall.function.name);
  return {
    ...toolCall,
    function: {
      ...toolCall.function,
      parsed_arguments: isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.function.arguments) : inputTool?.function.strict ? JSON.parse(toolCall.function.arguments) : null
    }
  };
}
function shouldParseToolCall(params, toolCall) {
  if (!params || !("tools" in params) || !params.tools) {
    return false;
  }
  const inputTool = params.tools?.find((inputTool2) => isChatCompletionFunctionTool(inputTool2) && inputTool2.function?.name === toolCall.function.name);
  return isChatCompletionFunctionTool(inputTool) && (isAutoParsableTool(inputTool) || inputTool?.function.strict || false);
}
function hasAutoParseableInput(params) {
  if (isAutoParsableResponseFormat(params.response_format)) {
    return true;
  }
  return params.tools?.some((t) => isAutoParsableTool(t) || t.type === "function" && t.function.strict === true) ?? false;
}
function assertToolCallsAreChatCompletionFunctionToolCalls(toolCalls) {
  for (const toolCall of toolCalls || []) {
    if (toolCall.type !== "function") {
      throw new OpenAIError(`Currently only \`function\` tool calls are supported; Received \`${toolCall.type}\``);
    }
  }
}
function validateInputTools(tools2) {
  for (const tool2 of tools2 ?? []) {
    if (tool2.type !== "function") {
      throw new OpenAIError(`Currently only \`function\` tool types support auto-parsing; Received \`${tool2.type}\``);
    }
    if (tool2.function.strict !== true) {
      throw new OpenAIError(`The \`${tool2.function.name}\` tool is not marked with \`strict: true\`. Only strict function tools can be auto-parsed`);
    }
  }
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/chatCompletionUtils.mjs
var isAssistantMessage = (message) => {
  return message?.role === "assistant";
};
var isToolMessage = (message) => {
  return message?.role === "tool";
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/EventStream.mjs
var _EventStream_instances;
var _EventStream_connectedPromise;
var _EventStream_resolveConnectedPromise;
var _EventStream_rejectConnectedPromise;
var _EventStream_endPromise;
var _EventStream_resolveEndPromise;
var _EventStream_rejectEndPromise;
var _EventStream_listeners;
var _EventStream_ended;
var _EventStream_errored;
var _EventStream_aborted;
var _EventStream_catchingPromiseCreated;
var _EventStream_handleError;
var EventStream = class {
  constructor() {
    _EventStream_instances.add(this);
    this.controller = new AbortController();
    _EventStream_connectedPromise.set(this, void 0);
    _EventStream_resolveConnectedPromise.set(this, () => {
    });
    _EventStream_rejectConnectedPromise.set(this, () => {
    });
    _EventStream_endPromise.set(this, void 0);
    _EventStream_resolveEndPromise.set(this, () => {
    });
    _EventStream_rejectEndPromise.set(this, () => {
    });
    _EventStream_listeners.set(this, {});
    _EventStream_ended.set(this, false);
    _EventStream_errored.set(this, false);
    _EventStream_aborted.set(this, false);
    _EventStream_catchingPromiseCreated.set(this, false);
    __classPrivateFieldSet(this, _EventStream_connectedPromise, new Promise((resolve, reject) => {
      __classPrivateFieldSet(this, _EventStream_resolveConnectedPromise, resolve, "f");
      __classPrivateFieldSet(this, _EventStream_rejectConnectedPromise, reject, "f");
    }), "f");
    __classPrivateFieldSet(this, _EventStream_endPromise, new Promise((resolve, reject) => {
      __classPrivateFieldSet(this, _EventStream_resolveEndPromise, resolve, "f");
      __classPrivateFieldSet(this, _EventStream_rejectEndPromise, reject, "f");
    }), "f");
    __classPrivateFieldGet(this, _EventStream_connectedPromise, "f").catch(() => {
    });
    __classPrivateFieldGet(this, _EventStream_endPromise, "f").catch(() => {
    });
  }
  _run(executor) {
    setTimeout(() => {
      executor().then(() => {
        this._emitFinal();
        this._emit("end");
      }, __classPrivateFieldGet(this, _EventStream_instances, "m", _EventStream_handleError).bind(this));
    }, 0);
  }
  _connected() {
    if (this.ended)
      return;
    __classPrivateFieldGet(this, _EventStream_resolveConnectedPromise, "f").call(this);
    this._emit("connect");
  }
  get ended() {
    return __classPrivateFieldGet(this, _EventStream_ended, "f");
  }
  get errored() {
    return __classPrivateFieldGet(this, _EventStream_errored, "f");
  }
  get aborted() {
    return __classPrivateFieldGet(this, _EventStream_aborted, "f");
  }
  abort() {
    this.controller.abort();
  }
  /**
   * Adds the listener function to the end of the listeners array for the event.
   * No checks are made to see if the listener has already been added. Multiple calls passing
   * the same combination of event and listener will result in the listener being added, and
   * called, multiple times.
   * @returns this ChatCompletionStream, so that calls can be chained
   */
  on(event, listener) {
    const listeners = __classPrivateFieldGet(this, _EventStream_listeners, "f")[event] || (__classPrivateFieldGet(this, _EventStream_listeners, "f")[event] = []);
    listeners.push({ listener });
    return this;
  }
  /**
   * Removes the specified listener from the listener array for the event.
   * off() will remove, at most, one instance of a listener from the listener array. If any single
   * listener has been added multiple times to the listener array for the specified event, then
   * off() must be called multiple times to remove each instance.
   * @returns this ChatCompletionStream, so that calls can be chained
   */
  off(event, listener) {
    const listeners = __classPrivateFieldGet(this, _EventStream_listeners, "f")[event];
    if (!listeners)
      return this;
    const index = listeners.findIndex((l) => l.listener === listener);
    if (index >= 0)
      listeners.splice(index, 1);
    return this;
  }
  /**
   * Adds a one-time listener function for the event. The next time the event is triggered,
   * this listener is removed and then invoked.
   * @returns this ChatCompletionStream, so that calls can be chained
   */
  once(event, listener) {
    const listeners = __classPrivateFieldGet(this, _EventStream_listeners, "f")[event] || (__classPrivateFieldGet(this, _EventStream_listeners, "f")[event] = []);
    listeners.push({ listener, once: true });
    return this;
  }
  /**
   * This is similar to `.once()`, but returns a Promise that resolves the next time
   * the event is triggered, instead of calling a listener callback.
   * @returns a Promise that resolves the next time given event is triggered,
   * or rejects if an error is emitted.  (If you request the 'error' event,
   * returns a promise that resolves with the error).
   *
   * Example:
   *
   *   const message = await stream.emitted('message') // rejects if the stream errors
   */
  emitted(event) {
    return new Promise((resolve, reject) => {
      __classPrivateFieldSet(this, _EventStream_catchingPromiseCreated, true, "f");
      if (event !== "error")
        this.once("error", reject);
      this.once(event, resolve);
    });
  }
  async done() {
    __classPrivateFieldSet(this, _EventStream_catchingPromiseCreated, true, "f");
    await __classPrivateFieldGet(this, _EventStream_endPromise, "f");
  }
  _emit(event, ...args) {
    if (__classPrivateFieldGet(this, _EventStream_ended, "f")) {
      return;
    }
    if (event === "end") {
      __classPrivateFieldSet(this, _EventStream_ended, true, "f");
      __classPrivateFieldGet(this, _EventStream_resolveEndPromise, "f").call(this);
    }
    const listeners = __classPrivateFieldGet(this, _EventStream_listeners, "f")[event];
    if (listeners) {
      __classPrivateFieldGet(this, _EventStream_listeners, "f")[event] = listeners.filter((l) => !l.once);
      listeners.forEach(({ listener }) => listener(...args));
    }
    if (event === "abort") {
      const error = args[0];
      if (!__classPrivateFieldGet(this, _EventStream_catchingPromiseCreated, "f") && !listeners?.length) {
        Promise.reject(error);
      }
      __classPrivateFieldGet(this, _EventStream_rejectConnectedPromise, "f").call(this, error);
      __classPrivateFieldGet(this, _EventStream_rejectEndPromise, "f").call(this, error);
      this._emit("end");
      return;
    }
    if (event === "error") {
      const error = args[0];
      if (!__classPrivateFieldGet(this, _EventStream_catchingPromiseCreated, "f") && !listeners?.length) {
        Promise.reject(error);
      }
      __classPrivateFieldGet(this, _EventStream_rejectConnectedPromise, "f").call(this, error);
      __classPrivateFieldGet(this, _EventStream_rejectEndPromise, "f").call(this, error);
      this._emit("end");
    }
  }
  _emitFinal() {
  }
};
_EventStream_connectedPromise = /* @__PURE__ */ new WeakMap(), _EventStream_resolveConnectedPromise = /* @__PURE__ */ new WeakMap(), _EventStream_rejectConnectedPromise = /* @__PURE__ */ new WeakMap(), _EventStream_endPromise = /* @__PURE__ */ new WeakMap(), _EventStream_resolveEndPromise = /* @__PURE__ */ new WeakMap(), _EventStream_rejectEndPromise = /* @__PURE__ */ new WeakMap(), _EventStream_listeners = /* @__PURE__ */ new WeakMap(), _EventStream_ended = /* @__PURE__ */ new WeakMap(), _EventStream_errored = /* @__PURE__ */ new WeakMap(), _EventStream_aborted = /* @__PURE__ */ new WeakMap(), _EventStream_catchingPromiseCreated = /* @__PURE__ */ new WeakMap(), _EventStream_instances = /* @__PURE__ */ new WeakSet(), _EventStream_handleError = function _EventStream_handleError2(error) {
  __classPrivateFieldSet(this, _EventStream_errored, true, "f");
  if (error instanceof Error && error.name === "AbortError") {
    error = new APIUserAbortError();
  }
  if (error instanceof APIUserAbortError) {
    __classPrivateFieldSet(this, _EventStream_aborted, true, "f");
    return this._emit("abort", error);
  }
  if (error instanceof OpenAIError) {
    return this._emit("error", error);
  }
  if (error instanceof Error) {
    const openAIError = new OpenAIError(error.message);
    openAIError.cause = error;
    return this._emit("error", openAIError);
  }
  return this._emit("error", new OpenAIError(String(error)));
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/RunnableFunction.mjs
function isRunnableFunctionWithParse(fn) {
  return typeof fn.parse === "function";
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/AbstractChatCompletionRunner.mjs
var _AbstractChatCompletionRunner_instances;
var _AbstractChatCompletionRunner_getFinalContent;
var _AbstractChatCompletionRunner_getFinalMessage;
var _AbstractChatCompletionRunner_getFinalFunctionToolCall;
var _AbstractChatCompletionRunner_getFinalFunctionToolCallResult;
var _AbstractChatCompletionRunner_calculateTotalUsage;
var _AbstractChatCompletionRunner_validateParams;
var _AbstractChatCompletionRunner_stringifyFunctionCallResult;
var DEFAULT_MAX_CHAT_COMPLETIONS = 10;
var AbstractChatCompletionRunner = class extends EventStream {
  constructor() {
    super(...arguments);
    _AbstractChatCompletionRunner_instances.add(this);
    this._chatCompletions = [];
    this.messages = [];
  }
  _addChatCompletion(chatCompletion) {
    this._chatCompletions.push(chatCompletion);
    this._emit("chatCompletion", chatCompletion);
    const message = chatCompletion.choices[0]?.message;
    if (message)
      this._addMessage(message);
    return chatCompletion;
  }
  _addMessage(message, emit = true) {
    if (!("content" in message))
      message.content = null;
    this.messages.push(message);
    if (emit) {
      this._emit("message", message);
      if (isToolMessage(message) && message.content) {
        this._emit("functionToolCallResult", message.content);
      } else if (isAssistantMessage(message) && message.tool_calls) {
        for (const tool_call of message.tool_calls) {
          if (tool_call.type === "function") {
            this._emit("functionToolCall", tool_call.function);
          }
        }
      }
    }
  }
  /**
   * @returns a promise that resolves with the final ChatCompletion, or rejects
   * if an error occurred or the stream ended prematurely without producing a ChatCompletion.
   */
  async finalChatCompletion() {
    await this.done();
    const completion = this._chatCompletions[this._chatCompletions.length - 1];
    if (!completion)
      throw new OpenAIError("stream ended without producing a ChatCompletion");
    return completion;
  }
  /**
   * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects
   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.
   */
  async finalContent() {
    await this.done();
    return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalContent).call(this);
  }
  /**
   * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,
   * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.
   */
  async finalMessage() {
    await this.done();
    return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalMessage).call(this);
  }
  /**
   * @returns a promise that resolves with the content of the final FunctionCall, or rejects
   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.
   */
  async finalFunctionToolCall() {
    await this.done();
    return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalFunctionToolCall).call(this);
  }
  async finalFunctionToolCallResult() {
    await this.done();
    return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalFunctionToolCallResult).call(this);
  }
  async totalUsage() {
    await this.done();
    return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_calculateTotalUsage).call(this);
  }
  allChatCompletions() {
    return [...this._chatCompletions];
  }
  _emitFinal() {
    const completion = this._chatCompletions[this._chatCompletions.length - 1];
    if (completion)
      this._emit("finalChatCompletion", completion);
    const finalMessage = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalMessage).call(this);
    if (finalMessage)
      this._emit("finalMessage", finalMessage);
    const finalContent = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalContent).call(this);
    if (finalContent)
      this._emit("finalContent", finalContent);
    const finalFunctionCall = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalFunctionToolCall).call(this);
    if (finalFunctionCall)
      this._emit("finalFunctionToolCall", finalFunctionCall);
    const finalFunctionCallResult = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalFunctionToolCallResult).call(this);
    if (finalFunctionCallResult != null)
      this._emit("finalFunctionToolCallResult", finalFunctionCallResult);
    if (this._chatCompletions.some((c) => c.usage)) {
      this._emit("totalUsage", __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_calculateTotalUsage).call(this));
    }
  }
  async _createChatCompletion(client, params, options) {
    const signal = options?.signal;
    if (signal) {
      if (signal.aborted)
        this.controller.abort();
      signal.addEventListener("abort", () => this.controller.abort());
    }
    __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_validateParams).call(this, params);
    const chatCompletion = await client.chat.completions.create({ ...params, stream: false }, { ...options, signal: this.controller.signal });
    this._connected();
    return this._addChatCompletion(parseChatCompletion(chatCompletion, params));
  }
  async _runChatCompletion(client, params, options) {
    for (const message of params.messages) {
      this._addMessage(message, false);
    }
    return await this._createChatCompletion(client, params, options);
  }
  async _runTools(client, params, options) {
    const role = "tool";
    const { tool_choice = "auto", stream, ...restParams } = params;
    const singleFunctionToCall = typeof tool_choice !== "string" && tool_choice.type === "function" && tool_choice?.function?.name;
    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};
    const inputTools = params.tools.map((tool2) => {
      if (isAutoParsableTool(tool2)) {
        if (!tool2.$callback) {
          throw new OpenAIError("Tool given to `.runTools()` that does not have an associated function");
        }
        return {
          type: "function",
          function: {
            function: tool2.$callback,
            name: tool2.function.name,
            description: tool2.function.description || "",
            parameters: tool2.function.parameters,
            parse: tool2.$parseRaw,
            strict: true
          }
        };
      }
      return tool2;
    });
    const functionsByName = {};
    for (const f of inputTools) {
      if (f.type === "function") {
        functionsByName[f.function.name || f.function.function.name] = f.function;
      }
    }
    const tools2 = "tools" in params ? inputTools.map((t) => t.type === "function" ? {
      type: "function",
      function: {
        name: t.function.name || t.function.function.name,
        parameters: t.function.parameters,
        description: t.function.description,
        strict: t.function.strict
      }
    } : t) : void 0;
    for (const message of params.messages) {
      this._addMessage(message, false);
    }
    for (let i = 0; i < maxChatCompletions; ++i) {
      const chatCompletion = await this._createChatCompletion(client, {
        ...restParams,
        tool_choice,
        tools: tools2,
        messages: [...this.messages]
      }, options);
      const message = chatCompletion.choices[0]?.message;
      if (!message) {
        throw new OpenAIError(`missing message in ChatCompletion response`);
      }
      if (!message.tool_calls?.length) {
        return;
      }
      for (const tool_call of message.tool_calls) {
        if (tool_call.type !== "function")
          continue;
        const tool_call_id = tool_call.id;
        const { name, arguments: args } = tool_call.function;
        const fn = functionsByName[name];
        if (!fn) {
          const content2 = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${Object.keys(functionsByName).map((name2) => JSON.stringify(name2)).join(", ")}. Please try again`;
          this._addMessage({ role, tool_call_id, content: content2 });
          continue;
        } else if (singleFunctionToCall && singleFunctionToCall !== name) {
          const content2 = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(singleFunctionToCall)} requested. Please try again`;
          this._addMessage({ role, tool_call_id, content: content2 });
          continue;
        }
        let parsed;
        try {
          parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;
        } catch (error) {
          const content2 = error instanceof Error ? error.message : String(error);
          this._addMessage({ role, tool_call_id, content: content2 });
          continue;
        }
        const rawContent = await fn.function(parsed, this);
        const content = __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_stringifyFunctionCallResult).call(this, rawContent);
        this._addMessage({ role, tool_call_id, content });
        if (singleFunctionToCall) {
          return;
        }
      }
    }
    return;
  }
};
_AbstractChatCompletionRunner_instances = /* @__PURE__ */ new WeakSet(), _AbstractChatCompletionRunner_getFinalContent = function _AbstractChatCompletionRunner_getFinalContent2() {
  return __classPrivateFieldGet(this, _AbstractChatCompletionRunner_instances, "m", _AbstractChatCompletionRunner_getFinalMessage).call(this).content ?? null;
}, _AbstractChatCompletionRunner_getFinalMessage = function _AbstractChatCompletionRunner_getFinalMessage2() {
  let i = this.messages.length;
  while (i-- > 0) {
    const message = this.messages[i];
    if (isAssistantMessage(message)) {
      const ret = {
        ...message,
        content: message.content ?? null,
        refusal: message.refusal ?? null
      };
      return ret;
    }
  }
  throw new OpenAIError("stream ended without producing a ChatCompletionMessage with role=assistant");
}, _AbstractChatCompletionRunner_getFinalFunctionToolCall = function _AbstractChatCompletionRunner_getFinalFunctionToolCall2() {
  for (let i = this.messages.length - 1; i >= 0; i--) {
    const message = this.messages[i];
    if (isAssistantMessage(message) && message?.tool_calls?.length) {
      return message.tool_calls.filter((x) => x.type === "function").at(-1)?.function;
    }
  }
  return;
}, _AbstractChatCompletionRunner_getFinalFunctionToolCallResult = function _AbstractChatCompletionRunner_getFinalFunctionToolCallResult2() {
  for (let i = this.messages.length - 1; i >= 0; i--) {
    const message = this.messages[i];
    if (isToolMessage(message) && message.content != null && typeof message.content === "string" && this.messages.some((x) => x.role === "assistant" && x.tool_calls?.some((y) => y.type === "function" && y.id === message.tool_call_id))) {
      return message.content;
    }
  }
  return;
}, _AbstractChatCompletionRunner_calculateTotalUsage = function _AbstractChatCompletionRunner_calculateTotalUsage2() {
  const total = {
    completion_tokens: 0,
    prompt_tokens: 0,
    total_tokens: 0
  };
  for (const { usage } of this._chatCompletions) {
    if (usage) {
      total.completion_tokens += usage.completion_tokens;
      total.prompt_tokens += usage.prompt_tokens;
      total.total_tokens += usage.total_tokens;
    }
  }
  return total;
}, _AbstractChatCompletionRunner_validateParams = function _AbstractChatCompletionRunner_validateParams2(params) {
  if (params.n != null && params.n > 1) {
    throw new OpenAIError("ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.");
  }
}, _AbstractChatCompletionRunner_stringifyFunctionCallResult = function _AbstractChatCompletionRunner_stringifyFunctionCallResult2(rawContent) {
  return typeof rawContent === "string" ? rawContent : rawContent === void 0 ? "undefined" : JSON.stringify(rawContent);
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/ChatCompletionRunner.mjs
var ChatCompletionRunner = class _ChatCompletionRunner extends AbstractChatCompletionRunner {
  static runTools(client, params, options) {
    const runner = new _ChatCompletionRunner();
    const opts = {
      ...options,
      headers: { ...options?.headers, "X-Stainless-Helper-Method": "runTools" }
    };
    runner._run(() => runner._runTools(client, params, opts));
    return runner;
  }
  _addMessage(message, emit = true) {
    super._addMessage(message, emit);
    if (isAssistantMessage(message) && message.content) {
      this._emit("content", message.content);
    }
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/partial-json-parser/parser.mjs
var STR = 1;
var NUM = 2;
var ARR = 4;
var OBJ = 8;
var NULL = 16;
var BOOL = 32;
var NAN = 64;
var INFINITY = 128;
var MINUS_INFINITY = 256;
var INF = INFINITY | MINUS_INFINITY;
var SPECIAL = NULL | BOOL | INF | NAN;
var ATOM = STR | NUM | SPECIAL;
var COLLECTION = ARR | OBJ;
var ALL = ATOM | COLLECTION;
var Allow = {
  STR,
  NUM,
  ARR,
  OBJ,
  NULL,
  BOOL,
  NAN,
  INFINITY,
  MINUS_INFINITY,
  INF,
  SPECIAL,
  ATOM,
  COLLECTION,
  ALL
};
var PartialJSON = class extends Error {
};
var MalformedJSON = class extends Error {
};
function parseJSON(jsonString, allowPartial = Allow.ALL) {
  if (typeof jsonString !== "string") {
    throw new TypeError(`expecting str, got ${typeof jsonString}`);
  }
  if (!jsonString.trim()) {
    throw new Error(`${jsonString} is empty`);
  }
  return _parseJSON(jsonString.trim(), allowPartial);
}
var _parseJSON = (jsonString, allow) => {
  const length = jsonString.length;
  let index = 0;
  const markPartialJSON = (msg) => {
    throw new PartialJSON(`${msg} at position ${index}`);
  };
  const throwMalformedError = (msg) => {
    throw new MalformedJSON(`${msg} at position ${index}`);
  };
  const parseAny = () => {
    skipBlank();
    if (index >= length)
      markPartialJSON("Unexpected end of input");
    if (jsonString[index] === '"')
      return parseStr();
    if (jsonString[index] === "{")
      return parseObj();
    if (jsonString[index] === "[")
      return parseArr();
    if (jsonString.substring(index, index + 4) === "null" || Allow.NULL & allow && length - index < 4 && "null".startsWith(jsonString.substring(index))) {
      index += 4;
      return null;
    }
    if (jsonString.substring(index, index + 4) === "true" || Allow.BOOL & allow && length - index < 4 && "true".startsWith(jsonString.substring(index))) {
      index += 4;
      return true;
    }
    if (jsonString.substring(index, index + 5) === "false" || Allow.BOOL & allow && length - index < 5 && "false".startsWith(jsonString.substring(index))) {
      index += 5;
      return false;
    }
    if (jsonString.substring(index, index + 8) === "Infinity" || Allow.INFINITY & allow && length - index < 8 && "Infinity".startsWith(jsonString.substring(index))) {
      index += 8;
      return Infinity;
    }
    if (jsonString.substring(index, index + 9) === "-Infinity" || Allow.MINUS_INFINITY & allow && 1 < length - index && length - index < 9 && "-Infinity".startsWith(jsonString.substring(index))) {
      index += 9;
      return -Infinity;
    }
    if (jsonString.substring(index, index + 3) === "NaN" || Allow.NAN & allow && length - index < 3 && "NaN".startsWith(jsonString.substring(index))) {
      index += 3;
      return NaN;
    }
    return parseNum();
  };
  const parseStr = () => {
    const start = index;
    let escape2 = false;
    index++;
    while (index < length && (jsonString[index] !== '"' || escape2 && jsonString[index - 1] === "\\")) {
      escape2 = jsonString[index] === "\\" ? !escape2 : false;
      index++;
    }
    if (jsonString.charAt(index) == '"') {
      try {
        return JSON.parse(jsonString.substring(start, ++index - Number(escape2)));
      } catch (e) {
        throwMalformedError(String(e));
      }
    } else if (Allow.STR & allow) {
      try {
        return JSON.parse(jsonString.substring(start, index - Number(escape2)) + '"');
      } catch (e) {
        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf("\\")) + '"');
      }
    }
    markPartialJSON("Unterminated string literal");
  };
  const parseObj = () => {
    index++;
    skipBlank();
    const obj = {};
    try {
      while (jsonString[index] !== "}") {
        skipBlank();
        if (index >= length && Allow.OBJ & allow)
          return obj;
        const key = parseStr();
        skipBlank();
        index++;
        try {
          const value = parseAny();
          Object.defineProperty(obj, key, { value, writable: true, enumerable: true, configurable: true });
        } catch (e) {
          if (Allow.OBJ & allow)
            return obj;
          else
            throw e;
        }
        skipBlank();
        if (jsonString[index] === ",")
          index++;
      }
    } catch (e) {
      if (Allow.OBJ & allow)
        return obj;
      else
        markPartialJSON("Expected '}' at end of object");
    }
    index++;
    return obj;
  };
  const parseArr = () => {
    index++;
    const arr = [];
    try {
      while (jsonString[index] !== "]") {
        arr.push(parseAny());
        skipBlank();
        if (jsonString[index] === ",") {
          index++;
        }
      }
    } catch (e) {
      if (Allow.ARR & allow) {
        return arr;
      }
      markPartialJSON("Expected ']' at end of array");
    }
    index++;
    return arr;
  };
  const parseNum = () => {
    if (index === 0) {
      if (jsonString === "-" && Allow.NUM & allow)
        markPartialJSON("Not sure what '-' is");
      try {
        return JSON.parse(jsonString);
      } catch (e) {
        if (Allow.NUM & allow) {
          try {
            if ("." === jsonString[jsonString.length - 1])
              return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf(".")));
            return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf("e")));
          } catch (e2) {
          }
        }
        throwMalformedError(String(e));
      }
    }
    const start = index;
    if (jsonString[index] === "-")
      index++;
    while (jsonString[index] && !",]}".includes(jsonString[index]))
      index++;
    if (index == length && !(Allow.NUM & allow))
      markPartialJSON("Unterminated number literal");
    try {
      return JSON.parse(jsonString.substring(start, index));
    } catch (e) {
      if (jsonString.substring(start, index) === "-" && Allow.NUM & allow)
        markPartialJSON("Not sure what '-' is");
      try {
        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf("e")));
      } catch (e2) {
        throwMalformedError(String(e2));
      }
    }
  };
  const skipBlank = () => {
    while (index < length && " \n\r	".includes(jsonString[index])) {
      index++;
    }
  };
  return parseAny();
};
var partialParse = (input) => parseJSON(input, Allow.ALL ^ Allow.NUM);

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/ChatCompletionStream.mjs
var _ChatCompletionStream_instances;
var _ChatCompletionStream_params;
var _ChatCompletionStream_choiceEventStates;
var _ChatCompletionStream_currentChatCompletionSnapshot;
var _ChatCompletionStream_beginRequest;
var _ChatCompletionStream_getChoiceEventState;
var _ChatCompletionStream_addChunk;
var _ChatCompletionStream_emitToolCallDoneEvent;
var _ChatCompletionStream_emitContentDoneEvents;
var _ChatCompletionStream_endRequest;
var _ChatCompletionStream_getAutoParseableResponseFormat;
var _ChatCompletionStream_accumulateChatCompletion;
var ChatCompletionStream = class _ChatCompletionStream extends AbstractChatCompletionRunner {
  constructor(params) {
    super();
    _ChatCompletionStream_instances.add(this);
    _ChatCompletionStream_params.set(this, void 0);
    _ChatCompletionStream_choiceEventStates.set(this, void 0);
    _ChatCompletionStream_currentChatCompletionSnapshot.set(this, void 0);
    __classPrivateFieldSet(this, _ChatCompletionStream_params, params, "f");
    __classPrivateFieldSet(this, _ChatCompletionStream_choiceEventStates, [], "f");
  }
  get currentChatCompletionSnapshot() {
    return __classPrivateFieldGet(this, _ChatCompletionStream_currentChatCompletionSnapshot, "f");
  }
  /**
   * Intended for use on the frontend, consuming a stream produced with
   * `.toReadableStream()` on the backend.
   *
   * Note that messages sent to the model do not appear in `.on('message')`
   * in this context.
   */
  static fromReadableStream(stream) {
    const runner = new _ChatCompletionStream(null);
    runner._run(() => runner._fromReadableStream(stream));
    return runner;
  }
  static createChatCompletion(client, params, options) {
    const runner = new _ChatCompletionStream(params);
    runner._run(() => runner._runChatCompletion(client, { ...params, stream: true }, { ...options, headers: { ...options?.headers, "X-Stainless-Helper-Method": "stream" } }));
    return runner;
  }
  async _createChatCompletion(client, params, options) {
    super._createChatCompletion;
    const signal = options?.signal;
    if (signal) {
      if (signal.aborted)
        this.controller.abort();
      signal.addEventListener("abort", () => this.controller.abort());
    }
    __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_beginRequest).call(this);
    const stream = await client.chat.completions.create({ ...params, stream: true }, { ...options, signal: this.controller.signal });
    this._connected();
    for await (const chunk of stream) {
      __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_addChunk).call(this, chunk);
    }
    if (stream.controller.signal?.aborted) {
      throw new APIUserAbortError();
    }
    return this._addChatCompletion(__classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_endRequest).call(this));
  }
  async _fromReadableStream(readableStream, options) {
    const signal = options?.signal;
    if (signal) {
      if (signal.aborted)
        this.controller.abort();
      signal.addEventListener("abort", () => this.controller.abort());
    }
    __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_beginRequest).call(this);
    this._connected();
    const stream = Stream.fromReadableStream(readableStream, this.controller);
    let chatId;
    for await (const chunk of stream) {
      if (chatId && chatId !== chunk.id) {
        this._addChatCompletion(__classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_endRequest).call(this));
      }
      __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_addChunk).call(this, chunk);
      chatId = chunk.id;
    }
    if (stream.controller.signal?.aborted) {
      throw new APIUserAbortError();
    }
    return this._addChatCompletion(__classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_endRequest).call(this));
  }
  [(_ChatCompletionStream_params = /* @__PURE__ */ new WeakMap(), _ChatCompletionStream_choiceEventStates = /* @__PURE__ */ new WeakMap(), _ChatCompletionStream_currentChatCompletionSnapshot = /* @__PURE__ */ new WeakMap(), _ChatCompletionStream_instances = /* @__PURE__ */ new WeakSet(), _ChatCompletionStream_beginRequest = function _ChatCompletionStream_beginRequest2() {
    if (this.ended)
      return;
    __classPrivateFieldSet(this, _ChatCompletionStream_currentChatCompletionSnapshot, void 0, "f");
  }, _ChatCompletionStream_getChoiceEventState = function _ChatCompletionStream_getChoiceEventState2(choice) {
    let state = __classPrivateFieldGet(this, _ChatCompletionStream_choiceEventStates, "f")[choice.index];
    if (state) {
      return state;
    }
    state = {
      content_done: false,
      refusal_done: false,
      logprobs_content_done: false,
      logprobs_refusal_done: false,
      done_tool_calls: /* @__PURE__ */ new Set(),
      current_tool_call_index: null
    };
    __classPrivateFieldGet(this, _ChatCompletionStream_choiceEventStates, "f")[choice.index] = state;
    return state;
  }, _ChatCompletionStream_addChunk = function _ChatCompletionStream_addChunk2(chunk) {
    if (this.ended)
      return;
    const completion = __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_accumulateChatCompletion).call(this, chunk);
    this._emit("chunk", chunk, completion);
    for (const choice of chunk.choices) {
      const choiceSnapshot = completion.choices[choice.index];
      if (choice.delta.content != null && choiceSnapshot.message?.role === "assistant" && choiceSnapshot.message?.content) {
        this._emit("content", choice.delta.content, choiceSnapshot.message.content);
        this._emit("content.delta", {
          delta: choice.delta.content,
          snapshot: choiceSnapshot.message.content,
          parsed: choiceSnapshot.message.parsed
        });
      }
      if (choice.delta.refusal != null && choiceSnapshot.message?.role === "assistant" && choiceSnapshot.message?.refusal) {
        this._emit("refusal.delta", {
          delta: choice.delta.refusal,
          snapshot: choiceSnapshot.message.refusal
        });
      }
      if (choice.logprobs?.content != null && choiceSnapshot.message?.role === "assistant") {
        this._emit("logprobs.content.delta", {
          content: choice.logprobs?.content,
          snapshot: choiceSnapshot.logprobs?.content ?? []
        });
      }
      if (choice.logprobs?.refusal != null && choiceSnapshot.message?.role === "assistant") {
        this._emit("logprobs.refusal.delta", {
          refusal: choice.logprobs?.refusal,
          snapshot: choiceSnapshot.logprobs?.refusal ?? []
        });
      }
      const state = __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_getChoiceEventState).call(this, choiceSnapshot);
      if (choiceSnapshot.finish_reason) {
        __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_emitContentDoneEvents).call(this, choiceSnapshot);
        if (state.current_tool_call_index != null) {
          __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_emitToolCallDoneEvent).call(this, choiceSnapshot, state.current_tool_call_index);
        }
      }
      for (const toolCall of choice.delta.tool_calls ?? []) {
        if (state.current_tool_call_index !== toolCall.index) {
          __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_emitContentDoneEvents).call(this, choiceSnapshot);
          if (state.current_tool_call_index != null) {
            __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_emitToolCallDoneEvent).call(this, choiceSnapshot, state.current_tool_call_index);
          }
        }
        state.current_tool_call_index = toolCall.index;
      }
      for (const toolCallDelta of choice.delta.tool_calls ?? []) {
        const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallDelta.index];
        if (!toolCallSnapshot?.type) {
          continue;
        }
        if (toolCallSnapshot?.type === "function") {
          this._emit("tool_calls.function.arguments.delta", {
            name: toolCallSnapshot.function?.name,
            index: toolCallDelta.index,
            arguments: toolCallSnapshot.function.arguments,
            parsed_arguments: toolCallSnapshot.function.parsed_arguments,
            arguments_delta: toolCallDelta.function?.arguments ?? ""
          });
        } else {
          assertNever(toolCallSnapshot?.type);
        }
      }
    }
  }, _ChatCompletionStream_emitToolCallDoneEvent = function _ChatCompletionStream_emitToolCallDoneEvent2(choiceSnapshot, toolCallIndex) {
    const state = __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_getChoiceEventState).call(this, choiceSnapshot);
    if (state.done_tool_calls.has(toolCallIndex)) {
      return;
    }
    const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallIndex];
    if (!toolCallSnapshot) {
      throw new Error("no tool call snapshot");
    }
    if (!toolCallSnapshot.type) {
      throw new Error("tool call snapshot missing `type`");
    }
    if (toolCallSnapshot.type === "function") {
      const inputTool = __classPrivateFieldGet(this, _ChatCompletionStream_params, "f")?.tools?.find((tool2) => isChatCompletionFunctionTool(tool2) && tool2.function.name === toolCallSnapshot.function.name);
      this._emit("tool_calls.function.arguments.done", {
        name: toolCallSnapshot.function.name,
        index: toolCallIndex,
        arguments: toolCallSnapshot.function.arguments,
        parsed_arguments: isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCallSnapshot.function.arguments) : inputTool?.function.strict ? JSON.parse(toolCallSnapshot.function.arguments) : null
      });
    } else {
      assertNever(toolCallSnapshot.type);
    }
  }, _ChatCompletionStream_emitContentDoneEvents = function _ChatCompletionStream_emitContentDoneEvents2(choiceSnapshot) {
    const state = __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_getChoiceEventState).call(this, choiceSnapshot);
    if (choiceSnapshot.message.content && !state.content_done) {
      state.content_done = true;
      const responseFormat = __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_getAutoParseableResponseFormat).call(this);
      this._emit("content.done", {
        content: choiceSnapshot.message.content,
        parsed: responseFormat ? responseFormat.$parseRaw(choiceSnapshot.message.content) : null
      });
    }
    if (choiceSnapshot.message.refusal && !state.refusal_done) {
      state.refusal_done = true;
      this._emit("refusal.done", { refusal: choiceSnapshot.message.refusal });
    }
    if (choiceSnapshot.logprobs?.content && !state.logprobs_content_done) {
      state.logprobs_content_done = true;
      this._emit("logprobs.content.done", { content: choiceSnapshot.logprobs.content });
    }
    if (choiceSnapshot.logprobs?.refusal && !state.logprobs_refusal_done) {
      state.logprobs_refusal_done = true;
      this._emit("logprobs.refusal.done", { refusal: choiceSnapshot.logprobs.refusal });
    }
  }, _ChatCompletionStream_endRequest = function _ChatCompletionStream_endRequest2() {
    if (this.ended) {
      throw new OpenAIError(`stream has ended, this shouldn't happen`);
    }
    const snapshot = __classPrivateFieldGet(this, _ChatCompletionStream_currentChatCompletionSnapshot, "f");
    if (!snapshot) {
      throw new OpenAIError(`request ended without sending any chunks`);
    }
    __classPrivateFieldSet(this, _ChatCompletionStream_currentChatCompletionSnapshot, void 0, "f");
    __classPrivateFieldSet(this, _ChatCompletionStream_choiceEventStates, [], "f");
    return finalizeChatCompletion(snapshot, __classPrivateFieldGet(this, _ChatCompletionStream_params, "f"));
  }, _ChatCompletionStream_getAutoParseableResponseFormat = function _ChatCompletionStream_getAutoParseableResponseFormat2() {
    const responseFormat = __classPrivateFieldGet(this, _ChatCompletionStream_params, "f")?.response_format;
    if (isAutoParsableResponseFormat(responseFormat)) {
      return responseFormat;
    }
    return null;
  }, _ChatCompletionStream_accumulateChatCompletion = function _ChatCompletionStream_accumulateChatCompletion2(chunk) {
    var _a3, _b, _c, _d;
    let snapshot = __classPrivateFieldGet(this, _ChatCompletionStream_currentChatCompletionSnapshot, "f");
    const { choices, ...rest } = chunk;
    if (!snapshot) {
      snapshot = __classPrivateFieldSet(this, _ChatCompletionStream_currentChatCompletionSnapshot, {
        ...rest,
        choices: []
      }, "f");
    } else {
      Object.assign(snapshot, rest);
    }
    for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {
      let choice = snapshot.choices[index];
      if (!choice) {
        choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };
      }
      if (logprobs) {
        if (!choice.logprobs) {
          choice.logprobs = Object.assign({}, logprobs);
        } else {
          const { content: content2, refusal: refusal2, ...rest3 } = logprobs;
          assertIsEmpty(rest3);
          Object.assign(choice.logprobs, rest3);
          if (content2) {
            (_a3 = choice.logprobs).content ?? (_a3.content = []);
            choice.logprobs.content.push(...content2);
          }
          if (refusal2) {
            (_b = choice.logprobs).refusal ?? (_b.refusal = []);
            choice.logprobs.refusal.push(...refusal2);
          }
        }
      }
      if (finish_reason) {
        choice.finish_reason = finish_reason;
        if (__classPrivateFieldGet(this, _ChatCompletionStream_params, "f") && hasAutoParseableInput(__classPrivateFieldGet(this, _ChatCompletionStream_params, "f"))) {
          if (finish_reason === "length") {
            throw new LengthFinishReasonError();
          }
          if (finish_reason === "content_filter") {
            throw new ContentFilterFinishReasonError();
          }
        }
      }
      Object.assign(choice, other);
      if (!delta)
        continue;
      const { content, refusal, function_call, role, tool_calls, ...rest2 } = delta;
      assertIsEmpty(rest2);
      Object.assign(choice.message, rest2);
      if (refusal) {
        choice.message.refusal = (choice.message.refusal || "") + refusal;
      }
      if (role)
        choice.message.role = role;
      if (function_call) {
        if (!choice.message.function_call) {
          choice.message.function_call = function_call;
        } else {
          if (function_call.name)
            choice.message.function_call.name = function_call.name;
          if (function_call.arguments) {
            (_c = choice.message.function_call).arguments ?? (_c.arguments = "");
            choice.message.function_call.arguments += function_call.arguments;
          }
        }
      }
      if (content) {
        choice.message.content = (choice.message.content || "") + content;
        if (!choice.message.refusal && __classPrivateFieldGet(this, _ChatCompletionStream_instances, "m", _ChatCompletionStream_getAutoParseableResponseFormat).call(this)) {
          choice.message.parsed = partialParse(choice.message.content);
        }
      }
      if (tool_calls) {
        if (!choice.message.tool_calls)
          choice.message.tool_calls = [];
        for (const { index: index2, id, type, function: fn, ...rest3 } of tool_calls) {
          const tool_call = (_d = choice.message.tool_calls)[index2] ?? (_d[index2] = {});
          Object.assign(tool_call, rest3);
          if (id)
            tool_call.id = id;
          if (type)
            tool_call.type = type;
          if (fn)
            tool_call.function ?? (tool_call.function = { name: fn.name ?? "", arguments: "" });
          if (fn?.name)
            tool_call.function.name = fn.name;
          if (fn?.arguments) {
            tool_call.function.arguments += fn.arguments;
            if (shouldParseToolCall(__classPrivateFieldGet(this, _ChatCompletionStream_params, "f"), tool_call)) {
              tool_call.function.parsed_arguments = partialParse(tool_call.function.arguments);
            }
          }
        }
      }
    }
    return snapshot;
  }, Symbol.asyncIterator)]() {
    const pushQueue = [];
    const readQueue = [];
    let done = false;
    this.on("chunk", (chunk) => {
      const reader = readQueue.shift();
      if (reader) {
        reader.resolve(chunk);
      } else {
        pushQueue.push(chunk);
      }
    });
    this.on("end", () => {
      done = true;
      for (const reader of readQueue) {
        reader.resolve(void 0);
      }
      readQueue.length = 0;
    });
    this.on("abort", (err) => {
      done = true;
      for (const reader of readQueue) {
        reader.reject(err);
      }
      readQueue.length = 0;
    });
    this.on("error", (err) => {
      done = true;
      for (const reader of readQueue) {
        reader.reject(err);
      }
      readQueue.length = 0;
    });
    return {
      next: async () => {
        if (!pushQueue.length) {
          if (done) {
            return { value: void 0, done: true };
          }
          return new Promise((resolve, reject) => readQueue.push({ resolve, reject })).then((chunk2) => chunk2 ? { value: chunk2, done: false } : { value: void 0, done: true });
        }
        const chunk = pushQueue.shift();
        return { value: chunk, done: false };
      },
      return: async () => {
        this.abort();
        return { value: void 0, done: true };
      }
    };
  }
  toReadableStream() {
    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);
    return stream.toReadableStream();
  }
};
function finalizeChatCompletion(snapshot, params) {
  const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;
  const completion = {
    ...rest,
    id,
    choices: choices.map(({ message, finish_reason, index, logprobs, ...choiceRest }) => {
      if (!finish_reason) {
        throw new OpenAIError(`missing finish_reason for choice ${index}`);
      }
      const { content = null, function_call, tool_calls, ...messageRest } = message;
      const role = message.role;
      if (!role) {
        throw new OpenAIError(`missing role for choice ${index}`);
      }
      if (function_call) {
        const { arguments: args, name } = function_call;
        if (args == null) {
          throw new OpenAIError(`missing function_call.arguments for choice ${index}`);
        }
        if (!name) {
          throw new OpenAIError(`missing function_call.name for choice ${index}`);
        }
        return {
          ...choiceRest,
          message: {
            content,
            function_call: { arguments: args, name },
            role,
            refusal: message.refusal ?? null
          },
          finish_reason,
          index,
          logprobs
        };
      }
      if (tool_calls) {
        return {
          ...choiceRest,
          index,
          finish_reason,
          logprobs,
          message: {
            ...messageRest,
            role,
            content,
            refusal: message.refusal ?? null,
            tool_calls: tool_calls.map((tool_call, i) => {
              const { function: fn, type, id: id2, ...toolRest } = tool_call;
              const { arguments: args, name, ...fnRest } = fn || {};
              if (id2 == null) {
                throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].id
${str(snapshot)}`);
              }
              if (type == null) {
                throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].type
${str(snapshot)}`);
              }
              if (name == null) {
                throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].function.name
${str(snapshot)}`);
              }
              if (args == null) {
                throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].function.arguments
${str(snapshot)}`);
              }
              return { ...toolRest, id: id2, type, function: { ...fnRest, name, arguments: args } };
            })
          }
        };
      }
      return {
        ...choiceRest,
        message: { ...messageRest, content, role, refusal: message.refusal ?? null },
        finish_reason,
        index,
        logprobs
      };
    }),
    created,
    model,
    object: "chat.completion",
    ...system_fingerprint ? { system_fingerprint } : {}
  };
  return maybeParseChatCompletion(completion, params);
}
function str(x) {
  return JSON.stringify(x);
}
function assertIsEmpty(obj) {
  return;
}
function assertNever(_x) {
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/ChatCompletionStreamingRunner.mjs
var ChatCompletionStreamingRunner = class _ChatCompletionStreamingRunner extends ChatCompletionStream {
  static fromReadableStream(stream) {
    const runner = new _ChatCompletionStreamingRunner(null);
    runner._run(() => runner._fromReadableStream(stream));
    return runner;
  }
  static runTools(client, params, options) {
    const runner = new _ChatCompletionStreamingRunner(
      // @ts-expect-error TODO these types are incompatible
      params
    );
    const opts = {
      ...options,
      headers: { ...options?.headers, "X-Stainless-Helper-Method": "runTools" }
    };
    runner._run(() => runner._runTools(client, params, opts));
    return runner;
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/chat/completions/completions.mjs
var Completions = class extends APIResource {
  constructor() {
    super(...arguments);
    this.messages = new Messages(this._client);
  }
  create(body, options) {
    return this._client.post("/chat/completions", { body, ...options, stream: body.stream ?? false });
  }
  /**
   * Get a stored chat completion. Only Chat Completions that have been created with
   * the `store` parameter set to `true` will be returned.
   *
   * @example
   * ```ts
   * const chatCompletion =
   *   await client.chat.completions.retrieve('completion_id');
   * ```
   */
  retrieve(completionID, options) {
    return this._client.get(path`/chat/completions/${completionID}`, options);
  }
  /**
   * Modify a stored chat completion. Only Chat Completions that have been created
   * with the `store` parameter set to `true` can be modified. Currently, the only
   * supported modification is to update the `metadata` field.
   *
   * @example
   * ```ts
   * const chatCompletion = await client.chat.completions.update(
   *   'completion_id',
   *   { metadata: { foo: 'string' } },
   * );
   * ```
   */
  update(completionID, body, options) {
    return this._client.post(path`/chat/completions/${completionID}`, { body, ...options });
  }
  /**
   * List stored Chat Completions. Only Chat Completions that have been stored with
   * the `store` parameter set to `true` will be returned.
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const chatCompletion of client.chat.completions.list()) {
   *   // ...
   * }
   * ```
   */
  list(query = {}, options) {
    return this._client.getAPIList("/chat/completions", CursorPage, { query, ...options });
  }
  /**
   * Delete a stored chat completion. Only Chat Completions that have been created
   * with the `store` parameter set to `true` can be deleted.
   *
   * @example
   * ```ts
   * const chatCompletionDeleted =
   *   await client.chat.completions.delete('completion_id');
   * ```
   */
  delete(completionID, options) {
    return this._client.delete(path`/chat/completions/${completionID}`, options);
  }
  parse(body, options) {
    validateInputTools(body.tools);
    return this._client.chat.completions.create(body, {
      ...options,
      headers: {
        ...options?.headers,
        "X-Stainless-Helper-Method": "chat.completions.parse"
      }
    })._thenUnwrap((completion) => parseChatCompletion(completion, body));
  }
  runTools(body, options) {
    if (body.stream) {
      return ChatCompletionStreamingRunner.runTools(this._client, body, options);
    }
    return ChatCompletionRunner.runTools(this._client, body, options);
  }
  /**
   * Creates a chat completion stream
   */
  stream(body, options) {
    return ChatCompletionStream.createChatCompletion(this._client, body, options);
  }
};
Completions.Messages = Messages;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/chat/chat.mjs
var Chat = class extends APIResource {
  constructor() {
    super(...arguments);
    this.completions = new Completions(this._client);
  }
};
Chat.Completions = Completions;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/headers.mjs
var brand_privateNullableHeaders = /* @__PURE__ */ Symbol("brand.privateNullableHeaders");
function* iterateHeaders(headers) {
  if (!headers)
    return;
  if (brand_privateNullableHeaders in headers) {
    const { values, nulls } = headers;
    yield* values.entries();
    for (const name of nulls) {
      yield [name, null];
    }
    return;
  }
  let shouldClear = false;
  let iter;
  if (headers instanceof Headers) {
    iter = headers.entries();
  } else if (isReadonlyArray(headers)) {
    iter = headers;
  } else {
    shouldClear = true;
    iter = Object.entries(headers ?? {});
  }
  for (let row of iter) {
    const name = row[0];
    if (typeof name !== "string")
      throw new TypeError("expected header name to be a string");
    const values = isReadonlyArray(row[1]) ? row[1] : [row[1]];
    let didClear = false;
    for (const value of values) {
      if (value === void 0)
        continue;
      if (shouldClear && !didClear) {
        didClear = true;
        yield [name, null];
      }
      yield [name, value];
    }
  }
}
var buildHeaders = (newHeaders) => {
  const targetHeaders = new Headers();
  const nullHeaders = /* @__PURE__ */ new Set();
  for (const headers of newHeaders) {
    const seenHeaders = /* @__PURE__ */ new Set();
    for (const [name, value] of iterateHeaders(headers)) {
      const lowerName = name.toLowerCase();
      if (!seenHeaders.has(lowerName)) {
        targetHeaders.delete(name);
        seenHeaders.add(lowerName);
      }
      if (value === null) {
        targetHeaders.delete(name);
        nullHeaders.add(lowerName);
      } else {
        targetHeaders.append(name, value);
        nullHeaders.delete(lowerName);
      }
    }
  }
  return { [brand_privateNullableHeaders]: true, values: targetHeaders, nulls: nullHeaders };
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/audio/speech.mjs
var Speech = class extends APIResource {
  /**
   * Generates audio from the input text.
   *
   * Returns the audio file content, or a stream of audio events.
   *
   * @example
   * ```ts
   * const speech = await client.audio.speech.create({
   *   input: 'input',
   *   model: 'string',
   *   voice: 'ash',
   * });
   *
   * const content = await speech.blob();
   * console.log(content);
   * ```
   */
  create(body, options) {
    return this._client.post("/audio/speech", {
      body,
      ...options,
      headers: buildHeaders([{ Accept: "application/octet-stream" }, options?.headers]),
      __binaryResponse: true
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/audio/transcriptions.mjs
var Transcriptions = class extends APIResource {
  create(body, options) {
    return this._client.post("/audio/transcriptions", multipartFormRequestOptions({
      body,
      ...options,
      stream: body.stream ?? false,
      __metadata: { model: body.model }
    }, this._client));
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/audio/translations.mjs
var Translations = class extends APIResource {
  create(body, options) {
    return this._client.post("/audio/translations", multipartFormRequestOptions({ body, ...options, __metadata: { model: body.model } }, this._client));
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/audio/audio.mjs
var Audio = class extends APIResource {
  constructor() {
    super(...arguments);
    this.transcriptions = new Transcriptions(this._client);
    this.translations = new Translations(this._client);
    this.speech = new Speech(this._client);
  }
};
Audio.Transcriptions = Transcriptions;
Audio.Translations = Translations;
Audio.Speech = Speech;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/batches.mjs
var Batches = class extends APIResource {
  /**
   * Creates and executes a batch from an uploaded file of requests
   */
  create(body, options) {
    return this._client.post("/batches", { body, ...options });
  }
  /**
   * Retrieves a batch.
   */
  retrieve(batchID, options) {
    return this._client.get(path`/batches/${batchID}`, options);
  }
  /**
   * List your organization's batches.
   */
  list(query = {}, options) {
    return this._client.getAPIList("/batches", CursorPage, { query, ...options });
  }
  /**
   * Cancels an in-progress batch. The batch will be in status `cancelling` for up to
   * 10 minutes, before changing to `cancelled`, where it will have partial results
   * (if any) available in the output file.
   */
  cancel(batchID, options) {
    return this._client.post(path`/batches/${batchID}/cancel`, options);
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/assistants.mjs
var Assistants = class extends APIResource {
  /**
   * Create an assistant with a model and instructions.
   *
   * @deprecated
   */
  create(body, options) {
    return this._client.post("/assistants", {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Retrieves an assistant.
   *
   * @deprecated
   */
  retrieve(assistantID, options) {
    return this._client.get(path`/assistants/${assistantID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Modifies an assistant.
   *
   * @deprecated
   */
  update(assistantID, body, options) {
    return this._client.post(path`/assistants/${assistantID}`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Returns a list of assistants.
   *
   * @deprecated
   */
  list(query = {}, options) {
    return this._client.getAPIList("/assistants", CursorPage, {
      query,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Delete an assistant.
   *
   * @deprecated
   */
  delete(assistantID, options) {
    return this._client.delete(path`/assistants/${assistantID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/realtime/sessions.mjs
var Sessions = class extends APIResource {
  /**
   * Create an ephemeral API token for use in client-side applications with the
   * Realtime API. Can be configured with the same session parameters as the
   * `session.update` client event.
   *
   * It responds with a session object, plus a `client_secret` key which contains a
   * usable ephemeral API token that can be used to authenticate browser clients for
   * the Realtime API.
   *
   * @example
   * ```ts
   * const session =
   *   await client.beta.realtime.sessions.create();
   * ```
   */
  create(body, options) {
    return this._client.post("/realtime/sessions", {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/realtime/transcription-sessions.mjs
var TranscriptionSessions = class extends APIResource {
  /**
   * Create an ephemeral API token for use in client-side applications with the
   * Realtime API specifically for realtime transcriptions. Can be configured with
   * the same session parameters as the `transcription_session.update` client event.
   *
   * It responds with a session object, plus a `client_secret` key which contains a
   * usable ephemeral API token that can be used to authenticate browser clients for
   * the Realtime API.
   *
   * @example
   * ```ts
   * const transcriptionSession =
   *   await client.beta.realtime.transcriptionSessions.create();
   * ```
   */
  create(body, options) {
    return this._client.post("/realtime/transcription_sessions", {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/realtime/realtime.mjs
var Realtime = class extends APIResource {
  constructor() {
    super(...arguments);
    this.sessions = new Sessions(this._client);
    this.transcriptionSessions = new TranscriptionSessions(this._client);
  }
};
Realtime.Sessions = Sessions;
Realtime.TranscriptionSessions = TranscriptionSessions;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/chatkit/sessions.mjs
var Sessions2 = class extends APIResource {
  /**
   * Create a ChatKit session.
   *
   * @example
   * ```ts
   * const chatSession =
   *   await client.beta.chatkit.sessions.create({
   *     user: 'x',
   *     workflow: { id: 'id' },
   *   });
   * ```
   */
  create(body, options) {
    return this._client.post("/chatkit/sessions", {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "chatkit_beta=v1" }, options?.headers])
    });
  }
  /**
   * Cancel an active ChatKit session and return its most recent metadata.
   *
   * Cancelling prevents new requests from using the issued client secret.
   *
   * @example
   * ```ts
   * const chatSession =
   *   await client.beta.chatkit.sessions.cancel('cksess_123');
   * ```
   */
  cancel(sessionID, options) {
    return this._client.post(path`/chatkit/sessions/${sessionID}/cancel`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "chatkit_beta=v1" }, options?.headers])
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/chatkit/threads.mjs
var Threads = class extends APIResource {
  /**
   * Retrieve a ChatKit thread by its identifier.
   *
   * @example
   * ```ts
   * const chatkitThread =
   *   await client.beta.chatkit.threads.retrieve('cthr_123');
   * ```
   */
  retrieve(threadID, options) {
    return this._client.get(path`/chatkit/threads/${threadID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "chatkit_beta=v1" }, options?.headers])
    });
  }
  /**
   * List ChatKit threads with optional pagination and user filters.
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const chatkitThread of client.beta.chatkit.threads.list()) {
   *   // ...
   * }
   * ```
   */
  list(query = {}, options) {
    return this._client.getAPIList("/chatkit/threads", ConversationCursorPage, {
      query,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "chatkit_beta=v1" }, options?.headers])
    });
  }
  /**
   * Delete a ChatKit thread along with its items and stored attachments.
   *
   * @example
   * ```ts
   * const thread = await client.beta.chatkit.threads.delete(
   *   'cthr_123',
   * );
   * ```
   */
  delete(threadID, options) {
    return this._client.delete(path`/chatkit/threads/${threadID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "chatkit_beta=v1" }, options?.headers])
    });
  }
  /**
   * List items that belong to a ChatKit thread.
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const thread of client.beta.chatkit.threads.listItems(
   *   'cthr_123',
   * )) {
   *   // ...
   * }
   * ```
   */
  listItems(threadID, query = {}, options) {
    return this._client.getAPIList(path`/chatkit/threads/${threadID}/items`, ConversationCursorPage, { query, ...options, headers: buildHeaders([{ "OpenAI-Beta": "chatkit_beta=v1" }, options?.headers]) });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/chatkit/chatkit.mjs
var ChatKit = class extends APIResource {
  constructor() {
    super(...arguments);
    this.sessions = new Sessions2(this._client);
    this.threads = new Threads(this._client);
  }
};
ChatKit.Sessions = Sessions2;
ChatKit.Threads = Threads;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/threads/messages.mjs
var Messages2 = class extends APIResource {
  /**
   * Create a message.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  create(threadID, body, options) {
    return this._client.post(path`/threads/${threadID}/messages`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Retrieve a message.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  retrieve(messageID, params, options) {
    const { thread_id } = params;
    return this._client.get(path`/threads/${thread_id}/messages/${messageID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Modifies a message.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  update(messageID, params, options) {
    const { thread_id, ...body } = params;
    return this._client.post(path`/threads/${thread_id}/messages/${messageID}`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Returns a list of messages for a given thread.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  list(threadID, query = {}, options) {
    return this._client.getAPIList(path`/threads/${threadID}/messages`, CursorPage, {
      query,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Deletes a message.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  delete(messageID, params, options) {
    const { thread_id } = params;
    return this._client.delete(path`/threads/${thread_id}/messages/${messageID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/threads/runs/steps.mjs
var Steps = class extends APIResource {
  /**
   * Retrieves a run step.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  retrieve(stepID, params, options) {
    const { thread_id, run_id, ...query } = params;
    return this._client.get(path`/threads/${thread_id}/runs/${run_id}/steps/${stepID}`, {
      query,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Returns a list of run steps belonging to a run.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  list(runID, params, options) {
    const { thread_id, ...query } = params;
    return this._client.getAPIList(path`/threads/${thread_id}/runs/${runID}/steps`, CursorPage, {
      query,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/utils/base64.mjs
var toFloat32Array = (base64Str) => {
  if (typeof Buffer !== "undefined") {
    const buf = Buffer.from(base64Str, "base64");
    return Array.from(new Float32Array(buf.buffer, buf.byteOffset, buf.length / Float32Array.BYTES_PER_ELEMENT));
  } else {
    const binaryStr = atob(base64Str);
    const len = binaryStr.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
      bytes[i] = binaryStr.charCodeAt(i);
    }
    return Array.from(new Float32Array(bytes.buffer));
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/internal/utils/env.mjs
var readEnv = (env) => {
  if (typeof globalThis.process !== "undefined") {
    return globalThis.process.env?.[env]?.trim() ?? void 0;
  }
  if (typeof globalThis.Deno !== "undefined") {
    return globalThis.Deno.env?.get?.(env)?.trim();
  }
  return void 0;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/AssistantStream.mjs
var _AssistantStream_instances;
var _a;
var _AssistantStream_events;
var _AssistantStream_runStepSnapshots;
var _AssistantStream_messageSnapshots;
var _AssistantStream_messageSnapshot;
var _AssistantStream_finalRun;
var _AssistantStream_currentContentIndex;
var _AssistantStream_currentContent;
var _AssistantStream_currentToolCallIndex;
var _AssistantStream_currentToolCall;
var _AssistantStream_currentEvent;
var _AssistantStream_currentRunSnapshot;
var _AssistantStream_currentRunStepSnapshot;
var _AssistantStream_addEvent;
var _AssistantStream_endRequest;
var _AssistantStream_handleMessage;
var _AssistantStream_handleRunStep;
var _AssistantStream_handleEvent;
var _AssistantStream_accumulateRunStep;
var _AssistantStream_accumulateMessage;
var _AssistantStream_accumulateContent;
var _AssistantStream_handleRun;
var AssistantStream = class extends EventStream {
  constructor() {
    super(...arguments);
    _AssistantStream_instances.add(this);
    _AssistantStream_events.set(this, []);
    _AssistantStream_runStepSnapshots.set(this, {});
    _AssistantStream_messageSnapshots.set(this, {});
    _AssistantStream_messageSnapshot.set(this, void 0);
    _AssistantStream_finalRun.set(this, void 0);
    _AssistantStream_currentContentIndex.set(this, void 0);
    _AssistantStream_currentContent.set(this, void 0);
    _AssistantStream_currentToolCallIndex.set(this, void 0);
    _AssistantStream_currentToolCall.set(this, void 0);
    _AssistantStream_currentEvent.set(this, void 0);
    _AssistantStream_currentRunSnapshot.set(this, void 0);
    _AssistantStream_currentRunStepSnapshot.set(this, void 0);
  }
  [(_AssistantStream_events = /* @__PURE__ */ new WeakMap(), _AssistantStream_runStepSnapshots = /* @__PURE__ */ new WeakMap(), _AssistantStream_messageSnapshots = /* @__PURE__ */ new WeakMap(), _AssistantStream_messageSnapshot = /* @__PURE__ */ new WeakMap(), _AssistantStream_finalRun = /* @__PURE__ */ new WeakMap(), _AssistantStream_currentContentIndex = /* @__PURE__ */ new WeakMap(), _AssistantStream_currentContent = /* @__PURE__ */ new WeakMap(), _AssistantStream_currentToolCallIndex = /* @__PURE__ */ new WeakMap(), _AssistantStream_currentToolCall = /* @__PURE__ */ new WeakMap(), _AssistantStream_currentEvent = /* @__PURE__ */ new WeakMap(), _AssistantStream_currentRunSnapshot = /* @__PURE__ */ new WeakMap(), _AssistantStream_currentRunStepSnapshot = /* @__PURE__ */ new WeakMap(), _AssistantStream_instances = /* @__PURE__ */ new WeakSet(), Symbol.asyncIterator)]() {
    const pushQueue = [];
    const readQueue = [];
    let done = false;
    this.on("event", (event) => {
      const reader = readQueue.shift();
      if (reader) {
        reader.resolve(event);
      } else {
        pushQueue.push(event);
      }
    });
    this.on("end", () => {
      done = true;
      for (const reader of readQueue) {
        reader.resolve(void 0);
      }
      readQueue.length = 0;
    });
    this.on("abort", (err) => {
      done = true;
      for (const reader of readQueue) {
        reader.reject(err);
      }
      readQueue.length = 0;
    });
    this.on("error", (err) => {
      done = true;
      for (const reader of readQueue) {
        reader.reject(err);
      }
      readQueue.length = 0;
    });
    return {
      next: async () => {
        if (!pushQueue.length) {
          if (done) {
            return { value: void 0, done: true };
          }
          return new Promise((resolve, reject) => readQueue.push({ resolve, reject })).then((chunk2) => chunk2 ? { value: chunk2, done: false } : { value: void 0, done: true });
        }
        const chunk = pushQueue.shift();
        return { value: chunk, done: false };
      },
      return: async () => {
        this.abort();
        return { value: void 0, done: true };
      }
    };
  }
  static fromReadableStream(stream) {
    const runner = new _a();
    runner._run(() => runner._fromReadableStream(stream));
    return runner;
  }
  async _fromReadableStream(readableStream, options) {
    const signal = options?.signal;
    if (signal) {
      if (signal.aborted)
        this.controller.abort();
      signal.addEventListener("abort", () => this.controller.abort());
    }
    this._connected();
    const stream = Stream.fromReadableStream(readableStream, this.controller);
    for await (const event of stream) {
      __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_addEvent).call(this, event);
    }
    if (stream.controller.signal?.aborted) {
      throw new APIUserAbortError();
    }
    return this._addRun(__classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_endRequest).call(this));
  }
  toReadableStream() {
    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);
    return stream.toReadableStream();
  }
  static createToolAssistantStream(runId, runs, params, options) {
    const runner = new _a();
    runner._run(() => runner._runToolAssistantStream(runId, runs, params, {
      ...options,
      headers: { ...options?.headers, "X-Stainless-Helper-Method": "stream" }
    }));
    return runner;
  }
  async _createToolAssistantStream(run, runId, params, options) {
    const signal = options?.signal;
    if (signal) {
      if (signal.aborted)
        this.controller.abort();
      signal.addEventListener("abort", () => this.controller.abort());
    }
    const body = { ...params, stream: true };
    const stream = await run.submitToolOutputs(runId, body, {
      ...options,
      signal: this.controller.signal
    });
    this._connected();
    for await (const event of stream) {
      __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_addEvent).call(this, event);
    }
    if (stream.controller.signal?.aborted) {
      throw new APIUserAbortError();
    }
    return this._addRun(__classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_endRequest).call(this));
  }
  static createThreadAssistantStream(params, thread, options) {
    const runner = new _a();
    runner._run(() => runner._threadAssistantStream(params, thread, {
      ...options,
      headers: { ...options?.headers, "X-Stainless-Helper-Method": "stream" }
    }));
    return runner;
  }
  static createAssistantStream(threadId, runs, params, options) {
    const runner = new _a();
    runner._run(() => runner._runAssistantStream(threadId, runs, params, {
      ...options,
      headers: { ...options?.headers, "X-Stainless-Helper-Method": "stream" }
    }));
    return runner;
  }
  currentEvent() {
    return __classPrivateFieldGet(this, _AssistantStream_currentEvent, "f");
  }
  currentRun() {
    return __classPrivateFieldGet(this, _AssistantStream_currentRunSnapshot, "f");
  }
  currentMessageSnapshot() {
    return __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, "f");
  }
  currentRunStepSnapshot() {
    return __classPrivateFieldGet(this, _AssistantStream_currentRunStepSnapshot, "f");
  }
  async finalRunSteps() {
    await this.done();
    return Object.values(__classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, "f"));
  }
  async finalMessages() {
    await this.done();
    return Object.values(__classPrivateFieldGet(this, _AssistantStream_messageSnapshots, "f"));
  }
  async finalRun() {
    await this.done();
    if (!__classPrivateFieldGet(this, _AssistantStream_finalRun, "f"))
      throw Error("Final run was not received.");
    return __classPrivateFieldGet(this, _AssistantStream_finalRun, "f");
  }
  async _createThreadAssistantStream(thread, params, options) {
    const signal = options?.signal;
    if (signal) {
      if (signal.aborted)
        this.controller.abort();
      signal.addEventListener("abort", () => this.controller.abort());
    }
    const body = { ...params, stream: true };
    const stream = await thread.createAndRun(body, { ...options, signal: this.controller.signal });
    this._connected();
    for await (const event of stream) {
      __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_addEvent).call(this, event);
    }
    if (stream.controller.signal?.aborted) {
      throw new APIUserAbortError();
    }
    return this._addRun(__classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_endRequest).call(this));
  }
  async _createAssistantStream(run, threadId, params, options) {
    const signal = options?.signal;
    if (signal) {
      if (signal.aborted)
        this.controller.abort();
      signal.addEventListener("abort", () => this.controller.abort());
    }
    const body = { ...params, stream: true };
    const stream = await run.create(threadId, body, { ...options, signal: this.controller.signal });
    this._connected();
    for await (const event of stream) {
      __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_addEvent).call(this, event);
    }
    if (stream.controller.signal?.aborted) {
      throw new APIUserAbortError();
    }
    return this._addRun(__classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_endRequest).call(this));
  }
  static accumulateDelta(acc, delta) {
    for (const [key, deltaValue] of Object.entries(delta)) {
      if (!acc.hasOwnProperty(key)) {
        acc[key] = deltaValue;
        continue;
      }
      let accValue = acc[key];
      if (accValue === null || accValue === void 0) {
        acc[key] = deltaValue;
        continue;
      }
      if (key === "index" || key === "type") {
        acc[key] = deltaValue;
        continue;
      }
      if (typeof accValue === "string" && typeof deltaValue === "string") {
        accValue += deltaValue;
      } else if (typeof accValue === "number" && typeof deltaValue === "number") {
        accValue += deltaValue;
      } else if (isObj(accValue) && isObj(deltaValue)) {
        accValue = this.accumulateDelta(accValue, deltaValue);
      } else if (Array.isArray(accValue) && Array.isArray(deltaValue)) {
        if (accValue.every((x) => typeof x === "string" || typeof x === "number")) {
          accValue.push(...deltaValue);
          continue;
        }
        for (const deltaEntry of deltaValue) {
          if (!isObj(deltaEntry)) {
            throw new Error(`Expected array delta entry to be an object but got: ${deltaEntry}`);
          }
          const index = deltaEntry["index"];
          if (index == null) {
            console.error(deltaEntry);
            throw new Error("Expected array delta entry to have an `index` property");
          }
          if (typeof index !== "number") {
            throw new Error(`Expected array delta entry \`index\` property to be a number but got ${index}`);
          }
          const accEntry = accValue[index];
          if (accEntry == null) {
            accValue.push(deltaEntry);
          } else {
            accValue[index] = this.accumulateDelta(accEntry, deltaEntry);
          }
        }
        continue;
      } else {
        throw Error(`Unhandled record type: ${key}, deltaValue: ${deltaValue}, accValue: ${accValue}`);
      }
      acc[key] = accValue;
    }
    return acc;
  }
  _addRun(run) {
    return run;
  }
  async _threadAssistantStream(params, thread, options) {
    return await this._createThreadAssistantStream(thread, params, options);
  }
  async _runAssistantStream(threadId, runs, params, options) {
    return await this._createAssistantStream(runs, threadId, params, options);
  }
  async _runToolAssistantStream(runId, runs, params, options) {
    return await this._createToolAssistantStream(runs, runId, params, options);
  }
};
_a = AssistantStream, _AssistantStream_addEvent = function _AssistantStream_addEvent2(event) {
  if (this.ended)
    return;
  __classPrivateFieldSet(this, _AssistantStream_currentEvent, event, "f");
  __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_handleEvent).call(this, event);
  switch (event.event) {
    case "thread.created":
      break;
    case "thread.run.created":
    case "thread.run.queued":
    case "thread.run.in_progress":
    case "thread.run.requires_action":
    case "thread.run.completed":
    case "thread.run.incomplete":
    case "thread.run.failed":
    case "thread.run.cancelling":
    case "thread.run.cancelled":
    case "thread.run.expired":
      __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_handleRun).call(this, event);
      break;
    case "thread.run.step.created":
    case "thread.run.step.in_progress":
    case "thread.run.step.delta":
    case "thread.run.step.completed":
    case "thread.run.step.failed":
    case "thread.run.step.cancelled":
    case "thread.run.step.expired":
      __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_handleRunStep).call(this, event);
      break;
    case "thread.message.created":
    case "thread.message.in_progress":
    case "thread.message.delta":
    case "thread.message.completed":
    case "thread.message.incomplete":
      __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_handleMessage).call(this, event);
      break;
    case "error":
      throw new Error("Encountered an error event in event processing - errors should be processed earlier");
    default:
      assertNever2(event);
  }
}, _AssistantStream_endRequest = function _AssistantStream_endRequest2() {
  if (this.ended) {
    throw new OpenAIError(`stream has ended, this shouldn't happen`);
  }
  if (!__classPrivateFieldGet(this, _AssistantStream_finalRun, "f"))
    throw Error("Final run has not been received");
  return __classPrivateFieldGet(this, _AssistantStream_finalRun, "f");
}, _AssistantStream_handleMessage = function _AssistantStream_handleMessage2(event) {
  const [accumulatedMessage, newContent] = __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_accumulateMessage).call(this, event, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, "f"));
  __classPrivateFieldSet(this, _AssistantStream_messageSnapshot, accumulatedMessage, "f");
  __classPrivateFieldGet(this, _AssistantStream_messageSnapshots, "f")[accumulatedMessage.id] = accumulatedMessage;
  for (const content of newContent) {
    const snapshotContent = accumulatedMessage.content[content.index];
    if (snapshotContent?.type == "text") {
      this._emit("textCreated", snapshotContent.text);
    }
  }
  switch (event.event) {
    case "thread.message.created":
      this._emit("messageCreated", event.data);
      break;
    case "thread.message.in_progress":
      break;
    case "thread.message.delta":
      this._emit("messageDelta", event.data.delta, accumulatedMessage);
      if (event.data.delta.content) {
        for (const content of event.data.delta.content) {
          if (content.type == "text" && content.text) {
            let textDelta = content.text;
            let snapshot = accumulatedMessage.content[content.index];
            if (snapshot && snapshot.type == "text") {
              this._emit("textDelta", textDelta, snapshot.text);
            } else {
              throw Error("The snapshot associated with this text delta is not text or missing");
            }
          }
          if (content.index != __classPrivateFieldGet(this, _AssistantStream_currentContentIndex, "f")) {
            if (__classPrivateFieldGet(this, _AssistantStream_currentContent, "f")) {
              switch (__classPrivateFieldGet(this, _AssistantStream_currentContent, "f").type) {
                case "text":
                  this._emit("textDone", __classPrivateFieldGet(this, _AssistantStream_currentContent, "f").text, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, "f"));
                  break;
                case "image_file":
                  this._emit("imageFileDone", __classPrivateFieldGet(this, _AssistantStream_currentContent, "f").image_file, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, "f"));
                  break;
              }
            }
            __classPrivateFieldSet(this, _AssistantStream_currentContentIndex, content.index, "f");
          }
          __classPrivateFieldSet(this, _AssistantStream_currentContent, accumulatedMessage.content[content.index], "f");
        }
      }
      break;
    case "thread.message.completed":
    case "thread.message.incomplete":
      if (__classPrivateFieldGet(this, _AssistantStream_currentContentIndex, "f") !== void 0) {
        const currentContent = event.data.content[__classPrivateFieldGet(this, _AssistantStream_currentContentIndex, "f")];
        if (currentContent) {
          switch (currentContent.type) {
            case "image_file":
              this._emit("imageFileDone", currentContent.image_file, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, "f"));
              break;
            case "text":
              this._emit("textDone", currentContent.text, __classPrivateFieldGet(this, _AssistantStream_messageSnapshot, "f"));
              break;
          }
        }
      }
      if (__classPrivateFieldGet(this, _AssistantStream_messageSnapshot, "f")) {
        this._emit("messageDone", event.data);
      }
      __classPrivateFieldSet(this, _AssistantStream_messageSnapshot, void 0, "f");
  }
}, _AssistantStream_handleRunStep = function _AssistantStream_handleRunStep2(event) {
  const accumulatedRunStep = __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_accumulateRunStep).call(this, event);
  __classPrivateFieldSet(this, _AssistantStream_currentRunStepSnapshot, accumulatedRunStep, "f");
  switch (event.event) {
    case "thread.run.step.created":
      this._emit("runStepCreated", event.data);
      break;
    case "thread.run.step.delta":
      const delta = event.data.delta;
      if (delta.step_details && delta.step_details.type == "tool_calls" && delta.step_details.tool_calls && accumulatedRunStep.step_details.type == "tool_calls") {
        for (const toolCall of delta.step_details.tool_calls) {
          if (toolCall.index == __classPrivateFieldGet(this, _AssistantStream_currentToolCallIndex, "f")) {
            this._emit("toolCallDelta", toolCall, accumulatedRunStep.step_details.tool_calls[toolCall.index]);
          } else {
            if (__classPrivateFieldGet(this, _AssistantStream_currentToolCall, "f")) {
              this._emit("toolCallDone", __classPrivateFieldGet(this, _AssistantStream_currentToolCall, "f"));
            }
            __classPrivateFieldSet(this, _AssistantStream_currentToolCallIndex, toolCall.index, "f");
            __classPrivateFieldSet(this, _AssistantStream_currentToolCall, accumulatedRunStep.step_details.tool_calls[toolCall.index], "f");
            if (__classPrivateFieldGet(this, _AssistantStream_currentToolCall, "f"))
              this._emit("toolCallCreated", __classPrivateFieldGet(this, _AssistantStream_currentToolCall, "f"));
          }
        }
      }
      this._emit("runStepDelta", event.data.delta, accumulatedRunStep);
      break;
    case "thread.run.step.completed":
    case "thread.run.step.failed":
    case "thread.run.step.cancelled":
    case "thread.run.step.expired":
      __classPrivateFieldSet(this, _AssistantStream_currentRunStepSnapshot, void 0, "f");
      const details = event.data.step_details;
      if (details.type == "tool_calls") {
        if (__classPrivateFieldGet(this, _AssistantStream_currentToolCall, "f")) {
          this._emit("toolCallDone", __classPrivateFieldGet(this, _AssistantStream_currentToolCall, "f"));
          __classPrivateFieldSet(this, _AssistantStream_currentToolCall, void 0, "f");
        }
      }
      this._emit("runStepDone", event.data, accumulatedRunStep);
      break;
    case "thread.run.step.in_progress":
      break;
  }
}, _AssistantStream_handleEvent = function _AssistantStream_handleEvent2(event) {
  __classPrivateFieldGet(this, _AssistantStream_events, "f").push(event);
  this._emit("event", event);
}, _AssistantStream_accumulateRunStep = function _AssistantStream_accumulateRunStep2(event) {
  switch (event.event) {
    case "thread.run.step.created":
      __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, "f")[event.data.id] = event.data;
      return event.data;
    case "thread.run.step.delta":
      let snapshot = __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, "f")[event.data.id];
      if (!snapshot) {
        throw Error("Received a RunStepDelta before creation of a snapshot");
      }
      let data = event.data;
      if (data.delta) {
        const accumulated = _a.accumulateDelta(snapshot, data.delta);
        __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, "f")[event.data.id] = accumulated;
      }
      return __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, "f")[event.data.id];
    case "thread.run.step.completed":
    case "thread.run.step.failed":
    case "thread.run.step.cancelled":
    case "thread.run.step.expired":
    case "thread.run.step.in_progress":
      __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, "f")[event.data.id] = event.data;
      break;
  }
  if (__classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, "f")[event.data.id])
    return __classPrivateFieldGet(this, _AssistantStream_runStepSnapshots, "f")[event.data.id];
  throw new Error("No snapshot available");
}, _AssistantStream_accumulateMessage = function _AssistantStream_accumulateMessage2(event, snapshot) {
  let newContent = [];
  switch (event.event) {
    case "thread.message.created":
      return [event.data, newContent];
    case "thread.message.delta":
      if (!snapshot) {
        throw Error("Received a delta with no existing snapshot (there should be one from message creation)");
      }
      let data = event.data;
      if (data.delta.content) {
        for (const contentElement of data.delta.content) {
          if (contentElement.index in snapshot.content) {
            let currentContent = snapshot.content[contentElement.index];
            snapshot.content[contentElement.index] = __classPrivateFieldGet(this, _AssistantStream_instances, "m", _AssistantStream_accumulateContent).call(this, contentElement, currentContent);
          } else {
            snapshot.content[contentElement.index] = contentElement;
            newContent.push(contentElement);
          }
        }
      }
      return [snapshot, newContent];
    case "thread.message.in_progress":
    case "thread.message.completed":
    case "thread.message.incomplete":
      if (snapshot) {
        return [snapshot, newContent];
      } else {
        throw Error("Received thread message event with no existing snapshot");
      }
  }
  throw Error("Tried to accumulate a non-message event");
}, _AssistantStream_accumulateContent = function _AssistantStream_accumulateContent2(contentElement, currentContent) {
  return _a.accumulateDelta(currentContent, contentElement);
}, _AssistantStream_handleRun = function _AssistantStream_handleRun2(event) {
  __classPrivateFieldSet(this, _AssistantStream_currentRunSnapshot, event.data, "f");
  switch (event.event) {
    case "thread.run.created":
      break;
    case "thread.run.queued":
      break;
    case "thread.run.in_progress":
      break;
    case "thread.run.requires_action":
    case "thread.run.cancelled":
    case "thread.run.failed":
    case "thread.run.completed":
    case "thread.run.expired":
    case "thread.run.incomplete":
      __classPrivateFieldSet(this, _AssistantStream_finalRun, event.data, "f");
      if (__classPrivateFieldGet(this, _AssistantStream_currentToolCall, "f")) {
        this._emit("toolCallDone", __classPrivateFieldGet(this, _AssistantStream_currentToolCall, "f"));
        __classPrivateFieldSet(this, _AssistantStream_currentToolCall, void 0, "f");
      }
      break;
    case "thread.run.cancelling":
      break;
  }
};
function assertNever2(_x) {
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/threads/runs/runs.mjs
var Runs = class extends APIResource {
  constructor() {
    super(...arguments);
    this.steps = new Steps(this._client);
  }
  create(threadID, params, options) {
    const { include, ...body } = params;
    return this._client.post(path`/threads/${threadID}/runs`, {
      query: { include },
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers]),
      stream: params.stream ?? false,
      __synthesizeEventData: true
    });
  }
  /**
   * Retrieves a run.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  retrieve(runID, params, options) {
    const { thread_id } = params;
    return this._client.get(path`/threads/${thread_id}/runs/${runID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Modifies a run.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  update(runID, params, options) {
    const { thread_id, ...body } = params;
    return this._client.post(path`/threads/${thread_id}/runs/${runID}`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Returns a list of runs belonging to a thread.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  list(threadID, query = {}, options) {
    return this._client.getAPIList(path`/threads/${threadID}/runs`, CursorPage, {
      query,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Cancels a run that is `in_progress`.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  cancel(runID, params, options) {
    const { thread_id } = params;
    return this._client.post(path`/threads/${thread_id}/runs/${runID}/cancel`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * A helper to create a run an poll for a terminal state. More information on Run
   * lifecycles can be found here:
   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps
   */
  async createAndPoll(threadId, body, options) {
    const run = await this.create(threadId, body, options);
    return await this.poll(run.id, { thread_id: threadId }, options);
  }
  /**
   * Create a Run stream
   *
   * @deprecated use `stream` instead
   */
  createAndStream(threadId, body, options) {
    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);
  }
  /**
   * A helper to poll a run status until it reaches a terminal state. More
   * information on Run lifecycles can be found here:
   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps
   */
  async poll(runId, params, options) {
    const headers = buildHeaders([
      options?.headers,
      {
        "X-Stainless-Poll-Helper": "true",
        "X-Stainless-Custom-Poll-Interval": options?.pollIntervalMs?.toString() ?? void 0
      }
    ]);
    while (true) {
      const { data: run, response } = await this.retrieve(runId, params, {
        ...options,
        headers: { ...options?.headers, ...headers }
      }).withResponse();
      switch (run.status) {
        //If we are in any sort of intermediate state we poll
        case "queued":
        case "in_progress":
        case "cancelling":
          let sleepInterval = 5e3;
          if (options?.pollIntervalMs) {
            sleepInterval = options.pollIntervalMs;
          } else {
            const headerInterval = response.headers.get("openai-poll-after-ms");
            if (headerInterval) {
              const headerIntervalMs = parseInt(headerInterval);
              if (!isNaN(headerIntervalMs)) {
                sleepInterval = headerIntervalMs;
              }
            }
          }
          await sleep(sleepInterval);
          break;
        //We return the run in any terminal state.
        case "requires_action":
        case "incomplete":
        case "cancelled":
        case "completed":
        case "failed":
        case "expired":
          return run;
      }
    }
  }
  /**
   * Create a Run stream
   */
  stream(threadId, body, options) {
    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);
  }
  submitToolOutputs(runID, params, options) {
    const { thread_id, ...body } = params;
    return this._client.post(path`/threads/${thread_id}/runs/${runID}/submit_tool_outputs`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers]),
      stream: params.stream ?? false,
      __synthesizeEventData: true
    });
  }
  /**
   * A helper to submit a tool output to a run and poll for a terminal run state.
   * More information on Run lifecycles can be found here:
   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps
   */
  async submitToolOutputsAndPoll(runId, params, options) {
    const run = await this.submitToolOutputs(runId, params, options);
    return await this.poll(run.id, params, options);
  }
  /**
   * Submit the tool outputs from a previous run and stream the run to a terminal
   * state. More information on Run lifecycles can be found here:
   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps
   */
  submitToolOutputsStream(runId, params, options) {
    return AssistantStream.createToolAssistantStream(runId, this._client.beta.threads.runs, params, options);
  }
};
Runs.Steps = Steps;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/threads/threads.mjs
var Threads2 = class extends APIResource {
  constructor() {
    super(...arguments);
    this.runs = new Runs(this._client);
    this.messages = new Messages2(this._client);
  }
  /**
   * Create a thread.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  create(body = {}, options) {
    return this._client.post("/threads", {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Retrieves a thread.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  retrieve(threadID, options) {
    return this._client.get(path`/threads/${threadID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Modifies a thread.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  update(threadID, body, options) {
    return this._client.post(path`/threads/${threadID}`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Delete a thread.
   *
   * @deprecated The Assistants API is deprecated in favor of the Responses API
   */
  delete(threadID, options) {
    return this._client.delete(path`/threads/${threadID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  createAndRun(body, options) {
    return this._client.post("/threads/runs", {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers]),
      stream: body.stream ?? false,
      __synthesizeEventData: true
    });
  }
  /**
   * A helper to create a thread, start a run and then poll for a terminal state.
   * More information on Run lifecycles can be found here:
   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps
   */
  async createAndRunPoll(body, options) {
    const run = await this.createAndRun(body, options);
    return await this.runs.poll(run.id, { thread_id: run.thread_id }, options);
  }
  /**
   * Create a thread and stream the run back
   */
  createAndRunStream(body, options) {
    return AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);
  }
};
Threads2.Runs = Runs;
Threads2.Messages = Messages2;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/beta/beta.mjs
var Beta = class extends APIResource {
  constructor() {
    super(...arguments);
    this.realtime = new Realtime(this._client);
    this.chatkit = new ChatKit(this._client);
    this.assistants = new Assistants(this._client);
    this.threads = new Threads2(this._client);
  }
};
Beta.Realtime = Realtime;
Beta.ChatKit = ChatKit;
Beta.Assistants = Assistants;
Beta.Threads = Threads2;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/completions.mjs
var Completions2 = class extends APIResource {
  create(body, options) {
    return this._client.post("/completions", { body, ...options, stream: body.stream ?? false });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/containers/files/content.mjs
var Content = class extends APIResource {
  /**
   * Retrieve Container File Content
   */
  retrieve(fileID, params, options) {
    const { container_id } = params;
    return this._client.get(path`/containers/${container_id}/files/${fileID}/content`, {
      ...options,
      headers: buildHeaders([{ Accept: "application/binary" }, options?.headers]),
      __binaryResponse: true
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/containers/files/files.mjs
var Files = class extends APIResource {
  constructor() {
    super(...arguments);
    this.content = new Content(this._client);
  }
  /**
   * Create a Container File
   *
   * You can send either a multipart/form-data request with the raw file content, or
   * a JSON request with a file ID.
   */
  create(containerID, body, options) {
    return this._client.post(path`/containers/${containerID}/files`, maybeMultipartFormRequestOptions({ body, ...options }, this._client));
  }
  /**
   * Retrieve Container File
   */
  retrieve(fileID, params, options) {
    const { container_id } = params;
    return this._client.get(path`/containers/${container_id}/files/${fileID}`, options);
  }
  /**
   * List Container files
   */
  list(containerID, query = {}, options) {
    return this._client.getAPIList(path`/containers/${containerID}/files`, CursorPage, {
      query,
      ...options
    });
  }
  /**
   * Delete Container File
   */
  delete(fileID, params, options) {
    const { container_id } = params;
    return this._client.delete(path`/containers/${container_id}/files/${fileID}`, {
      ...options,
      headers: buildHeaders([{ Accept: "*/*" }, options?.headers])
    });
  }
};
Files.Content = Content;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/containers/containers.mjs
var Containers = class extends APIResource {
  constructor() {
    super(...arguments);
    this.files = new Files(this._client);
  }
  /**
   * Create Container
   */
  create(body, options) {
    return this._client.post("/containers", { body, ...options });
  }
  /**
   * Retrieve Container
   */
  retrieve(containerID, options) {
    return this._client.get(path`/containers/${containerID}`, options);
  }
  /**
   * List Containers
   */
  list(query = {}, options) {
    return this._client.getAPIList("/containers", CursorPage, { query, ...options });
  }
  /**
   * Delete Container
   */
  delete(containerID, options) {
    return this._client.delete(path`/containers/${containerID}`, {
      ...options,
      headers: buildHeaders([{ Accept: "*/*" }, options?.headers])
    });
  }
};
Containers.Files = Files;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/conversations/items.mjs
var Items = class extends APIResource {
  /**
   * Create items in a conversation with the given ID.
   */
  create(conversationID, params, options) {
    const { include, ...body } = params;
    return this._client.post(path`/conversations/${conversationID}/items`, {
      query: { include },
      body,
      ...options
    });
  }
  /**
   * Get a single item from a conversation with the given IDs.
   */
  retrieve(itemID, params, options) {
    const { conversation_id, ...query } = params;
    return this._client.get(path`/conversations/${conversation_id}/items/${itemID}`, { query, ...options });
  }
  /**
   * List all items for a conversation with the given ID.
   */
  list(conversationID, query = {}, options) {
    return this._client.getAPIList(path`/conversations/${conversationID}/items`, ConversationCursorPage, { query, ...options });
  }
  /**
   * Delete an item from a conversation with the given IDs.
   */
  delete(itemID, params, options) {
    const { conversation_id } = params;
    return this._client.delete(path`/conversations/${conversation_id}/items/${itemID}`, options);
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/conversations/conversations.mjs
var Conversations = class extends APIResource {
  constructor() {
    super(...arguments);
    this.items = new Items(this._client);
  }
  /**
   * Create a conversation.
   */
  create(body = {}, options) {
    return this._client.post("/conversations", { body, ...options });
  }
  /**
   * Get a conversation
   */
  retrieve(conversationID, options) {
    return this._client.get(path`/conversations/${conversationID}`, options);
  }
  /**
   * Update a conversation
   */
  update(conversationID, body, options) {
    return this._client.post(path`/conversations/${conversationID}`, { body, ...options });
  }
  /**
   * Delete a conversation. Items in the conversation will not be deleted.
   */
  delete(conversationID, options) {
    return this._client.delete(path`/conversations/${conversationID}`, options);
  }
};
Conversations.Items = Items;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/embeddings.mjs
var Embeddings = class extends APIResource {
  /**
   * Creates an embedding vector representing the input text.
   *
   * @example
   * ```ts
   * const createEmbeddingResponse =
   *   await client.embeddings.create({
   *     input: 'The quick brown fox jumped over the lazy dog',
   *     model: 'text-embedding-3-small',
   *   });
   * ```
   */
  create(body, options) {
    const hasUserProvidedEncodingFormat = !!body.encoding_format;
    let encoding_format = hasUserProvidedEncodingFormat ? body.encoding_format : "base64";
    if (hasUserProvidedEncodingFormat) {
      loggerFor(this._client).debug("embeddings/user defined encoding_format:", body.encoding_format);
    }
    const response = this._client.post("/embeddings", {
      body: {
        ...body,
        encoding_format
      },
      ...options
    });
    if (hasUserProvidedEncodingFormat) {
      return response;
    }
    loggerFor(this._client).debug("embeddings/decoding base64 embeddings from base64");
    return response._thenUnwrap((response2) => {
      if (response2 && response2.data) {
        response2.data.forEach((embeddingBase64Obj) => {
          const embeddingBase64Str = embeddingBase64Obj.embedding;
          embeddingBase64Obj.embedding = toFloat32Array(embeddingBase64Str);
        });
      }
      return response2;
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/evals/runs/output-items.mjs
var OutputItems = class extends APIResource {
  /**
   * Get an evaluation run output item by ID.
   */
  retrieve(outputItemID, params, options) {
    const { eval_id, run_id } = params;
    return this._client.get(path`/evals/${eval_id}/runs/${run_id}/output_items/${outputItemID}`, options);
  }
  /**
   * Get a list of output items for an evaluation run.
   */
  list(runID, params, options) {
    const { eval_id, ...query } = params;
    return this._client.getAPIList(path`/evals/${eval_id}/runs/${runID}/output_items`, CursorPage, { query, ...options });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/evals/runs/runs.mjs
var Runs2 = class extends APIResource {
  constructor() {
    super(...arguments);
    this.outputItems = new OutputItems(this._client);
  }
  /**
   * Kicks off a new run for a given evaluation, specifying the data source, and what
   * model configuration to use to test. The datasource will be validated against the
   * schema specified in the config of the evaluation.
   */
  create(evalID, body, options) {
    return this._client.post(path`/evals/${evalID}/runs`, { body, ...options });
  }
  /**
   * Get an evaluation run by ID.
   */
  retrieve(runID, params, options) {
    const { eval_id } = params;
    return this._client.get(path`/evals/${eval_id}/runs/${runID}`, options);
  }
  /**
   * Get a list of runs for an evaluation.
   */
  list(evalID, query = {}, options) {
    return this._client.getAPIList(path`/evals/${evalID}/runs`, CursorPage, {
      query,
      ...options
    });
  }
  /**
   * Delete an eval run.
   */
  delete(runID, params, options) {
    const { eval_id } = params;
    return this._client.delete(path`/evals/${eval_id}/runs/${runID}`, options);
  }
  /**
   * Cancel an ongoing evaluation run.
   */
  cancel(runID, params, options) {
    const { eval_id } = params;
    return this._client.post(path`/evals/${eval_id}/runs/${runID}`, options);
  }
};
Runs2.OutputItems = OutputItems;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/evals/evals.mjs
var Evals = class extends APIResource {
  constructor() {
    super(...arguments);
    this.runs = new Runs2(this._client);
  }
  /**
   * Create the structure of an evaluation that can be used to test a model's
   * performance. An evaluation is a set of testing criteria and the config for a
   * data source, which dictates the schema of the data used in the evaluation. After
   * creating an evaluation, you can run it on different models and model parameters.
   * We support several types of graders and datasources. For more information, see
   * the [Evals guide](https://platform.openai.com/docs/guides/evals).
   */
  create(body, options) {
    return this._client.post("/evals", { body, ...options });
  }
  /**
   * Get an evaluation by ID.
   */
  retrieve(evalID, options) {
    return this._client.get(path`/evals/${evalID}`, options);
  }
  /**
   * Update certain properties of an evaluation.
   */
  update(evalID, body, options) {
    return this._client.post(path`/evals/${evalID}`, { body, ...options });
  }
  /**
   * List evaluations for a project.
   */
  list(query = {}, options) {
    return this._client.getAPIList("/evals", CursorPage, { query, ...options });
  }
  /**
   * Delete an evaluation.
   */
  delete(evalID, options) {
    return this._client.delete(path`/evals/${evalID}`, options);
  }
};
Evals.Runs = Runs2;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/files.mjs
var Files2 = class extends APIResource {
  /**
   * Upload a file that can be used across various endpoints. Individual files can be
   * up to 512 MB, and each project can store up to 2.5 TB of files in total. There
   * is no organization-wide storage limit.
   *
   * - The Assistants API supports files up to 2 million tokens and of specific file
   *   types. See the
   *   [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools)
   *   for details.
   * - The Fine-tuning API only supports `.jsonl` files. The input also has certain
   *   required formats for fine-tuning
   *   [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input)
   *   or
   *   [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)
   *   models.
   * - The Batch API only supports `.jsonl` files up to 200 MB in size. The input
   *   also has a specific required
   *   [format](https://platform.openai.com/docs/api-reference/batch/request-input).
   *
   * Please [contact us](https://help.openai.com/) if you need to increase these
   * storage limits.
   */
  create(body, options) {
    return this._client.post("/files", multipartFormRequestOptions({ body, ...options }, this._client));
  }
  /**
   * Returns information about a specific file.
   */
  retrieve(fileID, options) {
    return this._client.get(path`/files/${fileID}`, options);
  }
  /**
   * Returns a list of files.
   */
  list(query = {}, options) {
    return this._client.getAPIList("/files", CursorPage, { query, ...options });
  }
  /**
   * Delete a file and remove it from all vector stores.
   */
  delete(fileID, options) {
    return this._client.delete(path`/files/${fileID}`, options);
  }
  /**
   * Returns the contents of the specified file.
   */
  content(fileID, options) {
    return this._client.get(path`/files/${fileID}/content`, {
      ...options,
      headers: buildHeaders([{ Accept: "application/binary" }, options?.headers]),
      __binaryResponse: true
    });
  }
  /**
   * Waits for the given file to be processed, default timeout is 30 mins.
   */
  async waitForProcessing(id, { pollInterval = 5e3, maxWait = 30 * 60 * 1e3 } = {}) {
    const TERMINAL_STATES = /* @__PURE__ */ new Set(["processed", "error", "deleted"]);
    const start = Date.now();
    let file2 = await this.retrieve(id);
    while (!file2.status || !TERMINAL_STATES.has(file2.status)) {
      await sleep(pollInterval);
      file2 = await this.retrieve(id);
      if (Date.now() - start > maxWait) {
        throw new APIConnectionTimeoutError({
          message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`
        });
      }
    }
    return file2;
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/fine-tuning/methods.mjs
var Methods = class extends APIResource {
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/fine-tuning/alpha/graders.mjs
var Graders = class extends APIResource {
  /**
   * Run a grader.
   *
   * @example
   * ```ts
   * const response = await client.fineTuning.alpha.graders.run({
   *   grader: {
   *     input: 'input',
   *     name: 'name',
   *     operation: 'eq',
   *     reference: 'reference',
   *     type: 'string_check',
   *   },
   *   model_sample: 'model_sample',
   * });
   * ```
   */
  run(body, options) {
    return this._client.post("/fine_tuning/alpha/graders/run", { body, ...options });
  }
  /**
   * Validate a grader.
   *
   * @example
   * ```ts
   * const response =
   *   await client.fineTuning.alpha.graders.validate({
   *     grader: {
   *       input: 'input',
   *       name: 'name',
   *       operation: 'eq',
   *       reference: 'reference',
   *       type: 'string_check',
   *     },
   *   });
   * ```
   */
  validate(body, options) {
    return this._client.post("/fine_tuning/alpha/graders/validate", { body, ...options });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/fine-tuning/alpha/alpha.mjs
var Alpha = class extends APIResource {
  constructor() {
    super(...arguments);
    this.graders = new Graders(this._client);
  }
};
Alpha.Graders = Graders;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/fine-tuning/checkpoints/permissions.mjs
var Permissions = class extends APIResource {
  /**
   * **NOTE:** Calling this endpoint requires an [admin API key](../admin-api-keys).
   *
   * This enables organization owners to share fine-tuned models with other projects
   * in their organization.
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const permissionCreateResponse of client.fineTuning.checkpoints.permissions.create(
   *   'ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd',
   *   { project_ids: ['string'] },
   * )) {
   *   // ...
   * }
   * ```
   */
  create(fineTunedModelCheckpoint, body, options) {
    return this._client.getAPIList(path`/fine_tuning/checkpoints/${fineTunedModelCheckpoint}/permissions`, Page, { body, method: "post", ...options });
  }
  /**
   * **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).
   *
   * Organization owners can use this endpoint to view all permissions for a
   * fine-tuned model checkpoint.
   *
   * @example
   * ```ts
   * const permission =
   *   await client.fineTuning.checkpoints.permissions.retrieve(
   *     'ft-AF1WoRqd3aJAHsqc9NY7iL8F',
   *   );
   * ```
   */
  retrieve(fineTunedModelCheckpoint, query = {}, options) {
    return this._client.get(path`/fine_tuning/checkpoints/${fineTunedModelCheckpoint}/permissions`, {
      query,
      ...options
    });
  }
  /**
   * **NOTE:** This endpoint requires an [admin API key](../admin-api-keys).
   *
   * Organization owners can use this endpoint to delete a permission for a
   * fine-tuned model checkpoint.
   *
   * @example
   * ```ts
   * const permission =
   *   await client.fineTuning.checkpoints.permissions.delete(
   *     'cp_zc4Q7MP6XxulcVzj4MZdwsAB',
   *     {
   *       fine_tuned_model_checkpoint:
   *         'ft:gpt-4o-mini-2024-07-18:org:weather:B7R9VjQd',
   *     },
   *   );
   * ```
   */
  delete(permissionID, params, options) {
    const { fine_tuned_model_checkpoint } = params;
    return this._client.delete(path`/fine_tuning/checkpoints/${fine_tuned_model_checkpoint}/permissions/${permissionID}`, options);
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/fine-tuning/checkpoints/checkpoints.mjs
var Checkpoints = class extends APIResource {
  constructor() {
    super(...arguments);
    this.permissions = new Permissions(this._client);
  }
};
Checkpoints.Permissions = Permissions;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/fine-tuning/jobs/checkpoints.mjs
var Checkpoints2 = class extends APIResource {
  /**
   * List checkpoints for a fine-tuning job.
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const fineTuningJobCheckpoint of client.fineTuning.jobs.checkpoints.list(
   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',
   * )) {
   *   // ...
   * }
   * ```
   */
  list(fineTuningJobID, query = {}, options) {
    return this._client.getAPIList(path`/fine_tuning/jobs/${fineTuningJobID}/checkpoints`, CursorPage, { query, ...options });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/fine-tuning/jobs/jobs.mjs
var Jobs = class extends APIResource {
  constructor() {
    super(...arguments);
    this.checkpoints = new Checkpoints2(this._client);
  }
  /**
   * Creates a fine-tuning job which begins the process of creating a new model from
   * a given dataset.
   *
   * Response includes details of the enqueued job including job status and the name
   * of the fine-tuned models once complete.
   *
   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)
   *
   * @example
   * ```ts
   * const fineTuningJob = await client.fineTuning.jobs.create({
   *   model: 'gpt-4o-mini',
   *   training_file: 'file-abc123',
   * });
   * ```
   */
  create(body, options) {
    return this._client.post("/fine_tuning/jobs", { body, ...options });
  }
  /**
   * Get info about a fine-tuning job.
   *
   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/model-optimization)
   *
   * @example
   * ```ts
   * const fineTuningJob = await client.fineTuning.jobs.retrieve(
   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',
   * );
   * ```
   */
  retrieve(fineTuningJobID, options) {
    return this._client.get(path`/fine_tuning/jobs/${fineTuningJobID}`, options);
  }
  /**
   * List your organization's fine-tuning jobs
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const fineTuningJob of client.fineTuning.jobs.list()) {
   *   // ...
   * }
   * ```
   */
  list(query = {}, options) {
    return this._client.getAPIList("/fine_tuning/jobs", CursorPage, { query, ...options });
  }
  /**
   * Immediately cancel a fine-tune job.
   *
   * @example
   * ```ts
   * const fineTuningJob = await client.fineTuning.jobs.cancel(
   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',
   * );
   * ```
   */
  cancel(fineTuningJobID, options) {
    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/cancel`, options);
  }
  /**
   * Get status updates for a fine-tuning job.
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const fineTuningJobEvent of client.fineTuning.jobs.listEvents(
   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',
   * )) {
   *   // ...
   * }
   * ```
   */
  listEvents(fineTuningJobID, query = {}, options) {
    return this._client.getAPIList(path`/fine_tuning/jobs/${fineTuningJobID}/events`, CursorPage, { query, ...options });
  }
  /**
   * Pause a fine-tune job.
   *
   * @example
   * ```ts
   * const fineTuningJob = await client.fineTuning.jobs.pause(
   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',
   * );
   * ```
   */
  pause(fineTuningJobID, options) {
    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/pause`, options);
  }
  /**
   * Resume a fine-tune job.
   *
   * @example
   * ```ts
   * const fineTuningJob = await client.fineTuning.jobs.resume(
   *   'ft-AF1WoRqd3aJAHsqc9NY7iL8F',
   * );
   * ```
   */
  resume(fineTuningJobID, options) {
    return this._client.post(path`/fine_tuning/jobs/${fineTuningJobID}/resume`, options);
  }
};
Jobs.Checkpoints = Checkpoints2;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/fine-tuning/fine-tuning.mjs
var FineTuning = class extends APIResource {
  constructor() {
    super(...arguments);
    this.methods = new Methods(this._client);
    this.jobs = new Jobs(this._client);
    this.checkpoints = new Checkpoints(this._client);
    this.alpha = new Alpha(this._client);
  }
};
FineTuning.Methods = Methods;
FineTuning.Jobs = Jobs;
FineTuning.Checkpoints = Checkpoints;
FineTuning.Alpha = Alpha;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/graders/grader-models.mjs
var GraderModels = class extends APIResource {
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/graders/graders.mjs
var Graders2 = class extends APIResource {
  constructor() {
    super(...arguments);
    this.graderModels = new GraderModels(this._client);
  }
};
Graders2.GraderModels = GraderModels;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/images.mjs
var Images = class extends APIResource {
  /**
   * Creates a variation of a given image. This endpoint only supports `dall-e-2`.
   *
   * @example
   * ```ts
   * const imagesResponse = await client.images.createVariation({
   *   image: fs.createReadStream('otter.png'),
   * });
   * ```
   */
  createVariation(body, options) {
    return this._client.post("/images/variations", multipartFormRequestOptions({ body, ...options }, this._client));
  }
  edit(body, options) {
    return this._client.post("/images/edits", multipartFormRequestOptions({ body, ...options, stream: body.stream ?? false }, this._client));
  }
  generate(body, options) {
    return this._client.post("/images/generations", { body, ...options, stream: body.stream ?? false });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/models.mjs
var Models = class extends APIResource {
  /**
   * Retrieves a model instance, providing basic information about the model such as
   * the owner and permissioning.
   */
  retrieve(model, options) {
    return this._client.get(path`/models/${model}`, options);
  }
  /**
   * Lists the currently available models, and provides basic information about each
   * one such as the owner and availability.
   */
  list(options) {
    return this._client.getAPIList("/models", Page, options);
  }
  /**
   * Delete a fine-tuned model. You must have the Owner role in your organization to
   * delete a model.
   */
  delete(model, options) {
    return this._client.delete(path`/models/${model}`, options);
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/moderations.mjs
var Moderations = class extends APIResource {
  /**
   * Classifies if text and/or image inputs are potentially harmful. Learn more in
   * the [moderation guide](https://platform.openai.com/docs/guides/moderation).
   */
  create(body, options) {
    return this._client.post("/moderations", { body, ...options });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/realtime/calls.mjs
var Calls = class extends APIResource {
  /**
   * Accept an incoming SIP call and configure the realtime session that will handle
   * it.
   *
   * @example
   * ```ts
   * await client.realtime.calls.accept('call_id', {
   *   type: 'realtime',
   * });
   * ```
   */
  accept(callID, body, options) {
    return this._client.post(path`/realtime/calls/${callID}/accept`, {
      body,
      ...options,
      headers: buildHeaders([{ Accept: "*/*" }, options?.headers])
    });
  }
  /**
   * End an active Realtime API call, whether it was initiated over SIP or WebRTC.
   *
   * @example
   * ```ts
   * await client.realtime.calls.hangup('call_id');
   * ```
   */
  hangup(callID, options) {
    return this._client.post(path`/realtime/calls/${callID}/hangup`, {
      ...options,
      headers: buildHeaders([{ Accept: "*/*" }, options?.headers])
    });
  }
  /**
   * Transfer an active SIP call to a new destination using the SIP REFER verb.
   *
   * @example
   * ```ts
   * await client.realtime.calls.refer('call_id', {
   *   target_uri: 'tel:+14155550123',
   * });
   * ```
   */
  refer(callID, body, options) {
    return this._client.post(path`/realtime/calls/${callID}/refer`, {
      body,
      ...options,
      headers: buildHeaders([{ Accept: "*/*" }, options?.headers])
    });
  }
  /**
   * Decline an incoming SIP call by returning a SIP status code to the caller.
   *
   * @example
   * ```ts
   * await client.realtime.calls.reject('call_id');
   * ```
   */
  reject(callID, body = {}, options) {
    return this._client.post(path`/realtime/calls/${callID}/reject`, {
      body,
      ...options,
      headers: buildHeaders([{ Accept: "*/*" }, options?.headers])
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/realtime/client-secrets.mjs
var ClientSecrets = class extends APIResource {
  /**
   * Create a Realtime client secret with an associated session configuration.
   *
   * Client secrets are short-lived tokens that can be passed to a client app, such
   * as a web frontend or mobile client, which grants access to the Realtime API
   * without leaking your main API key. You can configure a custom TTL for each
   * client secret.
   *
   * You can also attach session configuration options to the client secret, which
   * will be applied to any sessions created using that client secret, but these can
   * also be overridden by the client connection.
   *
   * [Learn more about authentication with client secrets over WebRTC](https://platform.openai.com/docs/guides/realtime-webrtc).
   *
   * Returns the created client secret and the effective session object. The client
   * secret is a string that looks like `ek_1234`.
   *
   * @example
   * ```ts
   * const clientSecret =
   *   await client.realtime.clientSecrets.create();
   * ```
   */
  create(body, options) {
    return this._client.post("/realtime/client_secrets", { body, ...options });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/realtime/realtime.mjs
var Realtime2 = class extends APIResource {
  constructor() {
    super(...arguments);
    this.clientSecrets = new ClientSecrets(this._client);
    this.calls = new Calls(this._client);
  }
};
Realtime2.ClientSecrets = ClientSecrets;
Realtime2.Calls = Calls;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/ResponsesParser.mjs
function maybeParseResponse(response, params) {
  if (!params || !hasAutoParseableInput2(params)) {
    return {
      ...response,
      output_parsed: null,
      output: response.output.map((item) => {
        if (item.type === "function_call") {
          return {
            ...item,
            parsed_arguments: null
          };
        }
        if (item.type === "message") {
          return {
            ...item,
            content: item.content.map((content) => ({
              ...content,
              parsed: null
            }))
          };
        } else {
          return item;
        }
      })
    };
  }
  return parseResponse(response, params);
}
function parseResponse(response, params) {
  const output = response.output.map((item) => {
    if (item.type === "function_call") {
      return {
        ...item,
        parsed_arguments: parseToolCall2(params, item)
      };
    }
    if (item.type === "message") {
      const content = item.content.map((content2) => {
        if (content2.type === "output_text") {
          return {
            ...content2,
            parsed: parseTextFormat(params, content2.text)
          };
        }
        return content2;
      });
      return {
        ...item,
        content
      };
    }
    return item;
  });
  const parsed = Object.assign({}, response, { output });
  if (!Object.getOwnPropertyDescriptor(response, "output_text")) {
    addOutputText(parsed);
  }
  Object.defineProperty(parsed, "output_parsed", {
    enumerable: true,
    get() {
      for (const output2 of parsed.output) {
        if (output2.type !== "message") {
          continue;
        }
        for (const content of output2.content) {
          if (content.type === "output_text" && content.parsed !== null) {
            return content.parsed;
          }
        }
      }
      return null;
    }
  });
  return parsed;
}
function parseTextFormat(params, content) {
  if (params.text?.format?.type !== "json_schema") {
    return null;
  }
  if ("$parseRaw" in params.text?.format) {
    const text_format = params.text?.format;
    return text_format.$parseRaw(content);
  }
  return JSON.parse(content);
}
function hasAutoParseableInput2(params) {
  if (isAutoParsableResponseFormat(params.text?.format)) {
    return true;
  }
  return false;
}
function isAutoParsableTool2(tool2) {
  return tool2?.["$brand"] === "auto-parseable-tool";
}
function getInputToolByName(input_tools, name) {
  return input_tools.find((tool2) => tool2.type === "function" && tool2.name === name);
}
function parseToolCall2(params, toolCall) {
  const inputTool = getInputToolByName(params.tools ?? [], toolCall.name);
  return {
    ...toolCall,
    ...toolCall,
    parsed_arguments: isAutoParsableTool2(inputTool) ? inputTool.$parseRaw(toolCall.arguments) : inputTool?.strict ? JSON.parse(toolCall.arguments) : null
  };
}
function addOutputText(rsp) {
  const texts = [];
  for (const output of rsp.output) {
    if (output.type !== "message") {
      continue;
    }
    for (const content of output.content) {
      if (content.type === "output_text") {
        texts.push(content.text);
      }
    }
  }
  rsp.output_text = texts.join("");
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/responses/ResponseStream.mjs
var _ResponseStream_instances;
var _ResponseStream_params;
var _ResponseStream_currentResponseSnapshot;
var _ResponseStream_finalResponse;
var _ResponseStream_beginRequest;
var _ResponseStream_addEvent;
var _ResponseStream_endRequest;
var _ResponseStream_accumulateResponse;
var ResponseStream = class _ResponseStream extends EventStream {
  constructor(params) {
    super();
    _ResponseStream_instances.add(this);
    _ResponseStream_params.set(this, void 0);
    _ResponseStream_currentResponseSnapshot.set(this, void 0);
    _ResponseStream_finalResponse.set(this, void 0);
    __classPrivateFieldSet(this, _ResponseStream_params, params, "f");
  }
  static createResponse(client, params, options) {
    const runner = new _ResponseStream(params);
    runner._run(() => runner._createOrRetrieveResponse(client, params, {
      ...options,
      headers: { ...options?.headers, "X-Stainless-Helper-Method": "stream" }
    }));
    return runner;
  }
  async _createOrRetrieveResponse(client, params, options) {
    const signal = options?.signal;
    if (signal) {
      if (signal.aborted)
        this.controller.abort();
      signal.addEventListener("abort", () => this.controller.abort());
    }
    __classPrivateFieldGet(this, _ResponseStream_instances, "m", _ResponseStream_beginRequest).call(this);
    let stream;
    let starting_after = null;
    if ("response_id" in params) {
      stream = await client.responses.retrieve(params.response_id, { stream: true }, { ...options, signal: this.controller.signal, stream: true });
      starting_after = params.starting_after ?? null;
    } else {
      stream = await client.responses.create({ ...params, stream: true }, { ...options, signal: this.controller.signal });
    }
    this._connected();
    for await (const event of stream) {
      __classPrivateFieldGet(this, _ResponseStream_instances, "m", _ResponseStream_addEvent).call(this, event, starting_after);
    }
    if (stream.controller.signal?.aborted) {
      throw new APIUserAbortError();
    }
    return __classPrivateFieldGet(this, _ResponseStream_instances, "m", _ResponseStream_endRequest).call(this);
  }
  [(_ResponseStream_params = /* @__PURE__ */ new WeakMap(), _ResponseStream_currentResponseSnapshot = /* @__PURE__ */ new WeakMap(), _ResponseStream_finalResponse = /* @__PURE__ */ new WeakMap(), _ResponseStream_instances = /* @__PURE__ */ new WeakSet(), _ResponseStream_beginRequest = function _ResponseStream_beginRequest2() {
    if (this.ended)
      return;
    __classPrivateFieldSet(this, _ResponseStream_currentResponseSnapshot, void 0, "f");
  }, _ResponseStream_addEvent = function _ResponseStream_addEvent2(event, starting_after) {
    if (this.ended)
      return;
    const maybeEmit = (name, event2) => {
      if (starting_after == null || event2.sequence_number > starting_after) {
        this._emit(name, event2);
      }
    };
    const response = __classPrivateFieldGet(this, _ResponseStream_instances, "m", _ResponseStream_accumulateResponse).call(this, event);
    maybeEmit("event", event);
    switch (event.type) {
      case "response.output_text.delta": {
        const output = response.output[event.output_index];
        if (!output) {
          throw new OpenAIError(`missing output at index ${event.output_index}`);
        }
        if (output.type === "message") {
          const content = output.content[event.content_index];
          if (!content) {
            throw new OpenAIError(`missing content at index ${event.content_index}`);
          }
          if (content.type !== "output_text") {
            throw new OpenAIError(`expected content to be 'output_text', got ${content.type}`);
          }
          maybeEmit("response.output_text.delta", {
            ...event,
            snapshot: content.text
          });
        }
        break;
      }
      case "response.function_call_arguments.delta": {
        const output = response.output[event.output_index];
        if (!output) {
          throw new OpenAIError(`missing output at index ${event.output_index}`);
        }
        if (output.type === "function_call") {
          maybeEmit("response.function_call_arguments.delta", {
            ...event,
            snapshot: output.arguments
          });
        }
        break;
      }
      default:
        maybeEmit(event.type, event);
        break;
    }
  }, _ResponseStream_endRequest = function _ResponseStream_endRequest2() {
    if (this.ended) {
      throw new OpenAIError(`stream has ended, this shouldn't happen`);
    }
    const snapshot = __classPrivateFieldGet(this, _ResponseStream_currentResponseSnapshot, "f");
    if (!snapshot) {
      throw new OpenAIError(`request ended without sending any events`);
    }
    __classPrivateFieldSet(this, _ResponseStream_currentResponseSnapshot, void 0, "f");
    const parsedResponse = finalizeResponse(snapshot, __classPrivateFieldGet(this, _ResponseStream_params, "f"));
    __classPrivateFieldSet(this, _ResponseStream_finalResponse, parsedResponse, "f");
    return parsedResponse;
  }, _ResponseStream_accumulateResponse = function _ResponseStream_accumulateResponse2(event) {
    let snapshot = __classPrivateFieldGet(this, _ResponseStream_currentResponseSnapshot, "f");
    if (!snapshot) {
      if (event.type !== "response.created") {
        throw new OpenAIError(`When snapshot hasn't been set yet, expected 'response.created' event, got ${event.type}`);
      }
      snapshot = __classPrivateFieldSet(this, _ResponseStream_currentResponseSnapshot, event.response, "f");
      return snapshot;
    }
    switch (event.type) {
      case "response.output_item.added": {
        snapshot.output.push(event.item);
        break;
      }
      case "response.content_part.added": {
        const output = snapshot.output[event.output_index];
        if (!output) {
          throw new OpenAIError(`missing output at index ${event.output_index}`);
        }
        const type = output.type;
        const part = event.part;
        if (type === "message" && part.type !== "reasoning_text") {
          output.content.push(part);
        } else if (type === "reasoning" && part.type === "reasoning_text") {
          if (!output.content) {
            output.content = [];
          }
          output.content.push(part);
        }
        break;
      }
      case "response.output_text.delta": {
        const output = snapshot.output[event.output_index];
        if (!output) {
          throw new OpenAIError(`missing output at index ${event.output_index}`);
        }
        if (output.type === "message") {
          const content = output.content[event.content_index];
          if (!content) {
            throw new OpenAIError(`missing content at index ${event.content_index}`);
          }
          if (content.type !== "output_text") {
            throw new OpenAIError(`expected content to be 'output_text', got ${content.type}`);
          }
          content.text += event.delta;
        }
        break;
      }
      case "response.function_call_arguments.delta": {
        const output = snapshot.output[event.output_index];
        if (!output) {
          throw new OpenAIError(`missing output at index ${event.output_index}`);
        }
        if (output.type === "function_call") {
          output.arguments += event.delta;
        }
        break;
      }
      case "response.reasoning_text.delta": {
        const output = snapshot.output[event.output_index];
        if (!output) {
          throw new OpenAIError(`missing output at index ${event.output_index}`);
        }
        if (output.type === "reasoning") {
          const content = output.content?.[event.content_index];
          if (!content) {
            throw new OpenAIError(`missing content at index ${event.content_index}`);
          }
          if (content.type !== "reasoning_text") {
            throw new OpenAIError(`expected content to be 'reasoning_text', got ${content.type}`);
          }
          content.text += event.delta;
        }
        break;
      }
      case "response.completed": {
        __classPrivateFieldSet(this, _ResponseStream_currentResponseSnapshot, event.response, "f");
        break;
      }
    }
    return snapshot;
  }, Symbol.asyncIterator)]() {
    const pushQueue = [];
    const readQueue = [];
    let done = false;
    this.on("event", (event) => {
      const reader = readQueue.shift();
      if (reader) {
        reader.resolve(event);
      } else {
        pushQueue.push(event);
      }
    });
    this.on("end", () => {
      done = true;
      for (const reader of readQueue) {
        reader.resolve(void 0);
      }
      readQueue.length = 0;
    });
    this.on("abort", (err) => {
      done = true;
      for (const reader of readQueue) {
        reader.reject(err);
      }
      readQueue.length = 0;
    });
    this.on("error", (err) => {
      done = true;
      for (const reader of readQueue) {
        reader.reject(err);
      }
      readQueue.length = 0;
    });
    return {
      next: async () => {
        if (!pushQueue.length) {
          if (done) {
            return { value: void 0, done: true };
          }
          return new Promise((resolve, reject) => readQueue.push({ resolve, reject })).then((event2) => event2 ? { value: event2, done: false } : { value: void 0, done: true });
        }
        const event = pushQueue.shift();
        return { value: event, done: false };
      },
      return: async () => {
        this.abort();
        return { value: void 0, done: true };
      }
    };
  }
  /**
   * @returns a promise that resolves with the final Response, or rejects
   * if an error occurred or the stream ended prematurely without producing a REsponse.
   */
  async finalResponse() {
    await this.done();
    const response = __classPrivateFieldGet(this, _ResponseStream_finalResponse, "f");
    if (!response)
      throw new OpenAIError("stream ended without producing a ChatCompletion");
    return response;
  }
};
function finalizeResponse(snapshot, params) {
  return maybeParseResponse(snapshot, params);
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/responses/input-items.mjs
var InputItems = class extends APIResource {
  /**
   * Returns a list of input items for a given response.
   *
   * @example
   * ```ts
   * // Automatically fetches more pages as needed.
   * for await (const responseItem of client.responses.inputItems.list(
   *   'response_id',
   * )) {
   *   // ...
   * }
   * ```
   */
  list(responseID, query = {}, options) {
    return this._client.getAPIList(path`/responses/${responseID}/input_items`, CursorPage, { query, ...options });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/responses/input-tokens.mjs
var InputTokens = class extends APIResource {
  /**
   * Returns input token counts of the request.
   *
   * Returns an object with `object` set to `response.input_tokens` and an
   * `input_tokens` count.
   *
   * @example
   * ```ts
   * const response = await client.responses.inputTokens.count();
   * ```
   */
  count(body = {}, options) {
    return this._client.post("/responses/input_tokens", { body, ...options });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/responses/responses.mjs
var Responses = class extends APIResource {
  constructor() {
    super(...arguments);
    this.inputItems = new InputItems(this._client);
    this.inputTokens = new InputTokens(this._client);
  }
  create(body, options) {
    return this._client.post("/responses", { body, ...options, stream: body.stream ?? false })._thenUnwrap((rsp) => {
      if ("object" in rsp && rsp.object === "response") {
        addOutputText(rsp);
      }
      return rsp;
    });
  }
  retrieve(responseID, query = {}, options) {
    return this._client.get(path`/responses/${responseID}`, {
      query,
      ...options,
      stream: query?.stream ?? false
    })._thenUnwrap((rsp) => {
      if ("object" in rsp && rsp.object === "response") {
        addOutputText(rsp);
      }
      return rsp;
    });
  }
  /**
   * Deletes a model response with the given ID.
   *
   * @example
   * ```ts
   * await client.responses.delete(
   *   'resp_677efb5139a88190b512bc3fef8e535d',
   * );
   * ```
   */
  delete(responseID, options) {
    return this._client.delete(path`/responses/${responseID}`, {
      ...options,
      headers: buildHeaders([{ Accept: "*/*" }, options?.headers])
    });
  }
  parse(body, options) {
    return this._client.responses.create(body, options)._thenUnwrap((response) => parseResponse(response, body));
  }
  /**
   * Creates a model response stream
   */
  stream(body, options) {
    return ResponseStream.createResponse(this._client, body, options);
  }
  /**
   * Cancels a model response with the given ID. Only responses created with the
   * `background` parameter set to `true` can be cancelled.
   * [Learn more](https://platform.openai.com/docs/guides/background).
   *
   * @example
   * ```ts
   * const response = await client.responses.cancel(
   *   'resp_677efb5139a88190b512bc3fef8e535d',
   * );
   * ```
   */
  cancel(responseID, options) {
    return this._client.post(path`/responses/${responseID}/cancel`, options);
  }
  /**
   * Compact a conversation. Returns a compacted response object.
   *
   * Learn when and how to compact long-running conversations in the
   * [conversation state guide](https://platform.openai.com/docs/guides/conversation-state#managing-the-context-window).
   * For ZDR-compatible compaction details, see
   * [Compaction (advanced)](https://platform.openai.com/docs/guides/conversation-state#compaction-advanced).
   *
   * @example
   * ```ts
   * const compactedResponse = await client.responses.compact({
   *   model: 'gpt-5.2',
   * });
   * ```
   */
  compact(body, options) {
    return this._client.post("/responses/compact", { body, ...options });
  }
};
Responses.InputItems = InputItems;
Responses.InputTokens = InputTokens;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/skills/content.mjs
var Content2 = class extends APIResource {
  /**
   * Download a skill zip bundle by its ID.
   */
  retrieve(skillID, options) {
    return this._client.get(path`/skills/${skillID}/content`, {
      ...options,
      headers: buildHeaders([{ Accept: "application/binary" }, options?.headers]),
      __binaryResponse: true
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/skills/versions/content.mjs
var Content3 = class extends APIResource {
  /**
   * Download a skill version zip bundle.
   */
  retrieve(version, params, options) {
    const { skill_id } = params;
    return this._client.get(path`/skills/${skill_id}/versions/${version}/content`, {
      ...options,
      headers: buildHeaders([{ Accept: "application/binary" }, options?.headers]),
      __binaryResponse: true
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/skills/versions/versions.mjs
var Versions = class extends APIResource {
  constructor() {
    super(...arguments);
    this.content = new Content3(this._client);
  }
  /**
   * Create a new immutable skill version.
   */
  create(skillID, body = {}, options) {
    return this._client.post(path`/skills/${skillID}/versions`, maybeMultipartFormRequestOptions({ body, ...options }, this._client));
  }
  /**
   * Get a specific skill version.
   */
  retrieve(version, params, options) {
    const { skill_id } = params;
    return this._client.get(path`/skills/${skill_id}/versions/${version}`, options);
  }
  /**
   * List skill versions for a skill.
   */
  list(skillID, query = {}, options) {
    return this._client.getAPIList(path`/skills/${skillID}/versions`, CursorPage, {
      query,
      ...options
    });
  }
  /**
   * Delete a skill version.
   */
  delete(version, params, options) {
    const { skill_id } = params;
    return this._client.delete(path`/skills/${skill_id}/versions/${version}`, options);
  }
};
Versions.Content = Content3;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/skills/skills.mjs
var Skills = class extends APIResource {
  constructor() {
    super(...arguments);
    this.content = new Content2(this._client);
    this.versions = new Versions(this._client);
  }
  /**
   * Create a new skill.
   */
  create(body = {}, options) {
    return this._client.post("/skills", maybeMultipartFormRequestOptions({ body, ...options }, this._client));
  }
  /**
   * Get a skill by its ID.
   */
  retrieve(skillID, options) {
    return this._client.get(path`/skills/${skillID}`, options);
  }
  /**
   * Update the default version pointer for a skill.
   */
  update(skillID, body, options) {
    return this._client.post(path`/skills/${skillID}`, { body, ...options });
  }
  /**
   * List all skills for the current project.
   */
  list(query = {}, options) {
    return this._client.getAPIList("/skills", CursorPage, { query, ...options });
  }
  /**
   * Delete a skill by its ID.
   */
  delete(skillID, options) {
    return this._client.delete(path`/skills/${skillID}`, options);
  }
};
Skills.Content = Content2;
Skills.Versions = Versions;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/uploads/parts.mjs
var Parts = class extends APIResource {
  /**
   * Adds a
   * [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an
   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object.
   * A Part represents a chunk of bytes from the file you are trying to upload.
   *
   * Each Part can be at most 64 MB, and you can add Parts until you hit the Upload
   * maximum of 8 GB.
   *
   * It is possible to add multiple Parts in parallel. You can decide the intended
   * order of the Parts when you
   * [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).
   */
  create(uploadID, body, options) {
    return this._client.post(path`/uploads/${uploadID}/parts`, multipartFormRequestOptions({ body, ...options }, this._client));
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/uploads/uploads.mjs
var Uploads = class extends APIResource {
  constructor() {
    super(...arguments);
    this.parts = new Parts(this._client);
  }
  /**
   * Creates an intermediate
   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object
   * that you can add
   * [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.
   * Currently, an Upload can accept at most 8 GB in total and expires after an hour
   * after you create it.
   *
   * Once you complete the Upload, we will create a
   * [File](https://platform.openai.com/docs/api-reference/files/object) object that
   * contains all the parts you uploaded. This File is usable in the rest of our
   * platform as a regular File object.
   *
   * For certain `purpose` values, the correct `mime_type` must be specified. Please
   * refer to documentation for the
   * [supported MIME types for your use case](https://platform.openai.com/docs/assistants/tools/file-search#supported-files).
   *
   * For guidance on the proper filename extensions for each purpose, please follow
   * the documentation on
   * [creating a File](https://platform.openai.com/docs/api-reference/files/create).
   *
   * Returns the Upload object with status `pending`.
   */
  create(body, options) {
    return this._client.post("/uploads", { body, ...options });
  }
  /**
   * Cancels the Upload. No Parts may be added after an Upload is cancelled.
   *
   * Returns the Upload object with status `cancelled`.
   */
  cancel(uploadID, options) {
    return this._client.post(path`/uploads/${uploadID}/cancel`, options);
  }
  /**
   * Completes the
   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object).
   *
   * Within the returned Upload object, there is a nested
   * [File](https://platform.openai.com/docs/api-reference/files/object) object that
   * is ready to use in the rest of the platform.
   *
   * You can specify the order of the Parts by passing in an ordered list of the Part
   * IDs.
   *
   * The number of bytes uploaded upon completion must match the number of bytes
   * initially specified when creating the Upload object. No Parts may be added after
   * an Upload is completed. Returns the Upload object with status `completed`,
   * including an additional `file` property containing the created usable File
   * object.
   */
  complete(uploadID, body, options) {
    return this._client.post(path`/uploads/${uploadID}/complete`, { body, ...options });
  }
};
Uploads.Parts = Parts;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/Util.mjs
var allSettledWithThrow = async (promises) => {
  const results = await Promise.allSettled(promises);
  const rejected = results.filter((result) => result.status === "rejected");
  if (rejected.length) {
    for (const result of rejected) {
      console.error(result.reason);
    }
    throw new Error(`${rejected.length} promise(s) failed - see the above errors`);
  }
  const values = [];
  for (const result of results) {
    if (result.status === "fulfilled") {
      values.push(result.value);
    }
  }
  return values;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/vector-stores/file-batches.mjs
var FileBatches = class extends APIResource {
  /**
   * Create a vector store file batch.
   */
  create(vectorStoreID, body, options) {
    return this._client.post(path`/vector_stores/${vectorStoreID}/file_batches`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Retrieves a vector store file batch.
   */
  retrieve(batchID, params, options) {
    const { vector_store_id } = params;
    return this._client.get(path`/vector_stores/${vector_store_id}/file_batches/${batchID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Cancel a vector store file batch. This attempts to cancel the processing of
   * files in this batch as soon as possible.
   */
  cancel(batchID, params, options) {
    const { vector_store_id } = params;
    return this._client.post(path`/vector_stores/${vector_store_id}/file_batches/${batchID}/cancel`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Create a vector store batch and poll until all files have been processed.
   */
  async createAndPoll(vectorStoreId, body, options) {
    const batch = await this.create(vectorStoreId, body);
    return await this.poll(vectorStoreId, batch.id, options);
  }
  /**
   * Returns a list of vector store files in a batch.
   */
  listFiles(batchID, params, options) {
    const { vector_store_id, ...query } = params;
    return this._client.getAPIList(path`/vector_stores/${vector_store_id}/file_batches/${batchID}/files`, CursorPage, { query, ...options, headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers]) });
  }
  /**
   * Wait for the given file batch to be processed.
   *
   * Note: this will return even if one of the files failed to process, you need to
   * check batch.file_counts.failed_count to handle this case.
   */
  async poll(vectorStoreID, batchID, options) {
    const headers = buildHeaders([
      options?.headers,
      {
        "X-Stainless-Poll-Helper": "true",
        "X-Stainless-Custom-Poll-Interval": options?.pollIntervalMs?.toString() ?? void 0
      }
    ]);
    while (true) {
      const { data: batch, response } = await this.retrieve(batchID, { vector_store_id: vectorStoreID }, {
        ...options,
        headers
      }).withResponse();
      switch (batch.status) {
        case "in_progress":
          let sleepInterval = 5e3;
          if (options?.pollIntervalMs) {
            sleepInterval = options.pollIntervalMs;
          } else {
            const headerInterval = response.headers.get("openai-poll-after-ms");
            if (headerInterval) {
              const headerIntervalMs = parseInt(headerInterval);
              if (!isNaN(headerIntervalMs)) {
                sleepInterval = headerIntervalMs;
              }
            }
          }
          await sleep(sleepInterval);
          break;
        case "failed":
        case "cancelled":
        case "completed":
          return batch;
      }
    }
  }
  /**
   * Uploads the given files concurrently and then creates a vector store file batch.
   *
   * The concurrency limit is configurable using the `maxConcurrency` parameter.
   */
  async uploadAndPoll(vectorStoreId, { files, fileIds = [] }, options) {
    if (files == null || files.length == 0) {
      throw new Error(`No \`files\` provided to process. If you've already uploaded files you should use \`.createAndPoll()\` instead`);
    }
    const configuredConcurrency = options?.maxConcurrency ?? 5;
    const concurrencyLimit = Math.min(configuredConcurrency, files.length);
    const client = this._client;
    const fileIterator = files.values();
    const allFileIds = [...fileIds];
    async function processFiles(iterator) {
      for (let item of iterator) {
        const fileObj = await client.files.create({ file: item, purpose: "assistants" }, options);
        allFileIds.push(fileObj.id);
      }
    }
    const workers = Array(concurrencyLimit).fill(fileIterator).map(processFiles);
    await allSettledWithThrow(workers);
    return await this.createAndPoll(vectorStoreId, {
      file_ids: allFileIds
    });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/vector-stores/files.mjs
var Files3 = class extends APIResource {
  /**
   * Create a vector store file by attaching a
   * [File](https://platform.openai.com/docs/api-reference/files) to a
   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).
   */
  create(vectorStoreID, body, options) {
    return this._client.post(path`/vector_stores/${vectorStoreID}/files`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Retrieves a vector store file.
   */
  retrieve(fileID, params, options) {
    const { vector_store_id } = params;
    return this._client.get(path`/vector_stores/${vector_store_id}/files/${fileID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Update attributes on a vector store file.
   */
  update(fileID, params, options) {
    const { vector_store_id, ...body } = params;
    return this._client.post(path`/vector_stores/${vector_store_id}/files/${fileID}`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Returns a list of vector store files.
   */
  list(vectorStoreID, query = {}, options) {
    return this._client.getAPIList(path`/vector_stores/${vectorStoreID}/files`, CursorPage, {
      query,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Delete a vector store file. This will remove the file from the vector store but
   * the file itself will not be deleted. To delete the file, use the
   * [delete file](https://platform.openai.com/docs/api-reference/files/delete)
   * endpoint.
   */
  delete(fileID, params, options) {
    const { vector_store_id } = params;
    return this._client.delete(path`/vector_stores/${vector_store_id}/files/${fileID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Attach a file to the given vector store and wait for it to be processed.
   */
  async createAndPoll(vectorStoreId, body, options) {
    const file2 = await this.create(vectorStoreId, body, options);
    return await this.poll(vectorStoreId, file2.id, options);
  }
  /**
   * Wait for the vector store file to finish processing.
   *
   * Note: this will return even if the file failed to process, you need to check
   * file.last_error and file.status to handle these cases
   */
  async poll(vectorStoreID, fileID, options) {
    const headers = buildHeaders([
      options?.headers,
      {
        "X-Stainless-Poll-Helper": "true",
        "X-Stainless-Custom-Poll-Interval": options?.pollIntervalMs?.toString() ?? void 0
      }
    ]);
    while (true) {
      const fileResponse = await this.retrieve(fileID, {
        vector_store_id: vectorStoreID
      }, { ...options, headers }).withResponse();
      const file2 = fileResponse.data;
      switch (file2.status) {
        case "in_progress":
          let sleepInterval = 5e3;
          if (options?.pollIntervalMs) {
            sleepInterval = options.pollIntervalMs;
          } else {
            const headerInterval = fileResponse.response.headers.get("openai-poll-after-ms");
            if (headerInterval) {
              const headerIntervalMs = parseInt(headerInterval);
              if (!isNaN(headerIntervalMs)) {
                sleepInterval = headerIntervalMs;
              }
            }
          }
          await sleep(sleepInterval);
          break;
        case "failed":
        case "completed":
          return file2;
      }
    }
  }
  /**
   * Upload a file to the `files` API and then attach it to the given vector store.
   *
   * Note the file will be asynchronously processed (you can use the alternative
   * polling helper method to wait for processing to complete).
   */
  async upload(vectorStoreId, file2, options) {
    const fileInfo = await this._client.files.create({ file: file2, purpose: "assistants" }, options);
    return this.create(vectorStoreId, { file_id: fileInfo.id }, options);
  }
  /**
   * Add a file to a vector store and poll until processing is complete.
   */
  async uploadAndPoll(vectorStoreId, file2, options) {
    const fileInfo = await this.upload(vectorStoreId, file2, options);
    return await this.poll(vectorStoreId, fileInfo.id, options);
  }
  /**
   * Retrieve the parsed contents of a vector store file.
   */
  content(fileID, params, options) {
    const { vector_store_id } = params;
    return this._client.getAPIList(path`/vector_stores/${vector_store_id}/files/${fileID}/content`, Page, { ...options, headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers]) });
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/vector-stores/vector-stores.mjs
var VectorStores = class extends APIResource {
  constructor() {
    super(...arguments);
    this.files = new Files3(this._client);
    this.fileBatches = new FileBatches(this._client);
  }
  /**
   * Create a vector store.
   */
  create(body, options) {
    return this._client.post("/vector_stores", {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Retrieves a vector store.
   */
  retrieve(vectorStoreID, options) {
    return this._client.get(path`/vector_stores/${vectorStoreID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Modifies a vector store.
   */
  update(vectorStoreID, body, options) {
    return this._client.post(path`/vector_stores/${vectorStoreID}`, {
      body,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Returns a list of vector stores.
   */
  list(query = {}, options) {
    return this._client.getAPIList("/vector_stores", CursorPage, {
      query,
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Delete a vector store.
   */
  delete(vectorStoreID, options) {
    return this._client.delete(path`/vector_stores/${vectorStoreID}`, {
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
  /**
   * Search a vector store for relevant chunks based on a query and file attributes
   * filter.
   */
  search(vectorStoreID, body, options) {
    return this._client.getAPIList(path`/vector_stores/${vectorStoreID}/search`, Page, {
      body,
      method: "post",
      ...options,
      headers: buildHeaders([{ "OpenAI-Beta": "assistants=v2" }, options?.headers])
    });
  }
};
VectorStores.Files = Files3;
VectorStores.FileBatches = FileBatches;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/videos.mjs
var Videos = class extends APIResource {
  /**
   * Create a new video generation job from a prompt and optional reference assets.
   */
  create(body, options) {
    return this._client.post("/videos", maybeMultipartFormRequestOptions({ body, ...options }, this._client));
  }
  /**
   * Fetch the latest metadata for a generated video.
   */
  retrieve(videoID, options) {
    return this._client.get(path`/videos/${videoID}`, options);
  }
  /**
   * List recently generated videos for the current project.
   */
  list(query = {}, options) {
    return this._client.getAPIList("/videos", ConversationCursorPage, { query, ...options });
  }
  /**
   * Permanently delete a completed or failed video and its stored assets.
   */
  delete(videoID, options) {
    return this._client.delete(path`/videos/${videoID}`, options);
  }
  /**
   * Download the generated video bytes or a derived preview asset.
   *
   * Streams the rendered video content for the specified video job.
   */
  downloadContent(videoID, query = {}, options) {
    return this._client.get(path`/videos/${videoID}/content`, {
      query,
      ...options,
      headers: buildHeaders([{ Accept: "application/binary" }, options?.headers]),
      __binaryResponse: true
    });
  }
  /**
   * Create a remix of a completed video using a refreshed prompt.
   */
  remix(videoID, body, options) {
    return this._client.post(path`/videos/${videoID}/remix`, maybeMultipartFormRequestOptions({ body, ...options }, this._client));
  }
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/resources/webhooks/webhooks.mjs
var _Webhooks_instances;
var _Webhooks_validateSecret;
var _Webhooks_getRequiredHeader;
var Webhooks = class extends APIResource {
  constructor() {
    super(...arguments);
    _Webhooks_instances.add(this);
  }
  /**
   * Validates that the given payload was sent by OpenAI and parses the payload.
   */
  async unwrap(payload, headers, secret = this._client.webhookSecret, tolerance = 300) {
    await this.verifySignature(payload, headers, secret, tolerance);
    return JSON.parse(payload);
  }
  /**
   * Validates whether or not the webhook payload was sent by OpenAI.
   *
   * An error will be raised if the webhook payload was not sent by OpenAI.
   *
   * @param payload - The webhook payload
   * @param headers - The webhook headers
   * @param secret - The webhook secret (optional, will use client secret if not provided)
   * @param tolerance - Maximum age of the webhook in seconds (default: 300 = 5 minutes)
   */
  async verifySignature(payload, headers, secret = this._client.webhookSecret, tolerance = 300) {
    if (typeof crypto === "undefined" || typeof crypto.subtle.importKey !== "function" || typeof crypto.subtle.verify !== "function") {
      throw new Error("Webhook signature verification is only supported when the `crypto` global is defined");
    }
    __classPrivateFieldGet(this, _Webhooks_instances, "m", _Webhooks_validateSecret).call(this, secret);
    const headersObj = buildHeaders([headers]).values;
    const signatureHeader = __classPrivateFieldGet(this, _Webhooks_instances, "m", _Webhooks_getRequiredHeader).call(this, headersObj, "webhook-signature");
    const timestamp = __classPrivateFieldGet(this, _Webhooks_instances, "m", _Webhooks_getRequiredHeader).call(this, headersObj, "webhook-timestamp");
    const webhookId = __classPrivateFieldGet(this, _Webhooks_instances, "m", _Webhooks_getRequiredHeader).call(this, headersObj, "webhook-id");
    const timestampSeconds = parseInt(timestamp, 10);
    if (isNaN(timestampSeconds)) {
      throw new InvalidWebhookSignatureError("Invalid webhook timestamp format");
    }
    const nowSeconds = Math.floor(Date.now() / 1e3);
    if (nowSeconds - timestampSeconds > tolerance) {
      throw new InvalidWebhookSignatureError("Webhook timestamp is too old");
    }
    if (timestampSeconds > nowSeconds + tolerance) {
      throw new InvalidWebhookSignatureError("Webhook timestamp is too new");
    }
    const signatures = signatureHeader.split(" ").map((part) => part.startsWith("v1,") ? part.substring(3) : part);
    const decodedSecret = secret.startsWith("whsec_") ? Buffer.from(secret.replace("whsec_", ""), "base64") : Buffer.from(secret, "utf-8");
    const signedPayload = webhookId ? `${webhookId}.${timestamp}.${payload}` : `${timestamp}.${payload}`;
    const key = await crypto.subtle.importKey("raw", decodedSecret, { name: "HMAC", hash: "SHA-256" }, false, ["verify"]);
    for (const signature of signatures) {
      try {
        const signatureBytes = Buffer.from(signature, "base64");
        const isValid = await crypto.subtle.verify("HMAC", key, signatureBytes, new TextEncoder().encode(signedPayload));
        if (isValid) {
          return;
        }
      } catch {
        continue;
      }
    }
    throw new InvalidWebhookSignatureError("The given webhook signature does not match the expected signature");
  }
};
_Webhooks_instances = /* @__PURE__ */ new WeakSet(), _Webhooks_validateSecret = function _Webhooks_validateSecret2(secret) {
  if (typeof secret !== "string" || secret.length === 0) {
    throw new Error(`The webhook secret must either be set using the env var, OPENAI_WEBHOOK_SECRET, on the client class, OpenAI({ webhookSecret: '123' }), or passed to this function`);
  }
}, _Webhooks_getRequiredHeader = function _Webhooks_getRequiredHeader2(headers, name) {
  if (!headers) {
    throw new Error(`Headers are required`);
  }
  const value = headers.get(name);
  if (value === null || value === void 0) {
    throw new Error(`Missing required header: ${name}`);
  }
  return value;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/client.mjs
var _OpenAI_instances;
var _a2;
var _OpenAI_encoder;
var _OpenAI_baseURLOverridden;
var OpenAI = class {
  /**
   * API Client for interfacing with the OpenAI API.
   *
   * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]
   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]
   * @param {string | null | undefined} [opts.project=process.env['OPENAI_PROJECT_ID'] ?? null]
   * @param {string | null | undefined} [opts.webhookSecret=process.env['OPENAI_WEBHOOK_SECRET'] ?? null]
   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.
   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.
   * @param {MergedRequestInit} [opts.fetchOptions] - Additional `RequestInit` options to be passed to `fetch` calls.
   * @param {Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.
   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.
   * @param {HeadersLike} opts.defaultHeaders - Default headers to include with every request to the API.
   * @param {Record<string, string | undefined>} opts.defaultQuery - Default query parameters to include with every request to the API.
   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.
   */
  constructor({ baseURL = readEnv("OPENAI_BASE_URL"), apiKey = readEnv("OPENAI_API_KEY"), organization = readEnv("OPENAI_ORG_ID") ?? null, project = readEnv("OPENAI_PROJECT_ID") ?? null, webhookSecret = readEnv("OPENAI_WEBHOOK_SECRET") ?? null, ...opts } = {}) {
    _OpenAI_instances.add(this);
    _OpenAI_encoder.set(this, void 0);
    this.completions = new Completions2(this);
    this.chat = new Chat(this);
    this.embeddings = new Embeddings(this);
    this.files = new Files2(this);
    this.images = new Images(this);
    this.audio = new Audio(this);
    this.moderations = new Moderations(this);
    this.models = new Models(this);
    this.fineTuning = new FineTuning(this);
    this.graders = new Graders2(this);
    this.vectorStores = new VectorStores(this);
    this.webhooks = new Webhooks(this);
    this.beta = new Beta(this);
    this.batches = new Batches(this);
    this.uploads = new Uploads(this);
    this.responses = new Responses(this);
    this.realtime = new Realtime2(this);
    this.conversations = new Conversations(this);
    this.evals = new Evals(this);
    this.containers = new Containers(this);
    this.skills = new Skills(this);
    this.videos = new Videos(this);
    if (apiKey === void 0) {
      throw new OpenAIError("Missing credentials. Please pass an `apiKey`, or set the `OPENAI_API_KEY` environment variable.");
    }
    const options = {
      apiKey,
      organization,
      project,
      webhookSecret,
      ...opts,
      baseURL: baseURL || `https://api.openai.com/v1`
    };
    if (!options.dangerouslyAllowBrowser && isRunningInBrowser()) {
      throw new OpenAIError("It looks like you're running in a browser-like environment.\n\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\nIf you understand the risks and have appropriate mitigations in place,\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\n\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\n\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\n");
    }
    this.baseURL = options.baseURL;
    this.timeout = options.timeout ?? _a2.DEFAULT_TIMEOUT;
    this.logger = options.logger ?? console;
    const defaultLogLevel = "warn";
    this.logLevel = defaultLogLevel;
    this.logLevel = parseLogLevel(options.logLevel, "ClientOptions.logLevel", this) ?? parseLogLevel(readEnv("OPENAI_LOG"), "process.env['OPENAI_LOG']", this) ?? defaultLogLevel;
    this.fetchOptions = options.fetchOptions;
    this.maxRetries = options.maxRetries ?? 2;
    this.fetch = options.fetch ?? getDefaultFetch();
    __classPrivateFieldSet(this, _OpenAI_encoder, FallbackEncoder, "f");
    this._options = options;
    this.apiKey = typeof apiKey === "string" ? apiKey : "Missing Key";
    this.organization = organization;
    this.project = project;
    this.webhookSecret = webhookSecret;
  }
  /**
   * Create a new client instance re-using the same options given to the current client with optional overriding.
   */
  withOptions(options) {
    const client = new this.constructor({
      ...this._options,
      baseURL: this.baseURL,
      maxRetries: this.maxRetries,
      timeout: this.timeout,
      logger: this.logger,
      logLevel: this.logLevel,
      fetch: this.fetch,
      fetchOptions: this.fetchOptions,
      apiKey: this.apiKey,
      organization: this.organization,
      project: this.project,
      webhookSecret: this.webhookSecret,
      ...options
    });
    return client;
  }
  defaultQuery() {
    return this._options.defaultQuery;
  }
  validateHeaders({ values, nulls }) {
    return;
  }
  async authHeaders(opts) {
    return buildHeaders([{ Authorization: `Bearer ${this.apiKey}` }]);
  }
  stringifyQuery(query) {
    return stringify(query, { arrayFormat: "brackets" });
  }
  getUserAgent() {
    return `${this.constructor.name}/JS ${VERSION}`;
  }
  defaultIdempotencyKey() {
    return `stainless-node-retry-${uuid4()}`;
  }
  makeStatusError(status, error, message, headers) {
    return APIError.generate(status, error, message, headers);
  }
  async _callApiKey() {
    const apiKey = this._options.apiKey;
    if (typeof apiKey !== "function")
      return false;
    let token;
    try {
      token = await apiKey();
    } catch (err) {
      if (err instanceof OpenAIError)
        throw err;
      throw new OpenAIError(
        `Failed to get token from 'apiKey' function: ${err.message}`,
        // @ts-ignore
        { cause: err }
      );
    }
    if (typeof token !== "string" || !token) {
      throw new OpenAIError(`Expected 'apiKey' function argument to return a string but it returned ${token}`);
    }
    this.apiKey = token;
    return true;
  }
  buildURL(path2, query, defaultBaseURL) {
    const baseURL = !__classPrivateFieldGet(this, _OpenAI_instances, "m", _OpenAI_baseURLOverridden).call(this) && defaultBaseURL || this.baseURL;
    const url2 = isAbsoluteURL(path2) ? new URL(path2) : new URL(baseURL + (baseURL.endsWith("/") && path2.startsWith("/") ? path2.slice(1) : path2));
    const defaultQuery = this.defaultQuery();
    if (!isEmptyObj(defaultQuery)) {
      query = { ...defaultQuery, ...query };
    }
    if (typeof query === "object" && query && !Array.isArray(query)) {
      url2.search = this.stringifyQuery(query);
    }
    return url2.toString();
  }
  /**
   * Used as a callback for mutating the given `FinalRequestOptions` object.
   */
  async prepareOptions(options) {
    await this._callApiKey();
  }
  /**
   * Used as a callback for mutating the given `RequestInit` object.
   *
   * This is useful for cases where you want to add certain headers based off of
   * the request properties, e.g. `method` or `url`.
   */
  async prepareRequest(request, { url: url2, options }) {
  }
  get(path2, opts) {
    return this.methodRequest("get", path2, opts);
  }
  post(path2, opts) {
    return this.methodRequest("post", path2, opts);
  }
  patch(path2, opts) {
    return this.methodRequest("patch", path2, opts);
  }
  put(path2, opts) {
    return this.methodRequest("put", path2, opts);
  }
  delete(path2, opts) {
    return this.methodRequest("delete", path2, opts);
  }
  methodRequest(method, path2, opts) {
    return this.request(Promise.resolve(opts).then((opts2) => {
      return { method, path: path2, ...opts2 };
    }));
  }
  request(options, remainingRetries = null) {
    return new APIPromise(this, this.makeRequest(options, remainingRetries, void 0));
  }
  async makeRequest(optionsInput, retriesRemaining, retryOfRequestLogID) {
    const options = await optionsInput;
    const maxRetries = options.maxRetries ?? this.maxRetries;
    if (retriesRemaining == null) {
      retriesRemaining = maxRetries;
    }
    await this.prepareOptions(options);
    const { req, url: url2, timeout } = await this.buildRequest(options, {
      retryCount: maxRetries - retriesRemaining
    });
    await this.prepareRequest(req, { url: url2, options });
    const requestLogID = "log_" + (Math.random() * (1 << 24) | 0).toString(16).padStart(6, "0");
    const retryLogStr = retryOfRequestLogID === void 0 ? "" : `, retryOf: ${retryOfRequestLogID}`;
    const startTime = Date.now();
    loggerFor(this).debug(`[${requestLogID}] sending request`, formatRequestDetails({
      retryOfRequestLogID,
      method: options.method,
      url: url2,
      options,
      headers: req.headers
    }));
    if (options.signal?.aborted) {
      throw new APIUserAbortError();
    }
    const controller = new AbortController();
    const response = await this.fetchWithTimeout(url2, req, timeout, controller).catch(castToError);
    const headersTime = Date.now();
    if (response instanceof globalThis.Error) {
      const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;
      if (options.signal?.aborted) {
        throw new APIUserAbortError();
      }
      const isTimeout = isAbortError(response) || /timed? ?out/i.test(String(response) + ("cause" in response ? String(response.cause) : ""));
      if (retriesRemaining) {
        loggerFor(this).info(`[${requestLogID}] connection ${isTimeout ? "timed out" : "failed"} - ${retryMessage}`);
        loggerFor(this).debug(`[${requestLogID}] connection ${isTimeout ? "timed out" : "failed"} (${retryMessage})`, formatRequestDetails({
          retryOfRequestLogID,
          url: url2,
          durationMs: headersTime - startTime,
          message: response.message
        }));
        return this.retryRequest(options, retriesRemaining, retryOfRequestLogID ?? requestLogID);
      }
      loggerFor(this).info(`[${requestLogID}] connection ${isTimeout ? "timed out" : "failed"} - error; no more retries left`);
      loggerFor(this).debug(`[${requestLogID}] connection ${isTimeout ? "timed out" : "failed"} (error; no more retries left)`, formatRequestDetails({
        retryOfRequestLogID,
        url: url2,
        durationMs: headersTime - startTime,
        message: response.message
      }));
      if (isTimeout) {
        throw new APIConnectionTimeoutError();
      }
      throw new APIConnectionError({ cause: response });
    }
    const specialHeaders = [...response.headers.entries()].filter(([name]) => name === "x-request-id").map(([name, value]) => ", " + name + ": " + JSON.stringify(value)).join("");
    const responseInfo = `[${requestLogID}${retryLogStr}${specialHeaders}] ${req.method} ${url2} ${response.ok ? "succeeded" : "failed"} with status ${response.status} in ${headersTime - startTime}ms`;
    if (!response.ok) {
      const shouldRetry = await this.shouldRetry(response);
      if (retriesRemaining && shouldRetry) {
        const retryMessage2 = `retrying, ${retriesRemaining} attempts remaining`;
        await CancelReadableStream(response.body);
        loggerFor(this).info(`${responseInfo} - ${retryMessage2}`);
        loggerFor(this).debug(`[${requestLogID}] response error (${retryMessage2})`, formatRequestDetails({
          retryOfRequestLogID,
          url: response.url,
          status: response.status,
          headers: response.headers,
          durationMs: headersTime - startTime
        }));
        return this.retryRequest(options, retriesRemaining, retryOfRequestLogID ?? requestLogID, response.headers);
      }
      const retryMessage = shouldRetry ? `error; no more retries left` : `error; not retryable`;
      loggerFor(this).info(`${responseInfo} - ${retryMessage}`);
      const errText = await response.text().catch((err2) => castToError(err2).message);
      const errJSON = safeJSON(errText);
      const errMessage = errJSON ? void 0 : errText;
      loggerFor(this).debug(`[${requestLogID}] response error (${retryMessage})`, formatRequestDetails({
        retryOfRequestLogID,
        url: response.url,
        status: response.status,
        headers: response.headers,
        message: errMessage,
        durationMs: Date.now() - startTime
      }));
      const err = this.makeStatusError(response.status, errJSON, errMessage, response.headers);
      throw err;
    }
    loggerFor(this).info(responseInfo);
    loggerFor(this).debug(`[${requestLogID}] response start`, formatRequestDetails({
      retryOfRequestLogID,
      url: response.url,
      status: response.status,
      headers: response.headers,
      durationMs: headersTime - startTime
    }));
    return { response, options, controller, requestLogID, retryOfRequestLogID, startTime };
  }
  getAPIList(path2, Page2, opts) {
    return this.requestAPIList(Page2, opts && "then" in opts ? opts.then((opts2) => ({ method: "get", path: path2, ...opts2 })) : { method: "get", path: path2, ...opts });
  }
  requestAPIList(Page2, options) {
    const request = this.makeRequest(options, null, void 0);
    return new PagePromise(this, request, Page2);
  }
  async fetchWithTimeout(url2, init, ms, controller) {
    const { signal, method, ...options } = init || {};
    const abort = this._makeAbort(controller);
    if (signal)
      signal.addEventListener("abort", abort, { once: true });
    const timeout = setTimeout(abort, ms);
    const isReadableBody = globalThis.ReadableStream && options.body instanceof globalThis.ReadableStream || typeof options.body === "object" && options.body !== null && Symbol.asyncIterator in options.body;
    const fetchOptions = {
      signal: controller.signal,
      ...isReadableBody ? { duplex: "half" } : {},
      method: "GET",
      ...options
    };
    if (method) {
      fetchOptions.method = method.toUpperCase();
    }
    try {
      return await this.fetch.call(void 0, url2, fetchOptions);
    } finally {
      clearTimeout(timeout);
    }
  }
  async shouldRetry(response) {
    const shouldRetryHeader = response.headers.get("x-should-retry");
    if (shouldRetryHeader === "true")
      return true;
    if (shouldRetryHeader === "false")
      return false;
    if (response.status === 408)
      return true;
    if (response.status === 409)
      return true;
    if (response.status === 429)
      return true;
    if (response.status >= 500)
      return true;
    return false;
  }
  async retryRequest(options, retriesRemaining, requestLogID, responseHeaders) {
    let timeoutMillis;
    const retryAfterMillisHeader = responseHeaders?.get("retry-after-ms");
    if (retryAfterMillisHeader) {
      const timeoutMs = parseFloat(retryAfterMillisHeader);
      if (!Number.isNaN(timeoutMs)) {
        timeoutMillis = timeoutMs;
      }
    }
    const retryAfterHeader = responseHeaders?.get("retry-after");
    if (retryAfterHeader && !timeoutMillis) {
      const timeoutSeconds = parseFloat(retryAfterHeader);
      if (!Number.isNaN(timeoutSeconds)) {
        timeoutMillis = timeoutSeconds * 1e3;
      } else {
        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();
      }
    }
    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1e3)) {
      const maxRetries = options.maxRetries ?? this.maxRetries;
      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);
    }
    await sleep(timeoutMillis);
    return this.makeRequest(options, retriesRemaining - 1, requestLogID);
  }
  calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries) {
    const initialRetryDelay = 0.5;
    const maxRetryDelay = 8;
    const numRetries = maxRetries - retriesRemaining;
    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);
    const jitter = 1 - Math.random() * 0.25;
    return sleepSeconds * jitter * 1e3;
  }
  async buildRequest(inputOptions, { retryCount = 0 } = {}) {
    const options = { ...inputOptions };
    const { method, path: path2, query, defaultBaseURL } = options;
    const url2 = this.buildURL(path2, query, defaultBaseURL);
    if ("timeout" in options)
      validatePositiveInteger("timeout", options.timeout);
    options.timeout = options.timeout ?? this.timeout;
    const { bodyHeaders, body } = this.buildBody({ options });
    const reqHeaders = await this.buildHeaders({ options: inputOptions, method, bodyHeaders, retryCount });
    const req = {
      method,
      headers: reqHeaders,
      ...options.signal && { signal: options.signal },
      ...globalThis.ReadableStream && body instanceof globalThis.ReadableStream && { duplex: "half" },
      ...body && { body },
      ...this.fetchOptions ?? {},
      ...options.fetchOptions ?? {}
    };
    return { req, url: url2, timeout: options.timeout };
  }
  async buildHeaders({ options, method, bodyHeaders, retryCount }) {
    let idempotencyHeaders = {};
    if (this.idempotencyHeader && method !== "get") {
      if (!options.idempotencyKey)
        options.idempotencyKey = this.defaultIdempotencyKey();
      idempotencyHeaders[this.idempotencyHeader] = options.idempotencyKey;
    }
    const headers = buildHeaders([
      idempotencyHeaders,
      {
        Accept: "application/json",
        "User-Agent": this.getUserAgent(),
        "X-Stainless-Retry-Count": String(retryCount),
        ...options.timeout ? { "X-Stainless-Timeout": String(Math.trunc(options.timeout / 1e3)) } : {},
        ...getPlatformHeaders(),
        "OpenAI-Organization": this.organization,
        "OpenAI-Project": this.project
      },
      await this.authHeaders(options),
      this._options.defaultHeaders,
      bodyHeaders,
      options.headers
    ]);
    this.validateHeaders(headers);
    return headers.values;
  }
  _makeAbort(controller) {
    return () => controller.abort();
  }
  buildBody({ options: { body, headers: rawHeaders } }) {
    if (!body) {
      return { bodyHeaders: void 0, body: void 0 };
    }
    const headers = buildHeaders([rawHeaders]);
    if (
      // Pass raw type verbatim
      ArrayBuffer.isView(body) || body instanceof ArrayBuffer || body instanceof DataView || typeof body === "string" && // Preserve legacy string encoding behavior for now
      headers.values.has("content-type") || // `Blob` is superset of `File`
      globalThis.Blob && body instanceof globalThis.Blob || // `FormData` -> `multipart/form-data`
      body instanceof FormData || // `URLSearchParams` -> `application/x-www-form-urlencoded`
      body instanceof URLSearchParams || // Send chunked stream (each chunk has own `length`)
      globalThis.ReadableStream && body instanceof globalThis.ReadableStream
    ) {
      return { bodyHeaders: void 0, body };
    } else if (typeof body === "object" && (Symbol.asyncIterator in body || Symbol.iterator in body && "next" in body && typeof body.next === "function")) {
      return { bodyHeaders: void 0, body: ReadableStreamFrom(body) };
    } else if (typeof body === "object" && headers.values.get("content-type") === "application/x-www-form-urlencoded") {
      return {
        bodyHeaders: { "content-type": "application/x-www-form-urlencoded" },
        body: this.stringifyQuery(body)
      };
    } else {
      return __classPrivateFieldGet(this, _OpenAI_encoder, "f").call(this, { body, headers });
    }
  }
};
_a2 = OpenAI, _OpenAI_encoder = /* @__PURE__ */ new WeakMap(), _OpenAI_instances = /* @__PURE__ */ new WeakSet(), _OpenAI_baseURLOverridden = function _OpenAI_baseURLOverridden2() {
  return this.baseURL !== "https://api.openai.com/v1";
};
OpenAI.OpenAI = _a2;
OpenAI.DEFAULT_TIMEOUT = 6e5;
OpenAI.OpenAIError = OpenAIError;
OpenAI.APIError = APIError;
OpenAI.APIConnectionError = APIConnectionError;
OpenAI.APIConnectionTimeoutError = APIConnectionTimeoutError;
OpenAI.APIUserAbortError = APIUserAbortError;
OpenAI.NotFoundError = NotFoundError;
OpenAI.ConflictError = ConflictError;
OpenAI.RateLimitError = RateLimitError;
OpenAI.BadRequestError = BadRequestError;
OpenAI.AuthenticationError = AuthenticationError;
OpenAI.InternalServerError = InternalServerError;
OpenAI.PermissionDeniedError = PermissionDeniedError;
OpenAI.UnprocessableEntityError = UnprocessableEntityError;
OpenAI.InvalidWebhookSignatureError = InvalidWebhookSignatureError;
OpenAI.toFile = toFile;
OpenAI.Completions = Completions2;
OpenAI.Chat = Chat;
OpenAI.Embeddings = Embeddings;
OpenAI.Files = Files2;
OpenAI.Images = Images;
OpenAI.Audio = Audio;
OpenAI.Moderations = Moderations;
OpenAI.Models = Models;
OpenAI.FineTuning = FineTuning;
OpenAI.Graders = Graders2;
OpenAI.VectorStores = VectorStores;
OpenAI.Webhooks = Webhooks;
OpenAI.Beta = Beta;
OpenAI.Batches = Batches;
OpenAI.Uploads = Uploads;
OpenAI.Responses = Responses;
OpenAI.Realtime = Realtime2;
OpenAI.Conversations = Conversations;
OpenAI.Evals = Evals;
OpenAI.Containers = Containers;
OpenAI.Skills = Skills;
OpenAI.Videos = Videos;

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/azure.mjs
var AzureOpenAI = class extends OpenAI {
  /**
   * API Client for interfacing with the Azure OpenAI API.
   *
   * @param {string | undefined} [opts.apiVersion=process.env['OPENAI_API_VERSION'] ?? undefined]
   * @param {string | undefined} [opts.endpoint=process.env['AZURE_OPENAI_ENDPOINT'] ?? undefined] - Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`
   * @param {string | undefined} [opts.apiKey=process.env['AZURE_OPENAI_API_KEY'] ?? undefined]
   * @param {string | undefined} opts.deployment - A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.
   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]
   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL']] - Sets the base URL for the API, e.g. `https://example-resource.azure.openai.com/openai/`.
   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.
   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.
   * @param {Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.
   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.
   * @param {Headers} opts.defaultHeaders - Default headers to include with every request to the API.
   * @param {DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.
   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.
   */
  constructor({ baseURL = readEnv("OPENAI_BASE_URL"), apiKey = readEnv("AZURE_OPENAI_API_KEY"), apiVersion = readEnv("OPENAI_API_VERSION"), endpoint, deployment, azureADTokenProvider, dangerouslyAllowBrowser, ...opts } = {}) {
    if (!apiVersion) {
      throw new OpenAIError("The OPENAI_API_VERSION environment variable is missing or empty; either provide it, or instantiate the AzureOpenAI client with an apiVersion option, like new AzureOpenAI({ apiVersion: 'My API Version' }).");
    }
    if (typeof azureADTokenProvider === "function") {
      dangerouslyAllowBrowser = true;
    }
    if (!azureADTokenProvider && !apiKey) {
      throw new OpenAIError("Missing credentials. Please pass one of `apiKey` and `azureADTokenProvider`, or set the `AZURE_OPENAI_API_KEY` environment variable.");
    }
    if (azureADTokenProvider && apiKey) {
      throw new OpenAIError("The `apiKey` and `azureADTokenProvider` arguments are mutually exclusive; only one can be passed at a time.");
    }
    opts.defaultQuery = { ...opts.defaultQuery, "api-version": apiVersion };
    if (!baseURL) {
      if (!endpoint) {
        endpoint = process.env["AZURE_OPENAI_ENDPOINT"];
      }
      if (!endpoint) {
        throw new OpenAIError("Must provide one of the `baseURL` or `endpoint` arguments, or the `AZURE_OPENAI_ENDPOINT` environment variable");
      }
      baseURL = `${endpoint}/openai`;
    } else {
      if (endpoint) {
        throw new OpenAIError("baseURL and endpoint are mutually exclusive");
      }
    }
    super({
      apiKey: azureADTokenProvider ?? apiKey,
      baseURL,
      ...opts,
      ...dangerouslyAllowBrowser !== void 0 ? { dangerouslyAllowBrowser } : {}
    });
    this.apiVersion = "";
    this.apiVersion = apiVersion;
    this.deploymentName = deployment;
  }
  async buildRequest(options, props = {}) {
    if (_deployments_endpoints.has(options.path) && options.method === "post" && options.body !== void 0) {
      if (!isObj(options.body)) {
        throw new Error("Expected request body to be an object");
      }
      const model = this.deploymentName || options.body["model"] || options.__metadata?.["model"];
      if (model !== void 0 && !this.baseURL.includes("/deployments")) {
        options.path = `/deployments/${model}${options.path}`;
      }
    }
    return super.buildRequest(options, props);
  }
  async authHeaders(opts) {
    if (typeof this._options.apiKey === "string") {
      return buildHeaders([{ "api-key": this.apiKey }]);
    }
    return super.authHeaders(opts);
  }
};
var _deployments_endpoints = /* @__PURE__ */ new Set([
  "/completions",
  "/chat/completions",
  "/embeddings",
  "/audio/transcriptions",
  "/audio/translations",
  "/audio/speech",
  "/images/generations",
  "/batches",
  "/images/edits"
]);

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/utils/client.js
function _isOpenAIContextOverflowError(e) {
  if (String(e).includes("context_length_exceeded")) return true;
  if ("message" in e && typeof e.message === "string" && (e.message.includes("Input tokens exceed the configured limit") || e.message.includes("exceeds the context window"))) return true;
  return false;
}
function wrapOpenAIClientError(e) {
  if (!e || typeof e !== "object") return e;
  let error;
  if (e.constructor.name === APIConnectionTimeoutError.name && "message" in e && typeof e.message === "string") {
    error = new Error(e.message);
    error.name = "TimeoutError";
  } else if (e.constructor.name === APIUserAbortError.name && "message" in e && typeof e.message === "string") {
    error = new Error(e.message);
    error.name = "AbortError";
  } else if (_isOpenAIContextOverflowError(e)) error = ContextOverflowError.fromError(e);
  else if ("status" in e && e.status === 400 && "message" in e && typeof e.message === "string" && e.message.includes("tool_calls")) error = addLangChainErrorFields2(e, "INVALID_TOOL_RESULTS");
  else if ("status" in e && e.status === 401) error = addLangChainErrorFields2(e, "MODEL_AUTHENTICATION");
  else if ("status" in e && e.status === 429) error = addLangChainErrorFields2(e, "MODEL_RATE_LIMIT");
  else if ("status" in e && e.status === 404) error = addLangChainErrorFields2(e, "MODEL_NOT_FOUND");
  else error = e;
  return error;
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/utils/misc.js
var iife$1 = (fn) => fn();
function isReasoningModel(model) {
  if (!model) return false;
  if (/^o\d/.test(model ?? "")) return true;
  if (model.startsWith("gpt-5") && !model.startsWith("gpt-5-chat")) return true;
  return false;
}
function extractGenericMessageCustomRole(message) {
  if (message.role !== "system" && message.role !== "developer" && message.role !== "assistant" && message.role !== "user" && message.role !== "function" && message.role !== "tool") console.warn(`Unknown message role: ${message.role}`);
  return message.role;
}
function getFilenameFromMetadata(block) {
  return block.metadata?.filename ?? block.metadata?.name ?? block.metadata?.title;
}
function getRequiredFilenameFromMetadata(block) {
  const filename = block.metadata?.filename ?? block.metadata?.name ?? block.metadata?.title;
  if (!filename) throw new Error("a filename or name or title is needed via meta-data for OpenAI when working with multimodal blocks");
  return filename;
}
function messageToOpenAIRole(message) {
  const type = message._getType();
  switch (type) {
    case "system":
      return "system";
    case "ai":
      return "assistant";
    case "human":
      return "user";
    case "function":
      return "function";
    case "tool":
      return "tool";
    case "generic":
      if (!ChatMessage.isInstance(message)) throw new Error("Invalid generic chat message");
      return extractGenericMessageCustomRole(message);
    default:
      throw new Error(`Unknown message type: ${type}`);
  }
}
function _modelPrefersResponsesAPI(model) {
  if (model.includes("gpt-5.2-pro")) return true;
  if (model.includes("codex")) return true;
  return false;
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/utils/azure.js
function getEndpoint(config2) {
  const { azureOpenAIApiDeploymentName, azureOpenAIApiInstanceName, azureOpenAIApiKey, azureOpenAIBasePath, baseURL, azureADTokenProvider, azureOpenAIEndpoint } = config2;
  if ((azureOpenAIApiKey || azureADTokenProvider) && azureOpenAIBasePath && azureOpenAIApiDeploymentName) return `${azureOpenAIBasePath}/${azureOpenAIApiDeploymentName}`;
  if ((azureOpenAIApiKey || azureADTokenProvider) && azureOpenAIEndpoint && azureOpenAIApiDeploymentName) return `${azureOpenAIEndpoint}/openai/deployments/${azureOpenAIApiDeploymentName}`;
  if (azureOpenAIApiKey || azureADTokenProvider) {
    if (!azureOpenAIApiInstanceName) throw new Error("azureOpenAIApiInstanceName is required when using azureOpenAIApiKey");
    if (!azureOpenAIApiDeploymentName) throw new Error("azureOpenAIApiDeploymentName is a required parameter when using azureOpenAIApiKey");
    return `https://${azureOpenAIApiInstanceName}.openai.azure.com/openai/deployments/${azureOpenAIApiDeploymentName}`;
  }
  return baseURL;
}
function isHeaders(headers) {
  return typeof Headers !== "undefined" && headers !== null && typeof headers === "object" && Object.prototype.toString.call(headers) === "[object Headers]";
}
function normalizeHeaders(headers) {
  const output = iife$1(() => {
    if (isHeaders(headers)) return headers;
    else if (Array.isArray(headers)) return new Headers(headers);
    else if (typeof headers === "object" && headers !== null && "values" in headers && isHeaders(headers.values)) return headers.values;
    else if (typeof headers === "object" && headers !== null) {
      const entries = Object.entries(headers).filter(([, v]) => typeof v === "string").map(([k, v]) => [k, v]);
      return new Headers(entries);
    }
    return new Headers();
  });
  return Object.fromEntries(output.entries());
}
function getFormattedEnv() {
  let env = getEnv();
  if (env === "node" || env === "deno") env = `(${env}/${process.version}; ${process.platform}; ${process.arch})`;
  return env;
}
function getHeadersWithUserAgent(headers, isAzure = false, version = "1.0.0") {
  const normalizedHeaders = normalizeHeaders(headers);
  const env = getFormattedEnv();
  const library = `langchainjs${isAzure ? "-azure" : ""}-openai`;
  return {
    ...normalizedHeaders,
    "User-Agent": normalizedHeaders["User-Agent"] ? `${library}/${version} (${env})${normalizedHeaders["User-Agent"]}` : `${library}/${version} (${env})`
  };
}

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/tools/types.js
function isStructuredTool(tool2) {
  return tool2 !== void 0 && Array.isArray(tool2.lc_namespace);
}
function isRunnableToolLike(tool2) {
  return tool2 !== void 0 && Runnable.isRunnable(tool2) && "lc_name" in tool2.constructor && typeof tool2.constructor.lc_name === "function" && tool2.constructor.lc_name() === "RunnableToolLike";
}
function isStructuredToolParams(tool2) {
  return !!tool2 && typeof tool2 === "object" && "name" in tool2 && "schema" in tool2 && (isInteropZodSchema(tool2.schema) || tool2.schema != null && typeof tool2.schema === "object" && "type" in tool2.schema && typeof tool2.schema.type === "string" && [
    "null",
    "boolean",
    "object",
    "array",
    "number",
    "string"
  ].includes(tool2.schema.type));
}
function isLangChainTool(tool2) {
  return isStructuredToolParams(tool2) || isRunnableToolLike(tool2) || isStructuredTool(tool2);
}

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/utils/function_calling.js
var function_calling_exports = __exportAll({
  convertToOpenAIFunction: () => convertToOpenAIFunction,
  convertToOpenAITool: () => convertToOpenAITool,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams
});
function convertToOpenAIFunction(tool2, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  return {
    name: tool2.name,
    description: tool2.description,
    parameters: toJsonSchema(tool2.schema),
    ...fieldsCopy?.strict !== void 0 ? { strict: fieldsCopy.strict } : {}
  };
}
function convertToOpenAITool(tool2, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  let toolDef;
  if (isLangChainTool(tool2)) toolDef = {
    type: "function",
    function: convertToOpenAIFunction(tool2)
  };
  else toolDef = tool2;
  if (fieldsCopy?.strict !== void 0) toolDef.function.strict = fieldsCopy.strict;
  return toolDef;
}

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/utils/types/index.js
var types_exports = __exportAll({
  extendInteropZodObject: () => extendInteropZodObject,
  getInteropZodDefaultGetter: () => getInteropZodDefaultGetter,
  getInteropZodObjectShape: () => getInteropZodObjectShape,
  getSchemaDescription: () => getSchemaDescription,
  interopParse: () => interopParse,
  interopParseAsync: () => interopParseAsync,
  interopSafeParse: () => interopSafeParse,
  interopSafeParseAsync: () => interopSafeParseAsync,
  interopZodObjectMakeFieldsOptional: () => interopZodObjectMakeFieldsOptional,
  interopZodObjectPartial: () => interopZodObjectPartial,
  interopZodObjectPassthrough: () => interopZodObjectPassthrough,
  interopZodObjectStrict: () => interopZodObjectStrict,
  interopZodTransformInputSchema: () => interopZodTransformInputSchema,
  isInteropZodError: () => isInteropZodError,
  isInteropZodLiteral: () => isInteropZodLiteral,
  isInteropZodObject: () => isInteropZodObject,
  isInteropZodSchema: () => isInteropZodSchema,
  isShapelessZodSchema: () => isShapelessZodSchema,
  isSimpleStringZodSchema: () => isSimpleStringZodSchema,
  isZodArrayV4: () => isZodArrayV4,
  isZodLiteralV3: () => isZodLiteralV3,
  isZodLiteralV4: () => isZodLiteralV4,
  isZodNullableV4: () => isZodNullableV4,
  isZodObjectV3: () => isZodObjectV3,
  isZodObjectV4: () => isZodObjectV4,
  isZodOptionalV4: () => isZodOptionalV4,
  isZodSchema: () => isZodSchema,
  isZodSchemaV3: () => isZodSchemaV3,
  isZodSchemaV4: () => isZodSchemaV4
});

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/utils/tools.js
function _convertToOpenAITool(tool2, fields) {
  let toolDef;
  if (isLangChainTool(tool2)) toolDef = convertToOpenAITool(tool2);
  else toolDef = tool2;
  if (fields?.strict !== void 0) toolDef.function.strict = fields.strict;
  return toolDef;
}
function isAnyOfProp(prop) {
  return prop.anyOf !== void 0 && Array.isArray(prop.anyOf);
}
function formatFunctionDefinitions(functions) {
  const lines = ["namespace functions {", ""];
  for (const f of functions) {
    if (f.description) lines.push(`// ${f.description}`);
    if (Object.keys(f.parameters.properties ?? {}).length > 0) {
      lines.push(`type ${f.name} = (_: {`);
      lines.push(formatObjectProperties(f.parameters, 0));
      lines.push("}) => any;");
    } else lines.push(`type ${f.name} = () => any;`);
    lines.push("");
  }
  lines.push("} // namespace functions");
  return lines.join("\n");
}
function formatObjectProperties(obj, indent) {
  const lines = [];
  for (const [name, param] of Object.entries(obj.properties ?? {})) {
    if (param.description && indent < 2) lines.push(`// ${param.description}`);
    if (obj.required?.includes(name)) lines.push(`${name}: ${formatType(param, indent)},`);
    else lines.push(`${name}?: ${formatType(param, indent)},`);
  }
  return lines.map((line) => " ".repeat(indent) + line).join("\n");
}
function formatType(param, indent) {
  if (isAnyOfProp(param)) return param.anyOf.map((v) => formatType(v, indent)).join(" | ");
  switch (param.type) {
    case "string":
      if (param.enum) return param.enum.map((v) => `"${v}"`).join(" | ");
      return "string";
    case "number":
      if (param.enum) return param.enum.map((v) => `${v}`).join(" | ");
      return "number";
    case "integer":
      if (param.enum) return param.enum.map((v) => `${v}`).join(" | ");
      return "number";
    case "boolean":
      return "boolean";
    case "null":
      return "null";
    case "object":
      return [
        "{",
        formatObjectProperties(param, indent + 2),
        "}"
      ].join("\n");
    case "array":
      if (param.items) return `${formatType(param.items, indent)}[]`;
      return "any[]";
    default:
      return "";
  }
}
function formatToOpenAIToolChoice(toolChoice) {
  if (!toolChoice) return;
  else if (toolChoice === "any" || toolChoice === "required") return "required";
  else if (toolChoice === "auto") return "auto";
  else if (toolChoice === "none") return "none";
  else if (typeof toolChoice === "string") return {
    type: "function",
    function: { name: toolChoice }
  };
  else return toolChoice;
}
function isBuiltInTool(tool2) {
  return "type" in tool2 && tool2.type !== "function";
}
function hasProviderToolDefinition(tool2) {
  return typeof tool2 === "object" && tool2 !== null && "extras" in tool2 && typeof tool2.extras === "object" && tool2.extras !== null && "providerToolDefinition" in tool2.extras && typeof tool2.extras.providerToolDefinition === "object" && tool2.extras.providerToolDefinition !== null;
}
function isBuiltInToolChoice(tool_choice) {
  return tool_choice != null && typeof tool_choice === "object" && "type" in tool_choice && tool_choice.type !== "function";
}
function isCustomTool(tool2) {
  return typeof tool2 === "object" && tool2 !== null && "metadata" in tool2 && typeof tool2.metadata === "object" && tool2.metadata !== null && "customTool" in tool2.metadata && typeof tool2.metadata.customTool === "object" && tool2.metadata.customTool !== null;
}
function isOpenAICustomTool(tool2) {
  return "type" in tool2 && tool2.type === "custom" && "custom" in tool2 && typeof tool2.custom === "object" && tool2.custom !== null;
}
function parseCustomToolCall(rawToolCall) {
  if (rawToolCall.type !== "custom_tool_call") return;
  return {
    ...rawToolCall,
    type: "tool_call",
    call_id: rawToolCall.id,
    id: rawToolCall.call_id,
    name: rawToolCall.name,
    isCustomTool: true,
    args: { input: rawToolCall.input }
  };
}
function parseComputerCall(rawToolCall) {
  if (rawToolCall.type !== "computer_call") return;
  return {
    ...rawToolCall,
    type: "tool_call",
    call_id: rawToolCall.id,
    id: rawToolCall.call_id,
    name: "computer_use",
    isComputerTool: true,
    args: { action: rawToolCall.action }
  };
}
function isComputerToolCall(toolCall) {
  return typeof toolCall === "object" && toolCall !== null && "type" in toolCall && toolCall.type === "tool_call" && "isComputerTool" in toolCall && toolCall.isComputerTool === true;
}
function isCustomToolCall(toolCall) {
  return typeof toolCall === "object" && toolCall !== null && "type" in toolCall && toolCall.type === "tool_call" && "isCustomTool" in toolCall && toolCall.isCustomTool === true;
}
function convertCompletionsCustomTool(tool2) {
  const getFormat = () => {
    if (!tool2.custom.format) return;
    if (tool2.custom.format.type === "grammar") return {
      type: "grammar",
      definition: tool2.custom.format.grammar.definition,
      syntax: tool2.custom.format.grammar.syntax
    };
    if (tool2.custom.format.type === "text") return { type: "text" };
  };
  return {
    type: "custom",
    name: tool2.custom.name,
    description: tool2.custom.description,
    format: getFormat()
  };
}
function convertResponsesCustomTool(tool2) {
  const getFormat = () => {
    if (!tool2.format) return;
    if (tool2.format.type === "grammar") return {
      type: "grammar",
      grammar: {
        definition: tool2.format.definition,
        syntax: tool2.format.syntax
      }
    };
    if (tool2.format.type === "text") return { type: "text" };
  };
  return {
    type: "custom",
    custom: {
      name: tool2.name,
      description: tool2.description,
      format: getFormat()
    }
  };
}

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/external.js
var external_exports2 = {};
__export(external_exports2, {
  $brand: () => $brand,
  $input: () => $input,
  $output: () => $output,
  NEVER: () => NEVER,
  TimePrecision: () => TimePrecision,
  ZodAny: () => ZodAny,
  ZodArray: () => ZodArray,
  ZodBase64: () => ZodBase64,
  ZodBase64URL: () => ZodBase64URL,
  ZodBigInt: () => ZodBigInt,
  ZodBigIntFormat: () => ZodBigIntFormat,
  ZodBoolean: () => ZodBoolean,
  ZodCIDRv4: () => ZodCIDRv4,
  ZodCIDRv6: () => ZodCIDRv6,
  ZodCUID: () => ZodCUID,
  ZodCUID2: () => ZodCUID2,
  ZodCatch: () => ZodCatch,
  ZodCodec: () => ZodCodec,
  ZodCustom: () => ZodCustom,
  ZodCustomStringFormat: () => ZodCustomStringFormat,
  ZodDate: () => ZodDate,
  ZodDefault: () => ZodDefault,
  ZodDiscriminatedUnion: () => ZodDiscriminatedUnion,
  ZodE164: () => ZodE164,
  ZodEmail: () => ZodEmail,
  ZodEmoji: () => ZodEmoji,
  ZodEnum: () => ZodEnum,
  ZodError: () => ZodError,
  ZodExactOptional: () => ZodExactOptional,
  ZodFile: () => ZodFile,
  ZodFirstPartyTypeKind: () => ZodFirstPartyTypeKind2,
  ZodFunction: () => ZodFunction,
  ZodGUID: () => ZodGUID,
  ZodIPv4: () => ZodIPv4,
  ZodIPv6: () => ZodIPv6,
  ZodISODate: () => ZodISODate,
  ZodISODateTime: () => ZodISODateTime,
  ZodISODuration: () => ZodISODuration,
  ZodISOTime: () => ZodISOTime,
  ZodIntersection: () => ZodIntersection,
  ZodIssueCode: () => ZodIssueCode,
  ZodJWT: () => ZodJWT,
  ZodKSUID: () => ZodKSUID,
  ZodLazy: () => ZodLazy,
  ZodLiteral: () => ZodLiteral,
  ZodMAC: () => ZodMAC,
  ZodMap: () => ZodMap,
  ZodNaN: () => ZodNaN,
  ZodNanoID: () => ZodNanoID,
  ZodNever: () => ZodNever,
  ZodNonOptional: () => ZodNonOptional,
  ZodNull: () => ZodNull,
  ZodNullable: () => ZodNullable,
  ZodNumber: () => ZodNumber,
  ZodNumberFormat: () => ZodNumberFormat,
  ZodObject: () => ZodObject,
  ZodOptional: () => ZodOptional,
  ZodPipe: () => ZodPipe,
  ZodPrefault: () => ZodPrefault,
  ZodPromise: () => ZodPromise,
  ZodReadonly: () => ZodReadonly,
  ZodRealError: () => ZodRealError,
  ZodRecord: () => ZodRecord,
  ZodSet: () => ZodSet,
  ZodString: () => ZodString,
  ZodStringFormat: () => ZodStringFormat,
  ZodSuccess: () => ZodSuccess,
  ZodSymbol: () => ZodSymbol,
  ZodTemplateLiteral: () => ZodTemplateLiteral,
  ZodTransform: () => ZodTransform,
  ZodTuple: () => ZodTuple,
  ZodType: () => ZodType,
  ZodULID: () => ZodULID,
  ZodURL: () => ZodURL,
  ZodUUID: () => ZodUUID,
  ZodUndefined: () => ZodUndefined,
  ZodUnion: () => ZodUnion,
  ZodUnknown: () => ZodUnknown,
  ZodVoid: () => ZodVoid,
  ZodXID: () => ZodXID,
  ZodXor: () => ZodXor,
  _ZodString: () => _ZodString,
  _default: () => _default,
  _function: () => _function,
  any: () => any,
  array: () => array,
  base64: () => base64,
  base64url: () => base64url,
  bigint: () => bigint,
  boolean: () => boolean,
  catch: () => _catch,
  check: () => check,
  cidrv4: () => cidrv4,
  cidrv6: () => cidrv6,
  clone: () => clone,
  codec: () => codec,
  coerce: () => coerce_exports,
  config: () => config,
  core: () => core_exports,
  cuid: () => cuid,
  cuid2: () => cuid2,
  custom: () => custom,
  date: () => date2,
  decode: () => decode,
  decodeAsync: () => decodeAsync,
  describe: () => describe2,
  discriminatedUnion: () => discriminatedUnion,
  e164: () => e164,
  email: () => email,
  emoji: () => emoji,
  encode: () => encode2,
  encodeAsync: () => encodeAsync,
  endsWith: () => _endsWith,
  enum: () => _enum,
  exactOptional: () => exactOptional,
  file: () => file,
  flattenError: () => flattenError,
  float32: () => float32,
  float64: () => float64,
  formatError: () => formatError,
  fromJSONSchema: () => fromJSONSchema,
  function: () => _function,
  getErrorMap: () => getErrorMap,
  globalRegistry: () => globalRegistry,
  gt: () => _gt,
  gte: () => _gte,
  guid: () => guid,
  hash: () => hash,
  hex: () => hex,
  hostname: () => hostname,
  httpUrl: () => httpUrl,
  includes: () => _includes,
  instanceof: () => _instanceof,
  int: () => int,
  int32: () => int32,
  int64: () => int64,
  intersection: () => intersection,
  ipv4: () => ipv4,
  ipv6: () => ipv6,
  iso: () => iso_exports,
  json: () => json,
  jwt: () => jwt,
  keyof: () => keyof,
  ksuid: () => ksuid,
  lazy: () => lazy,
  length: () => _length,
  literal: () => literal,
  locales: () => locales_exports,
  looseObject: () => looseObject,
  looseRecord: () => looseRecord,
  lowercase: () => _lowercase,
  lt: () => _lt,
  lte: () => _lte,
  mac: () => mac,
  map: () => map,
  maxLength: () => _maxLength,
  maxSize: () => _maxSize,
  meta: () => meta2,
  mime: () => _mime,
  minLength: () => _minLength,
  minSize: () => _minSize,
  multipleOf: () => _multipleOf,
  nan: () => nan,
  nanoid: () => nanoid,
  nativeEnum: () => nativeEnum,
  negative: () => _negative,
  never: () => never,
  nonnegative: () => _nonnegative,
  nonoptional: () => nonoptional,
  nonpositive: () => _nonpositive,
  normalize: () => _normalize,
  null: () => _null2,
  nullable: () => nullable,
  nullish: () => nullish,
  number: () => number,
  object: () => object,
  optional: () => optional,
  overwrite: () => _overwrite,
  parse: () => parse2,
  parseAsync: () => parseAsync,
  partialRecord: () => partialRecord,
  pipe: () => pipe,
  positive: () => _positive,
  prefault: () => prefault,
  preprocess: () => preprocess,
  prettifyError: () => prettifyError,
  promise: () => promise,
  property: () => _property,
  readonly: () => readonly,
  record: () => record,
  refine: () => refine,
  regex: () => _regex,
  regexes: () => regexes_exports,
  registry: () => registry,
  safeDecode: () => safeDecode,
  safeDecodeAsync: () => safeDecodeAsync,
  safeEncode: () => safeEncode,
  safeEncodeAsync: () => safeEncodeAsync,
  safeParse: () => safeParse,
  safeParseAsync: () => safeParseAsync,
  set: () => set,
  setErrorMap: () => setErrorMap,
  size: () => _size,
  slugify: () => _slugify,
  startsWith: () => _startsWith,
  strictObject: () => strictObject,
  string: () => string,
  stringFormat: () => stringFormat,
  stringbool: () => stringbool,
  success: () => success,
  superRefine: () => superRefine,
  symbol: () => symbol,
  templateLiteral: () => templateLiteral,
  toJSONSchema: () => toJSONSchema,
  toLowerCase: () => _toLowerCase,
  toUpperCase: () => _toUpperCase,
  transform: () => transform,
  treeifyError: () => treeifyError,
  trim: () => _trim,
  tuple: () => tuple,
  uint32: () => uint32,
  uint64: () => uint64,
  ulid: () => ulid,
  undefined: () => _undefined2,
  union: () => union,
  unknown: () => unknown,
  uppercase: () => _uppercase,
  url: () => url,
  util: () => util_exports,
  uuid: () => uuid,
  uuidv4: () => uuidv4,
  uuidv6: () => uuidv6,
  uuidv7: () => uuidv7,
  void: () => _void2,
  xid: () => xid,
  xor: () => xor
});

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/schemas.js
var schemas_exports = {};
__export(schemas_exports, {
  ZodAny: () => ZodAny,
  ZodArray: () => ZodArray,
  ZodBase64: () => ZodBase64,
  ZodBase64URL: () => ZodBase64URL,
  ZodBigInt: () => ZodBigInt,
  ZodBigIntFormat: () => ZodBigIntFormat,
  ZodBoolean: () => ZodBoolean,
  ZodCIDRv4: () => ZodCIDRv4,
  ZodCIDRv6: () => ZodCIDRv6,
  ZodCUID: () => ZodCUID,
  ZodCUID2: () => ZodCUID2,
  ZodCatch: () => ZodCatch,
  ZodCodec: () => ZodCodec,
  ZodCustom: () => ZodCustom,
  ZodCustomStringFormat: () => ZodCustomStringFormat,
  ZodDate: () => ZodDate,
  ZodDefault: () => ZodDefault,
  ZodDiscriminatedUnion: () => ZodDiscriminatedUnion,
  ZodE164: () => ZodE164,
  ZodEmail: () => ZodEmail,
  ZodEmoji: () => ZodEmoji,
  ZodEnum: () => ZodEnum,
  ZodExactOptional: () => ZodExactOptional,
  ZodFile: () => ZodFile,
  ZodFunction: () => ZodFunction,
  ZodGUID: () => ZodGUID,
  ZodIPv4: () => ZodIPv4,
  ZodIPv6: () => ZodIPv6,
  ZodIntersection: () => ZodIntersection,
  ZodJWT: () => ZodJWT,
  ZodKSUID: () => ZodKSUID,
  ZodLazy: () => ZodLazy,
  ZodLiteral: () => ZodLiteral,
  ZodMAC: () => ZodMAC,
  ZodMap: () => ZodMap,
  ZodNaN: () => ZodNaN,
  ZodNanoID: () => ZodNanoID,
  ZodNever: () => ZodNever,
  ZodNonOptional: () => ZodNonOptional,
  ZodNull: () => ZodNull,
  ZodNullable: () => ZodNullable,
  ZodNumber: () => ZodNumber,
  ZodNumberFormat: () => ZodNumberFormat,
  ZodObject: () => ZodObject,
  ZodOptional: () => ZodOptional,
  ZodPipe: () => ZodPipe,
  ZodPrefault: () => ZodPrefault,
  ZodPromise: () => ZodPromise,
  ZodReadonly: () => ZodReadonly,
  ZodRecord: () => ZodRecord,
  ZodSet: () => ZodSet,
  ZodString: () => ZodString,
  ZodStringFormat: () => ZodStringFormat,
  ZodSuccess: () => ZodSuccess,
  ZodSymbol: () => ZodSymbol,
  ZodTemplateLiteral: () => ZodTemplateLiteral,
  ZodTransform: () => ZodTransform,
  ZodTuple: () => ZodTuple,
  ZodType: () => ZodType,
  ZodULID: () => ZodULID,
  ZodURL: () => ZodURL,
  ZodUUID: () => ZodUUID,
  ZodUndefined: () => ZodUndefined,
  ZodUnion: () => ZodUnion,
  ZodUnknown: () => ZodUnknown,
  ZodVoid: () => ZodVoid,
  ZodXID: () => ZodXID,
  ZodXor: () => ZodXor,
  _ZodString: () => _ZodString,
  _default: () => _default,
  _function: () => _function,
  any: () => any,
  array: () => array,
  base64: () => base64,
  base64url: () => base64url,
  bigint: () => bigint,
  boolean: () => boolean,
  catch: () => _catch,
  check: () => check,
  cidrv4: () => cidrv4,
  cidrv6: () => cidrv6,
  codec: () => codec,
  cuid: () => cuid,
  cuid2: () => cuid2,
  custom: () => custom,
  date: () => date2,
  describe: () => describe2,
  discriminatedUnion: () => discriminatedUnion,
  e164: () => e164,
  email: () => email,
  emoji: () => emoji,
  enum: () => _enum,
  exactOptional: () => exactOptional,
  file: () => file,
  float32: () => float32,
  float64: () => float64,
  function: () => _function,
  guid: () => guid,
  hash: () => hash,
  hex: () => hex,
  hostname: () => hostname,
  httpUrl: () => httpUrl,
  instanceof: () => _instanceof,
  int: () => int,
  int32: () => int32,
  int64: () => int64,
  intersection: () => intersection,
  ipv4: () => ipv4,
  ipv6: () => ipv6,
  json: () => json,
  jwt: () => jwt,
  keyof: () => keyof,
  ksuid: () => ksuid,
  lazy: () => lazy,
  literal: () => literal,
  looseObject: () => looseObject,
  looseRecord: () => looseRecord,
  mac: () => mac,
  map: () => map,
  meta: () => meta2,
  nan: () => nan,
  nanoid: () => nanoid,
  nativeEnum: () => nativeEnum,
  never: () => never,
  nonoptional: () => nonoptional,
  null: () => _null2,
  nullable: () => nullable,
  nullish: () => nullish,
  number: () => number,
  object: () => object,
  optional: () => optional,
  partialRecord: () => partialRecord,
  pipe: () => pipe,
  prefault: () => prefault,
  preprocess: () => preprocess,
  promise: () => promise,
  readonly: () => readonly,
  record: () => record,
  refine: () => refine,
  set: () => set,
  strictObject: () => strictObject,
  string: () => string,
  stringFormat: () => stringFormat,
  stringbool: () => stringbool,
  success: () => success,
  superRefine: () => superRefine,
  symbol: () => symbol,
  templateLiteral: () => templateLiteral,
  transform: () => transform,
  tuple: () => tuple,
  uint32: () => uint32,
  uint64: () => uint64,
  ulid: () => ulid,
  undefined: () => _undefined2,
  union: () => union,
  unknown: () => unknown,
  url: () => url,
  uuid: () => uuid,
  uuidv4: () => uuidv4,
  uuidv6: () => uuidv6,
  uuidv7: () => uuidv7,
  void: () => _void2,
  xid: () => xid,
  xor: () => xor
});

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/checks.js
var checks_exports = {};
__export(checks_exports, {
  endsWith: () => _endsWith,
  gt: () => _gt,
  gte: () => _gte,
  includes: () => _includes,
  length: () => _length,
  lowercase: () => _lowercase,
  lt: () => _lt,
  lte: () => _lte,
  maxLength: () => _maxLength,
  maxSize: () => _maxSize,
  mime: () => _mime,
  minLength: () => _minLength,
  minSize: () => _minSize,
  multipleOf: () => _multipleOf,
  negative: () => _negative,
  nonnegative: () => _nonnegative,
  nonpositive: () => _nonpositive,
  normalize: () => _normalize,
  overwrite: () => _overwrite,
  positive: () => _positive,
  property: () => _property,
  regex: () => _regex,
  size: () => _size,
  slugify: () => _slugify,
  startsWith: () => _startsWith,
  toLowerCase: () => _toLowerCase,
  toUpperCase: () => _toUpperCase,
  trim: () => _trim,
  uppercase: () => _uppercase
});

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/iso.js
var iso_exports = {};
__export(iso_exports, {
  ZodISODate: () => ZodISODate,
  ZodISODateTime: () => ZodISODateTime,
  ZodISODuration: () => ZodISODuration,
  ZodISOTime: () => ZodISOTime,
  date: () => date,
  datetime: () => datetime,
  duration: () => duration,
  time: () => time
});
var ZodISODateTime = $constructor("ZodISODateTime", (inst, def) => {
  $ZodISODateTime.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function datetime(params) {
  return _isoDateTime(ZodISODateTime, params);
}
var ZodISODate = $constructor("ZodISODate", (inst, def) => {
  $ZodISODate.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function date(params) {
  return _isoDate(ZodISODate, params);
}
var ZodISOTime = $constructor("ZodISOTime", (inst, def) => {
  $ZodISOTime.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function time(params) {
  return _isoTime(ZodISOTime, params);
}
var ZodISODuration = $constructor("ZodISODuration", (inst, def) => {
  $ZodISODuration.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function duration(params) {
  return _isoDuration(ZodISODuration, params);
}

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/errors.js
var initializer = (inst, issues) => {
  $ZodError.init(inst, issues);
  inst.name = "ZodError";
  Object.defineProperties(inst, {
    format: {
      value: (mapper) => formatError(inst, mapper)
      // enumerable: false,
    },
    flatten: {
      value: (mapper) => flattenError(inst, mapper)
      // enumerable: false,
    },
    addIssue: {
      value: (issue) => {
        inst.issues.push(issue);
        inst.message = JSON.stringify(inst.issues, jsonStringifyReplacer, 2);
      }
      // enumerable: false,
    },
    addIssues: {
      value: (issues2) => {
        inst.issues.push(...issues2);
        inst.message = JSON.stringify(inst.issues, jsonStringifyReplacer, 2);
      }
      // enumerable: false,
    },
    isEmpty: {
      get() {
        return inst.issues.length === 0;
      }
      // enumerable: false,
    }
  });
};
var ZodError = $constructor("ZodError", initializer);
var ZodRealError = $constructor("ZodError", initializer, {
  Parent: Error
});

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/parse.js
var parse2 = _parse(ZodRealError);
var parseAsync = _parseAsync(ZodRealError);
var safeParse = _safeParse(ZodRealError);
var safeParseAsync = _safeParseAsync(ZodRealError);
var encode2 = _encode(ZodRealError);
var decode = _decode(ZodRealError);
var encodeAsync = _encodeAsync(ZodRealError);
var decodeAsync = _decodeAsync(ZodRealError);
var safeEncode = _safeEncode(ZodRealError);
var safeDecode = _safeDecode(ZodRealError);
var safeEncodeAsync = _safeEncodeAsync(ZodRealError);
var safeDecodeAsync = _safeDecodeAsync(ZodRealError);

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/schemas.js
var ZodType = $constructor("ZodType", (inst, def) => {
  $ZodType.init(inst, def);
  Object.assign(inst["~standard"], {
    jsonSchema: {
      input: createStandardJSONSchemaMethod(inst, "input"),
      output: createStandardJSONSchemaMethod(inst, "output")
    }
  });
  inst.toJSONSchema = createToJSONSchemaMethod(inst, {});
  inst.def = def;
  inst.type = def.type;
  Object.defineProperty(inst, "_def", { value: def });
  inst.check = (...checks) => {
    return inst.clone(util_exports.mergeDefs(def, {
      checks: [
        ...def.checks ?? [],
        ...checks.map((ch) => typeof ch === "function" ? { _zod: { check: ch, def: { check: "custom" }, onattach: [] } } : ch)
      ]
    }), {
      parent: true
    });
  };
  inst.with = inst.check;
  inst.clone = (def2, params) => clone(inst, def2, params);
  inst.brand = () => inst;
  inst.register = ((reg, meta3) => {
    reg.add(inst, meta3);
    return inst;
  });
  inst.parse = (data, params) => parse2(inst, data, params, { callee: inst.parse });
  inst.safeParse = (data, params) => safeParse(inst, data, params);
  inst.parseAsync = async (data, params) => parseAsync(inst, data, params, { callee: inst.parseAsync });
  inst.safeParseAsync = async (data, params) => safeParseAsync(inst, data, params);
  inst.spa = inst.safeParseAsync;
  inst.encode = (data, params) => encode2(inst, data, params);
  inst.decode = (data, params) => decode(inst, data, params);
  inst.encodeAsync = async (data, params) => encodeAsync(inst, data, params);
  inst.decodeAsync = async (data, params) => decodeAsync(inst, data, params);
  inst.safeEncode = (data, params) => safeEncode(inst, data, params);
  inst.safeDecode = (data, params) => safeDecode(inst, data, params);
  inst.safeEncodeAsync = async (data, params) => safeEncodeAsync(inst, data, params);
  inst.safeDecodeAsync = async (data, params) => safeDecodeAsync(inst, data, params);
  inst.refine = (check2, params) => inst.check(refine(check2, params));
  inst.superRefine = (refinement) => inst.check(superRefine(refinement));
  inst.overwrite = (fn) => inst.check(_overwrite(fn));
  inst.optional = () => optional(inst);
  inst.exactOptional = () => exactOptional(inst);
  inst.nullable = () => nullable(inst);
  inst.nullish = () => optional(nullable(inst));
  inst.nonoptional = (params) => nonoptional(inst, params);
  inst.array = () => array(inst);
  inst.or = (arg) => union([inst, arg]);
  inst.and = (arg) => intersection(inst, arg);
  inst.transform = (tx) => pipe(inst, transform(tx));
  inst.default = (def2) => _default(inst, def2);
  inst.prefault = (def2) => prefault(inst, def2);
  inst.catch = (params) => _catch(inst, params);
  inst.pipe = (target) => pipe(inst, target);
  inst.readonly = () => readonly(inst);
  inst.describe = (description) => {
    const cl = inst.clone();
    globalRegistry.add(cl, { description });
    return cl;
  };
  Object.defineProperty(inst, "description", {
    get() {
      return globalRegistry.get(inst)?.description;
    },
    configurable: true
  });
  inst.meta = (...args) => {
    if (args.length === 0) {
      return globalRegistry.get(inst);
    }
    const cl = inst.clone();
    globalRegistry.add(cl, args[0]);
    return cl;
  };
  inst.isOptional = () => inst.safeParse(void 0).success;
  inst.isNullable = () => inst.safeParse(null).success;
  inst.apply = (fn) => fn(inst);
  return inst;
});
var _ZodString = $constructor("_ZodString", (inst, def) => {
  $ZodString.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => stringProcessor(inst, ctx, json2, params);
  const bag = inst._zod.bag;
  inst.format = bag.format ?? null;
  inst.minLength = bag.minimum ?? null;
  inst.maxLength = bag.maximum ?? null;
  inst.regex = (...args) => inst.check(_regex(...args));
  inst.includes = (...args) => inst.check(_includes(...args));
  inst.startsWith = (...args) => inst.check(_startsWith(...args));
  inst.endsWith = (...args) => inst.check(_endsWith(...args));
  inst.min = (...args) => inst.check(_minLength(...args));
  inst.max = (...args) => inst.check(_maxLength(...args));
  inst.length = (...args) => inst.check(_length(...args));
  inst.nonempty = (...args) => inst.check(_minLength(1, ...args));
  inst.lowercase = (params) => inst.check(_lowercase(params));
  inst.uppercase = (params) => inst.check(_uppercase(params));
  inst.trim = () => inst.check(_trim());
  inst.normalize = (...args) => inst.check(_normalize(...args));
  inst.toLowerCase = () => inst.check(_toLowerCase());
  inst.toUpperCase = () => inst.check(_toUpperCase());
  inst.slugify = () => inst.check(_slugify());
});
var ZodString = $constructor("ZodString", (inst, def) => {
  $ZodString.init(inst, def);
  _ZodString.init(inst, def);
  inst.email = (params) => inst.check(_email(ZodEmail, params));
  inst.url = (params) => inst.check(_url(ZodURL, params));
  inst.jwt = (params) => inst.check(_jwt(ZodJWT, params));
  inst.emoji = (params) => inst.check(_emoji(ZodEmoji, params));
  inst.guid = (params) => inst.check(_guid(ZodGUID, params));
  inst.uuid = (params) => inst.check(_uuid(ZodUUID, params));
  inst.uuidv4 = (params) => inst.check(_uuidv4(ZodUUID, params));
  inst.uuidv6 = (params) => inst.check(_uuidv6(ZodUUID, params));
  inst.uuidv7 = (params) => inst.check(_uuidv7(ZodUUID, params));
  inst.nanoid = (params) => inst.check(_nanoid(ZodNanoID, params));
  inst.guid = (params) => inst.check(_guid(ZodGUID, params));
  inst.cuid = (params) => inst.check(_cuid(ZodCUID, params));
  inst.cuid2 = (params) => inst.check(_cuid2(ZodCUID2, params));
  inst.ulid = (params) => inst.check(_ulid(ZodULID, params));
  inst.base64 = (params) => inst.check(_base64(ZodBase64, params));
  inst.base64url = (params) => inst.check(_base64url(ZodBase64URL, params));
  inst.xid = (params) => inst.check(_xid(ZodXID, params));
  inst.ksuid = (params) => inst.check(_ksuid(ZodKSUID, params));
  inst.ipv4 = (params) => inst.check(_ipv4(ZodIPv4, params));
  inst.ipv6 = (params) => inst.check(_ipv6(ZodIPv6, params));
  inst.cidrv4 = (params) => inst.check(_cidrv4(ZodCIDRv4, params));
  inst.cidrv6 = (params) => inst.check(_cidrv6(ZodCIDRv6, params));
  inst.e164 = (params) => inst.check(_e164(ZodE164, params));
  inst.datetime = (params) => inst.check(datetime(params));
  inst.date = (params) => inst.check(date(params));
  inst.time = (params) => inst.check(time(params));
  inst.duration = (params) => inst.check(duration(params));
});
function string(params) {
  return _string(ZodString, params);
}
var ZodStringFormat = $constructor("ZodStringFormat", (inst, def) => {
  $ZodStringFormat.init(inst, def);
  _ZodString.init(inst, def);
});
var ZodEmail = $constructor("ZodEmail", (inst, def) => {
  $ZodEmail.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function email(params) {
  return _email(ZodEmail, params);
}
var ZodGUID = $constructor("ZodGUID", (inst, def) => {
  $ZodGUID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function guid(params) {
  return _guid(ZodGUID, params);
}
var ZodUUID = $constructor("ZodUUID", (inst, def) => {
  $ZodUUID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function uuid(params) {
  return _uuid(ZodUUID, params);
}
function uuidv4(params) {
  return _uuidv4(ZodUUID, params);
}
function uuidv6(params) {
  return _uuidv6(ZodUUID, params);
}
function uuidv7(params) {
  return _uuidv7(ZodUUID, params);
}
var ZodURL = $constructor("ZodURL", (inst, def) => {
  $ZodURL.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function url(params) {
  return _url(ZodURL, params);
}
function httpUrl(params) {
  return _url(ZodURL, {
    protocol: /^https?$/,
    hostname: regexes_exports.domain,
    ...util_exports.normalizeParams(params)
  });
}
var ZodEmoji = $constructor("ZodEmoji", (inst, def) => {
  $ZodEmoji.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function emoji(params) {
  return _emoji(ZodEmoji, params);
}
var ZodNanoID = $constructor("ZodNanoID", (inst, def) => {
  $ZodNanoID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function nanoid(params) {
  return _nanoid(ZodNanoID, params);
}
var ZodCUID = $constructor("ZodCUID", (inst, def) => {
  $ZodCUID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function cuid(params) {
  return _cuid(ZodCUID, params);
}
var ZodCUID2 = $constructor("ZodCUID2", (inst, def) => {
  $ZodCUID2.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function cuid2(params) {
  return _cuid2(ZodCUID2, params);
}
var ZodULID = $constructor("ZodULID", (inst, def) => {
  $ZodULID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function ulid(params) {
  return _ulid(ZodULID, params);
}
var ZodXID = $constructor("ZodXID", (inst, def) => {
  $ZodXID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function xid(params) {
  return _xid(ZodXID, params);
}
var ZodKSUID = $constructor("ZodKSUID", (inst, def) => {
  $ZodKSUID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function ksuid(params) {
  return _ksuid(ZodKSUID, params);
}
var ZodIPv4 = $constructor("ZodIPv4", (inst, def) => {
  $ZodIPv4.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function ipv4(params) {
  return _ipv4(ZodIPv4, params);
}
var ZodMAC = $constructor("ZodMAC", (inst, def) => {
  $ZodMAC.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function mac(params) {
  return _mac(ZodMAC, params);
}
var ZodIPv6 = $constructor("ZodIPv6", (inst, def) => {
  $ZodIPv6.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function ipv6(params) {
  return _ipv6(ZodIPv6, params);
}
var ZodCIDRv4 = $constructor("ZodCIDRv4", (inst, def) => {
  $ZodCIDRv4.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function cidrv4(params) {
  return _cidrv4(ZodCIDRv4, params);
}
var ZodCIDRv6 = $constructor("ZodCIDRv6", (inst, def) => {
  $ZodCIDRv6.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function cidrv6(params) {
  return _cidrv6(ZodCIDRv6, params);
}
var ZodBase64 = $constructor("ZodBase64", (inst, def) => {
  $ZodBase64.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function base64(params) {
  return _base64(ZodBase64, params);
}
var ZodBase64URL = $constructor("ZodBase64URL", (inst, def) => {
  $ZodBase64URL.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function base64url(params) {
  return _base64url(ZodBase64URL, params);
}
var ZodE164 = $constructor("ZodE164", (inst, def) => {
  $ZodE164.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function e164(params) {
  return _e164(ZodE164, params);
}
var ZodJWT = $constructor("ZodJWT", (inst, def) => {
  $ZodJWT.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function jwt(params) {
  return _jwt(ZodJWT, params);
}
var ZodCustomStringFormat = $constructor("ZodCustomStringFormat", (inst, def) => {
  $ZodCustomStringFormat.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function stringFormat(format, fnOrRegex, _params = {}) {
  return _stringFormat(ZodCustomStringFormat, format, fnOrRegex, _params);
}
function hostname(_params) {
  return _stringFormat(ZodCustomStringFormat, "hostname", regexes_exports.hostname, _params);
}
function hex(_params) {
  return _stringFormat(ZodCustomStringFormat, "hex", regexes_exports.hex, _params);
}
function hash(alg, params) {
  const enc = params?.enc ?? "hex";
  const format = `${alg}_${enc}`;
  const regex = regexes_exports[format];
  if (!regex)
    throw new Error(`Unrecognized hash format: ${format}`);
  return _stringFormat(ZodCustomStringFormat, format, regex, params);
}
var ZodNumber = $constructor("ZodNumber", (inst, def) => {
  $ZodNumber.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => numberProcessor(inst, ctx, json2, params);
  inst.gt = (value, params) => inst.check(_gt(value, params));
  inst.gte = (value, params) => inst.check(_gte(value, params));
  inst.min = (value, params) => inst.check(_gte(value, params));
  inst.lt = (value, params) => inst.check(_lt(value, params));
  inst.lte = (value, params) => inst.check(_lte(value, params));
  inst.max = (value, params) => inst.check(_lte(value, params));
  inst.int = (params) => inst.check(int(params));
  inst.safe = (params) => inst.check(int(params));
  inst.positive = (params) => inst.check(_gt(0, params));
  inst.nonnegative = (params) => inst.check(_gte(0, params));
  inst.negative = (params) => inst.check(_lt(0, params));
  inst.nonpositive = (params) => inst.check(_lte(0, params));
  inst.multipleOf = (value, params) => inst.check(_multipleOf(value, params));
  inst.step = (value, params) => inst.check(_multipleOf(value, params));
  inst.finite = () => inst;
  const bag = inst._zod.bag;
  inst.minValue = Math.max(bag.minimum ?? Number.NEGATIVE_INFINITY, bag.exclusiveMinimum ?? Number.NEGATIVE_INFINITY) ?? null;
  inst.maxValue = Math.min(bag.maximum ?? Number.POSITIVE_INFINITY, bag.exclusiveMaximum ?? Number.POSITIVE_INFINITY) ?? null;
  inst.isInt = (bag.format ?? "").includes("int") || Number.isSafeInteger(bag.multipleOf ?? 0.5);
  inst.isFinite = true;
  inst.format = bag.format ?? null;
});
function number(params) {
  return _number(ZodNumber, params);
}
var ZodNumberFormat = $constructor("ZodNumberFormat", (inst, def) => {
  $ZodNumberFormat.init(inst, def);
  ZodNumber.init(inst, def);
});
function int(params) {
  return _int(ZodNumberFormat, params);
}
function float32(params) {
  return _float32(ZodNumberFormat, params);
}
function float64(params) {
  return _float64(ZodNumberFormat, params);
}
function int32(params) {
  return _int32(ZodNumberFormat, params);
}
function uint32(params) {
  return _uint32(ZodNumberFormat, params);
}
var ZodBoolean = $constructor("ZodBoolean", (inst, def) => {
  $ZodBoolean.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => booleanProcessor(inst, ctx, json2, params);
});
function boolean(params) {
  return _boolean(ZodBoolean, params);
}
var ZodBigInt = $constructor("ZodBigInt", (inst, def) => {
  $ZodBigInt.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => bigintProcessor(inst, ctx, json2, params);
  inst.gte = (value, params) => inst.check(_gte(value, params));
  inst.min = (value, params) => inst.check(_gte(value, params));
  inst.gt = (value, params) => inst.check(_gt(value, params));
  inst.gte = (value, params) => inst.check(_gte(value, params));
  inst.min = (value, params) => inst.check(_gte(value, params));
  inst.lt = (value, params) => inst.check(_lt(value, params));
  inst.lte = (value, params) => inst.check(_lte(value, params));
  inst.max = (value, params) => inst.check(_lte(value, params));
  inst.positive = (params) => inst.check(_gt(BigInt(0), params));
  inst.negative = (params) => inst.check(_lt(BigInt(0), params));
  inst.nonpositive = (params) => inst.check(_lte(BigInt(0), params));
  inst.nonnegative = (params) => inst.check(_gte(BigInt(0), params));
  inst.multipleOf = (value, params) => inst.check(_multipleOf(value, params));
  const bag = inst._zod.bag;
  inst.minValue = bag.minimum ?? null;
  inst.maxValue = bag.maximum ?? null;
  inst.format = bag.format ?? null;
});
function bigint(params) {
  return _bigint(ZodBigInt, params);
}
var ZodBigIntFormat = $constructor("ZodBigIntFormat", (inst, def) => {
  $ZodBigIntFormat.init(inst, def);
  ZodBigInt.init(inst, def);
});
function int64(params) {
  return _int64(ZodBigIntFormat, params);
}
function uint64(params) {
  return _uint64(ZodBigIntFormat, params);
}
var ZodSymbol = $constructor("ZodSymbol", (inst, def) => {
  $ZodSymbol.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => symbolProcessor(inst, ctx, json2, params);
});
function symbol(params) {
  return _symbol(ZodSymbol, params);
}
var ZodUndefined = $constructor("ZodUndefined", (inst, def) => {
  $ZodUndefined.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => undefinedProcessor(inst, ctx, json2, params);
});
function _undefined2(params) {
  return _undefined(ZodUndefined, params);
}
var ZodNull = $constructor("ZodNull", (inst, def) => {
  $ZodNull.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => nullProcessor(inst, ctx, json2, params);
});
function _null2(params) {
  return _null(ZodNull, params);
}
var ZodAny = $constructor("ZodAny", (inst, def) => {
  $ZodAny.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => anyProcessor(inst, ctx, json2, params);
});
function any() {
  return _any(ZodAny);
}
var ZodUnknown = $constructor("ZodUnknown", (inst, def) => {
  $ZodUnknown.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => unknownProcessor(inst, ctx, json2, params);
});
function unknown() {
  return _unknown(ZodUnknown);
}
var ZodNever = $constructor("ZodNever", (inst, def) => {
  $ZodNever.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => neverProcessor(inst, ctx, json2, params);
});
function never(params) {
  return _never(ZodNever, params);
}
var ZodVoid = $constructor("ZodVoid", (inst, def) => {
  $ZodVoid.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => voidProcessor(inst, ctx, json2, params);
});
function _void2(params) {
  return _void(ZodVoid, params);
}
var ZodDate = $constructor("ZodDate", (inst, def) => {
  $ZodDate.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => dateProcessor(inst, ctx, json2, params);
  inst.min = (value, params) => inst.check(_gte(value, params));
  inst.max = (value, params) => inst.check(_lte(value, params));
  const c = inst._zod.bag;
  inst.minDate = c.minimum ? new Date(c.minimum) : null;
  inst.maxDate = c.maximum ? new Date(c.maximum) : null;
});
function date2(params) {
  return _date(ZodDate, params);
}
var ZodArray = $constructor("ZodArray", (inst, def) => {
  $ZodArray.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => arrayProcessor(inst, ctx, json2, params);
  inst.element = def.element;
  inst.min = (minLength, params) => inst.check(_minLength(minLength, params));
  inst.nonempty = (params) => inst.check(_minLength(1, params));
  inst.max = (maxLength, params) => inst.check(_maxLength(maxLength, params));
  inst.length = (len, params) => inst.check(_length(len, params));
  inst.unwrap = () => inst.element;
});
function array(element, params) {
  return _array(ZodArray, element, params);
}
function keyof(schema) {
  const shape = schema._zod.def.shape;
  return _enum(Object.keys(shape));
}
var ZodObject = $constructor("ZodObject", (inst, def) => {
  $ZodObjectJIT.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => objectProcessor(inst, ctx, json2, params);
  util_exports.defineLazy(inst, "shape", () => {
    return def.shape;
  });
  inst.keyof = () => _enum(Object.keys(inst._zod.def.shape));
  inst.catchall = (catchall) => inst.clone({ ...inst._zod.def, catchall });
  inst.passthrough = () => inst.clone({ ...inst._zod.def, catchall: unknown() });
  inst.loose = () => inst.clone({ ...inst._zod.def, catchall: unknown() });
  inst.strict = () => inst.clone({ ...inst._zod.def, catchall: never() });
  inst.strip = () => inst.clone({ ...inst._zod.def, catchall: void 0 });
  inst.extend = (incoming) => {
    return util_exports.extend(inst, incoming);
  };
  inst.safeExtend = (incoming) => {
    return util_exports.safeExtend(inst, incoming);
  };
  inst.merge = (other) => util_exports.merge(inst, other);
  inst.pick = (mask) => util_exports.pick(inst, mask);
  inst.omit = (mask) => util_exports.omit(inst, mask);
  inst.partial = (...args) => util_exports.partial(ZodOptional, inst, args[0]);
  inst.required = (...args) => util_exports.required(ZodNonOptional, inst, args[0]);
});
function object(shape, params) {
  const def = {
    type: "object",
    shape: shape ?? {},
    ...util_exports.normalizeParams(params)
  };
  return new ZodObject(def);
}
function strictObject(shape, params) {
  return new ZodObject({
    type: "object",
    shape,
    catchall: never(),
    ...util_exports.normalizeParams(params)
  });
}
function looseObject(shape, params) {
  return new ZodObject({
    type: "object",
    shape,
    catchall: unknown(),
    ...util_exports.normalizeParams(params)
  });
}
var ZodUnion = $constructor("ZodUnion", (inst, def) => {
  $ZodUnion.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => unionProcessor(inst, ctx, json2, params);
  inst.options = def.options;
});
function union(options, params) {
  return new ZodUnion({
    type: "union",
    options,
    ...util_exports.normalizeParams(params)
  });
}
var ZodXor = $constructor("ZodXor", (inst, def) => {
  ZodUnion.init(inst, def);
  $ZodXor.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => unionProcessor(inst, ctx, json2, params);
  inst.options = def.options;
});
function xor(options, params) {
  return new ZodXor({
    type: "union",
    options,
    inclusive: false,
    ...util_exports.normalizeParams(params)
  });
}
var ZodDiscriminatedUnion = $constructor("ZodDiscriminatedUnion", (inst, def) => {
  ZodUnion.init(inst, def);
  $ZodDiscriminatedUnion.init(inst, def);
});
function discriminatedUnion(discriminator, options, params) {
  return new ZodDiscriminatedUnion({
    type: "union",
    options,
    discriminator,
    ...util_exports.normalizeParams(params)
  });
}
var ZodIntersection = $constructor("ZodIntersection", (inst, def) => {
  $ZodIntersection.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => intersectionProcessor(inst, ctx, json2, params);
});
function intersection(left, right) {
  return new ZodIntersection({
    type: "intersection",
    left,
    right
  });
}
var ZodTuple = $constructor("ZodTuple", (inst, def) => {
  $ZodTuple.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => tupleProcessor(inst, ctx, json2, params);
  inst.rest = (rest) => inst.clone({
    ...inst._zod.def,
    rest
  });
});
function tuple(items, _paramsOrRest, _params) {
  const hasRest = _paramsOrRest instanceof $ZodType;
  const params = hasRest ? _params : _paramsOrRest;
  const rest = hasRest ? _paramsOrRest : null;
  return new ZodTuple({
    type: "tuple",
    items,
    rest,
    ...util_exports.normalizeParams(params)
  });
}
var ZodRecord = $constructor("ZodRecord", (inst, def) => {
  $ZodRecord.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => recordProcessor(inst, ctx, json2, params);
  inst.keyType = def.keyType;
  inst.valueType = def.valueType;
});
function record(keyType, valueType, params) {
  return new ZodRecord({
    type: "record",
    keyType,
    valueType,
    ...util_exports.normalizeParams(params)
  });
}
function partialRecord(keyType, valueType, params) {
  const k = clone(keyType);
  k._zod.values = void 0;
  return new ZodRecord({
    type: "record",
    keyType: k,
    valueType,
    ...util_exports.normalizeParams(params)
  });
}
function looseRecord(keyType, valueType, params) {
  return new ZodRecord({
    type: "record",
    keyType,
    valueType,
    mode: "loose",
    ...util_exports.normalizeParams(params)
  });
}
var ZodMap = $constructor("ZodMap", (inst, def) => {
  $ZodMap.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => mapProcessor(inst, ctx, json2, params);
  inst.keyType = def.keyType;
  inst.valueType = def.valueType;
  inst.min = (...args) => inst.check(_minSize(...args));
  inst.nonempty = (params) => inst.check(_minSize(1, params));
  inst.max = (...args) => inst.check(_maxSize(...args));
  inst.size = (...args) => inst.check(_size(...args));
});
function map(keyType, valueType, params) {
  return new ZodMap({
    type: "map",
    keyType,
    valueType,
    ...util_exports.normalizeParams(params)
  });
}
var ZodSet = $constructor("ZodSet", (inst, def) => {
  $ZodSet.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => setProcessor(inst, ctx, json2, params);
  inst.min = (...args) => inst.check(_minSize(...args));
  inst.nonempty = (params) => inst.check(_minSize(1, params));
  inst.max = (...args) => inst.check(_maxSize(...args));
  inst.size = (...args) => inst.check(_size(...args));
});
function set(valueType, params) {
  return new ZodSet({
    type: "set",
    valueType,
    ...util_exports.normalizeParams(params)
  });
}
var ZodEnum = $constructor("ZodEnum", (inst, def) => {
  $ZodEnum.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => enumProcessor(inst, ctx, json2, params);
  inst.enum = def.entries;
  inst.options = Object.values(def.entries);
  const keys = new Set(Object.keys(def.entries));
  inst.extract = (values, params) => {
    const newEntries = {};
    for (const value of values) {
      if (keys.has(value)) {
        newEntries[value] = def.entries[value];
      } else
        throw new Error(`Key ${value} not found in enum`);
    }
    return new ZodEnum({
      ...def,
      checks: [],
      ...util_exports.normalizeParams(params),
      entries: newEntries
    });
  };
  inst.exclude = (values, params) => {
    const newEntries = { ...def.entries };
    for (const value of values) {
      if (keys.has(value)) {
        delete newEntries[value];
      } else
        throw new Error(`Key ${value} not found in enum`);
    }
    return new ZodEnum({
      ...def,
      checks: [],
      ...util_exports.normalizeParams(params),
      entries: newEntries
    });
  };
});
function _enum(values, params) {
  const entries = Array.isArray(values) ? Object.fromEntries(values.map((v) => [v, v])) : values;
  return new ZodEnum({
    type: "enum",
    entries,
    ...util_exports.normalizeParams(params)
  });
}
function nativeEnum(entries, params) {
  return new ZodEnum({
    type: "enum",
    entries,
    ...util_exports.normalizeParams(params)
  });
}
var ZodLiteral = $constructor("ZodLiteral", (inst, def) => {
  $ZodLiteral.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => literalProcessor(inst, ctx, json2, params);
  inst.values = new Set(def.values);
  Object.defineProperty(inst, "value", {
    get() {
      if (def.values.length > 1) {
        throw new Error("This schema contains multiple valid literal values. Use `.values` instead.");
      }
      return def.values[0];
    }
  });
});
function literal(value, params) {
  return new ZodLiteral({
    type: "literal",
    values: Array.isArray(value) ? value : [value],
    ...util_exports.normalizeParams(params)
  });
}
var ZodFile = $constructor("ZodFile", (inst, def) => {
  $ZodFile.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => fileProcessor(inst, ctx, json2, params);
  inst.min = (size, params) => inst.check(_minSize(size, params));
  inst.max = (size, params) => inst.check(_maxSize(size, params));
  inst.mime = (types, params) => inst.check(_mime(Array.isArray(types) ? types : [types], params));
});
function file(params) {
  return _file(ZodFile, params);
}
var ZodTransform = $constructor("ZodTransform", (inst, def) => {
  $ZodTransform.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => transformProcessor(inst, ctx, json2, params);
  inst._zod.parse = (payload, _ctx) => {
    if (_ctx.direction === "backward") {
      throw new $ZodEncodeError(inst.constructor.name);
    }
    payload.addIssue = (issue) => {
      if (typeof issue === "string") {
        payload.issues.push(util_exports.issue(issue, payload.value, def));
      } else {
        const _issue = issue;
        if (_issue.fatal)
          _issue.continue = false;
        _issue.code ?? (_issue.code = "custom");
        _issue.input ?? (_issue.input = payload.value);
        _issue.inst ?? (_issue.inst = inst);
        payload.issues.push(util_exports.issue(_issue));
      }
    };
    const output = def.transform(payload.value, payload);
    if (output instanceof Promise) {
      return output.then((output2) => {
        payload.value = output2;
        return payload;
      });
    }
    payload.value = output;
    return payload;
  };
});
function transform(fn) {
  return new ZodTransform({
    type: "transform",
    transform: fn
  });
}
var ZodOptional = $constructor("ZodOptional", (inst, def) => {
  $ZodOptional.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => optionalProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function optional(innerType) {
  return new ZodOptional({
    type: "optional",
    innerType
  });
}
var ZodExactOptional = $constructor("ZodExactOptional", (inst, def) => {
  $ZodExactOptional.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => optionalProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function exactOptional(innerType) {
  return new ZodExactOptional({
    type: "optional",
    innerType
  });
}
var ZodNullable = $constructor("ZodNullable", (inst, def) => {
  $ZodNullable.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => nullableProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function nullable(innerType) {
  return new ZodNullable({
    type: "nullable",
    innerType
  });
}
function nullish(innerType) {
  return optional(nullable(innerType));
}
var ZodDefault = $constructor("ZodDefault", (inst, def) => {
  $ZodDefault.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => defaultProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
  inst.removeDefault = inst.unwrap;
});
function _default(innerType, defaultValue) {
  return new ZodDefault({
    type: "default",
    innerType,
    get defaultValue() {
      return typeof defaultValue === "function" ? defaultValue() : util_exports.shallowClone(defaultValue);
    }
  });
}
var ZodPrefault = $constructor("ZodPrefault", (inst, def) => {
  $ZodPrefault.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => prefaultProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function prefault(innerType, defaultValue) {
  return new ZodPrefault({
    type: "prefault",
    innerType,
    get defaultValue() {
      return typeof defaultValue === "function" ? defaultValue() : util_exports.shallowClone(defaultValue);
    }
  });
}
var ZodNonOptional = $constructor("ZodNonOptional", (inst, def) => {
  $ZodNonOptional.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => nonoptionalProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function nonoptional(innerType, params) {
  return new ZodNonOptional({
    type: "nonoptional",
    innerType,
    ...util_exports.normalizeParams(params)
  });
}
var ZodSuccess = $constructor("ZodSuccess", (inst, def) => {
  $ZodSuccess.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => successProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function success(innerType) {
  return new ZodSuccess({
    type: "success",
    innerType
  });
}
var ZodCatch = $constructor("ZodCatch", (inst, def) => {
  $ZodCatch.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => catchProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
  inst.removeCatch = inst.unwrap;
});
function _catch(innerType, catchValue) {
  return new ZodCatch({
    type: "catch",
    innerType,
    catchValue: typeof catchValue === "function" ? catchValue : () => catchValue
  });
}
var ZodNaN = $constructor("ZodNaN", (inst, def) => {
  $ZodNaN.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => nanProcessor(inst, ctx, json2, params);
});
function nan(params) {
  return _nan(ZodNaN, params);
}
var ZodPipe = $constructor("ZodPipe", (inst, def) => {
  $ZodPipe.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => pipeProcessor(inst, ctx, json2, params);
  inst.in = def.in;
  inst.out = def.out;
});
function pipe(in_, out) {
  return new ZodPipe({
    type: "pipe",
    in: in_,
    out
    // ...util.normalizeParams(params),
  });
}
var ZodCodec = $constructor("ZodCodec", (inst, def) => {
  ZodPipe.init(inst, def);
  $ZodCodec.init(inst, def);
});
function codec(in_, out, params) {
  return new ZodCodec({
    type: "pipe",
    in: in_,
    out,
    transform: params.decode,
    reverseTransform: params.encode
  });
}
var ZodReadonly = $constructor("ZodReadonly", (inst, def) => {
  $ZodReadonly.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => readonlyProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function readonly(innerType) {
  return new ZodReadonly({
    type: "readonly",
    innerType
  });
}
var ZodTemplateLiteral = $constructor("ZodTemplateLiteral", (inst, def) => {
  $ZodTemplateLiteral.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => templateLiteralProcessor(inst, ctx, json2, params);
});
function templateLiteral(parts, params) {
  return new ZodTemplateLiteral({
    type: "template_literal",
    parts,
    ...util_exports.normalizeParams(params)
  });
}
var ZodLazy = $constructor("ZodLazy", (inst, def) => {
  $ZodLazy.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => lazyProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.getter();
});
function lazy(getter) {
  return new ZodLazy({
    type: "lazy",
    getter
  });
}
var ZodPromise = $constructor("ZodPromise", (inst, def) => {
  $ZodPromise.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => promiseProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function promise(innerType) {
  return new ZodPromise({
    type: "promise",
    innerType
  });
}
var ZodFunction = $constructor("ZodFunction", (inst, def) => {
  $ZodFunction.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => functionProcessor(inst, ctx, json2, params);
});
function _function(params) {
  return new ZodFunction({
    type: "function",
    input: Array.isArray(params?.input) ? tuple(params?.input) : params?.input ?? array(unknown()),
    output: params?.output ?? unknown()
  });
}
var ZodCustom = $constructor("ZodCustom", (inst, def) => {
  $ZodCustom.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => customProcessor(inst, ctx, json2, params);
});
function check(fn) {
  const ch = new $ZodCheck({
    check: "custom"
    // ...util.normalizeParams(params),
  });
  ch._zod.check = fn;
  return ch;
}
function custom(fn, _params) {
  return _custom(ZodCustom, fn ?? (() => true), _params);
}
function refine(fn, _params = {}) {
  return _refine(ZodCustom, fn, _params);
}
function superRefine(fn) {
  return _superRefine(fn);
}
var describe2 = describe;
var meta2 = meta;
function _instanceof(cls, params = {}) {
  const inst = new ZodCustom({
    type: "custom",
    check: "custom",
    fn: (data) => data instanceof cls,
    abort: true,
    ...util_exports.normalizeParams(params)
  });
  inst._zod.bag.Class = cls;
  inst._zod.check = (payload) => {
    if (!(payload.value instanceof cls)) {
      payload.issues.push({
        code: "invalid_type",
        expected: cls.name,
        input: payload.value,
        inst,
        path: [...inst._zod.def.path ?? []]
      });
    }
  };
  return inst;
}
var stringbool = (...args) => _stringbool({
  Codec: ZodCodec,
  Boolean: ZodBoolean,
  String: ZodString
}, ...args);
function json(params) {
  const jsonSchema = lazy(() => {
    return union([string(params), number(), boolean(), _null2(), array(jsonSchema), record(string(), jsonSchema)]);
  });
  return jsonSchema;
}
function preprocess(fn, schema) {
  return pipe(transform(fn), schema);
}

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/compat.js
var ZodIssueCode = {
  invalid_type: "invalid_type",
  too_big: "too_big",
  too_small: "too_small",
  invalid_format: "invalid_format",
  not_multiple_of: "not_multiple_of",
  unrecognized_keys: "unrecognized_keys",
  invalid_union: "invalid_union",
  invalid_key: "invalid_key",
  invalid_element: "invalid_element",
  invalid_value: "invalid_value",
  custom: "custom"
};
function setErrorMap(map2) {
  config({
    customError: map2
  });
}
function getErrorMap() {
  return config().customError;
}
var ZodFirstPartyTypeKind2;
/* @__PURE__ */ (function(ZodFirstPartyTypeKind3) {
})(ZodFirstPartyTypeKind2 || (ZodFirstPartyTypeKind2 = {}));

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/from-json-schema.js
var z = {
  ...schemas_exports,
  ...checks_exports,
  iso: iso_exports
};
var RECOGNIZED_KEYS = /* @__PURE__ */ new Set([
  // Schema identification
  "$schema",
  "$ref",
  "$defs",
  "definitions",
  // Core schema keywords
  "$id",
  "id",
  "$comment",
  "$anchor",
  "$vocabulary",
  "$dynamicRef",
  "$dynamicAnchor",
  // Type
  "type",
  "enum",
  "const",
  // Composition
  "anyOf",
  "oneOf",
  "allOf",
  "not",
  // Object
  "properties",
  "required",
  "additionalProperties",
  "patternProperties",
  "propertyNames",
  "minProperties",
  "maxProperties",
  // Array
  "items",
  "prefixItems",
  "additionalItems",
  "minItems",
  "maxItems",
  "uniqueItems",
  "contains",
  "minContains",
  "maxContains",
  // String
  "minLength",
  "maxLength",
  "pattern",
  "format",
  // Number
  "minimum",
  "maximum",
  "exclusiveMinimum",
  "exclusiveMaximum",
  "multipleOf",
  // Already handled metadata
  "description",
  "default",
  // Content
  "contentEncoding",
  "contentMediaType",
  "contentSchema",
  // Unsupported (error-throwing)
  "unevaluatedItems",
  "unevaluatedProperties",
  "if",
  "then",
  "else",
  "dependentSchemas",
  "dependentRequired",
  // OpenAPI
  "nullable",
  "readOnly"
]);
function detectVersion(schema, defaultTarget) {
  const $schema = schema.$schema;
  if ($schema === "https://json-schema.org/draft/2020-12/schema") {
    return "draft-2020-12";
  }
  if ($schema === "http://json-schema.org/draft-07/schema#") {
    return "draft-7";
  }
  if ($schema === "http://json-schema.org/draft-04/schema#") {
    return "draft-4";
  }
  return defaultTarget ?? "draft-2020-12";
}
function resolveRef(ref, ctx) {
  if (!ref.startsWith("#")) {
    throw new Error("External $ref is not supported, only local refs (#/...) are allowed");
  }
  const path2 = ref.slice(1).split("/").filter(Boolean);
  if (path2.length === 0) {
    return ctx.rootSchema;
  }
  const defsKey = ctx.version === "draft-2020-12" ? "$defs" : "definitions";
  if (path2[0] === defsKey) {
    const key = path2[1];
    if (!key || !ctx.defs[key]) {
      throw new Error(`Reference not found: ${ref}`);
    }
    return ctx.defs[key];
  }
  throw new Error(`Reference not found: ${ref}`);
}
function convertBaseSchema(schema, ctx) {
  if (schema.not !== void 0) {
    if (typeof schema.not === "object" && Object.keys(schema.not).length === 0) {
      return z.never();
    }
    throw new Error("not is not supported in Zod (except { not: {} } for never)");
  }
  if (schema.unevaluatedItems !== void 0) {
    throw new Error("unevaluatedItems is not supported");
  }
  if (schema.unevaluatedProperties !== void 0) {
    throw new Error("unevaluatedProperties is not supported");
  }
  if (schema.if !== void 0 || schema.then !== void 0 || schema.else !== void 0) {
    throw new Error("Conditional schemas (if/then/else) are not supported");
  }
  if (schema.dependentSchemas !== void 0 || schema.dependentRequired !== void 0) {
    throw new Error("dependentSchemas and dependentRequired are not supported");
  }
  if (schema.$ref) {
    const refPath = schema.$ref;
    if (ctx.refs.has(refPath)) {
      return ctx.refs.get(refPath);
    }
    if (ctx.processing.has(refPath)) {
      return z.lazy(() => {
        if (!ctx.refs.has(refPath)) {
          throw new Error(`Circular reference not resolved: ${refPath}`);
        }
        return ctx.refs.get(refPath);
      });
    }
    ctx.processing.add(refPath);
    const resolved = resolveRef(refPath, ctx);
    const zodSchema2 = convertSchema(resolved, ctx);
    ctx.refs.set(refPath, zodSchema2);
    ctx.processing.delete(refPath);
    return zodSchema2;
  }
  if (schema.enum !== void 0) {
    const enumValues = schema.enum;
    if (ctx.version === "openapi-3.0" && schema.nullable === true && enumValues.length === 1 && enumValues[0] === null) {
      return z.null();
    }
    if (enumValues.length === 0) {
      return z.never();
    }
    if (enumValues.length === 1) {
      return z.literal(enumValues[0]);
    }
    if (enumValues.every((v) => typeof v === "string")) {
      return z.enum(enumValues);
    }
    const literalSchemas = enumValues.map((v) => z.literal(v));
    if (literalSchemas.length < 2) {
      return literalSchemas[0];
    }
    return z.union([literalSchemas[0], literalSchemas[1], ...literalSchemas.slice(2)]);
  }
  if (schema.const !== void 0) {
    return z.literal(schema.const);
  }
  const type = schema.type;
  if (Array.isArray(type)) {
    const typeSchemas = type.map((t) => {
      const typeSchema = { ...schema, type: t };
      return convertBaseSchema(typeSchema, ctx);
    });
    if (typeSchemas.length === 0) {
      return z.never();
    }
    if (typeSchemas.length === 1) {
      return typeSchemas[0];
    }
    return z.union(typeSchemas);
  }
  if (!type) {
    return z.any();
  }
  let zodSchema;
  switch (type) {
    case "string": {
      let stringSchema = z.string();
      if (schema.format) {
        const format = schema.format;
        if (format === "email") {
          stringSchema = stringSchema.check(z.email());
        } else if (format === "uri" || format === "uri-reference") {
          stringSchema = stringSchema.check(z.url());
        } else if (format === "uuid" || format === "guid") {
          stringSchema = stringSchema.check(z.uuid());
        } else if (format === "date-time") {
          stringSchema = stringSchema.check(z.iso.datetime());
        } else if (format === "date") {
          stringSchema = stringSchema.check(z.iso.date());
        } else if (format === "time") {
          stringSchema = stringSchema.check(z.iso.time());
        } else if (format === "duration") {
          stringSchema = stringSchema.check(z.iso.duration());
        } else if (format === "ipv4") {
          stringSchema = stringSchema.check(z.ipv4());
        } else if (format === "ipv6") {
          stringSchema = stringSchema.check(z.ipv6());
        } else if (format === "mac") {
          stringSchema = stringSchema.check(z.mac());
        } else if (format === "cidr") {
          stringSchema = stringSchema.check(z.cidrv4());
        } else if (format === "cidr-v6") {
          stringSchema = stringSchema.check(z.cidrv6());
        } else if (format === "base64") {
          stringSchema = stringSchema.check(z.base64());
        } else if (format === "base64url") {
          stringSchema = stringSchema.check(z.base64url());
        } else if (format === "e164") {
          stringSchema = stringSchema.check(z.e164());
        } else if (format === "jwt") {
          stringSchema = stringSchema.check(z.jwt());
        } else if (format === "emoji") {
          stringSchema = stringSchema.check(z.emoji());
        } else if (format === "nanoid") {
          stringSchema = stringSchema.check(z.nanoid());
        } else if (format === "cuid") {
          stringSchema = stringSchema.check(z.cuid());
        } else if (format === "cuid2") {
          stringSchema = stringSchema.check(z.cuid2());
        } else if (format === "ulid") {
          stringSchema = stringSchema.check(z.ulid());
        } else if (format === "xid") {
          stringSchema = stringSchema.check(z.xid());
        } else if (format === "ksuid") {
          stringSchema = stringSchema.check(z.ksuid());
        }
      }
      if (typeof schema.minLength === "number") {
        stringSchema = stringSchema.min(schema.minLength);
      }
      if (typeof schema.maxLength === "number") {
        stringSchema = stringSchema.max(schema.maxLength);
      }
      if (schema.pattern) {
        stringSchema = stringSchema.regex(new RegExp(schema.pattern));
      }
      zodSchema = stringSchema;
      break;
    }
    case "number":
    case "integer": {
      let numberSchema = type === "integer" ? z.number().int() : z.number();
      if (typeof schema.minimum === "number") {
        numberSchema = numberSchema.min(schema.minimum);
      }
      if (typeof schema.maximum === "number") {
        numberSchema = numberSchema.max(schema.maximum);
      }
      if (typeof schema.exclusiveMinimum === "number") {
        numberSchema = numberSchema.gt(schema.exclusiveMinimum);
      } else if (schema.exclusiveMinimum === true && typeof schema.minimum === "number") {
        numberSchema = numberSchema.gt(schema.minimum);
      }
      if (typeof schema.exclusiveMaximum === "number") {
        numberSchema = numberSchema.lt(schema.exclusiveMaximum);
      } else if (schema.exclusiveMaximum === true && typeof schema.maximum === "number") {
        numberSchema = numberSchema.lt(schema.maximum);
      }
      if (typeof schema.multipleOf === "number") {
        numberSchema = numberSchema.multipleOf(schema.multipleOf);
      }
      zodSchema = numberSchema;
      break;
    }
    case "boolean": {
      zodSchema = z.boolean();
      break;
    }
    case "null": {
      zodSchema = z.null();
      break;
    }
    case "object": {
      const shape = {};
      const properties = schema.properties || {};
      const requiredSet = new Set(schema.required || []);
      for (const [key, propSchema] of Object.entries(properties)) {
        const propZodSchema = convertSchema(propSchema, ctx);
        shape[key] = requiredSet.has(key) ? propZodSchema : propZodSchema.optional();
      }
      if (schema.propertyNames) {
        const keySchema = convertSchema(schema.propertyNames, ctx);
        const valueSchema = schema.additionalProperties && typeof schema.additionalProperties === "object" ? convertSchema(schema.additionalProperties, ctx) : z.any();
        if (Object.keys(shape).length === 0) {
          zodSchema = z.record(keySchema, valueSchema);
          break;
        }
        const objectSchema2 = z.object(shape).passthrough();
        const recordSchema = z.looseRecord(keySchema, valueSchema);
        zodSchema = z.intersection(objectSchema2, recordSchema);
        break;
      }
      if (schema.patternProperties) {
        const patternProps = schema.patternProperties;
        const patternKeys = Object.keys(patternProps);
        const looseRecords = [];
        for (const pattern of patternKeys) {
          const patternValue = convertSchema(patternProps[pattern], ctx);
          const keySchema = z.string().regex(new RegExp(pattern));
          looseRecords.push(z.looseRecord(keySchema, patternValue));
        }
        const schemasToIntersect = [];
        if (Object.keys(shape).length > 0) {
          schemasToIntersect.push(z.object(shape).passthrough());
        }
        schemasToIntersect.push(...looseRecords);
        if (schemasToIntersect.length === 0) {
          zodSchema = z.object({}).passthrough();
        } else if (schemasToIntersect.length === 1) {
          zodSchema = schemasToIntersect[0];
        } else {
          let result = z.intersection(schemasToIntersect[0], schemasToIntersect[1]);
          for (let i = 2; i < schemasToIntersect.length; i++) {
            result = z.intersection(result, schemasToIntersect[i]);
          }
          zodSchema = result;
        }
        break;
      }
      const objectSchema = z.object(shape);
      if (schema.additionalProperties === false) {
        zodSchema = objectSchema.strict();
      } else if (typeof schema.additionalProperties === "object") {
        zodSchema = objectSchema.catchall(convertSchema(schema.additionalProperties, ctx));
      } else {
        zodSchema = objectSchema.passthrough();
      }
      break;
    }
    case "array": {
      const prefixItems = schema.prefixItems;
      const items = schema.items;
      if (prefixItems && Array.isArray(prefixItems)) {
        const tupleItems = prefixItems.map((item) => convertSchema(item, ctx));
        const rest = items && typeof items === "object" && !Array.isArray(items) ? convertSchema(items, ctx) : void 0;
        if (rest) {
          zodSchema = z.tuple(tupleItems).rest(rest);
        } else {
          zodSchema = z.tuple(tupleItems);
        }
        if (typeof schema.minItems === "number") {
          zodSchema = zodSchema.check(z.minLength(schema.minItems));
        }
        if (typeof schema.maxItems === "number") {
          zodSchema = zodSchema.check(z.maxLength(schema.maxItems));
        }
      } else if (Array.isArray(items)) {
        const tupleItems = items.map((item) => convertSchema(item, ctx));
        const rest = schema.additionalItems && typeof schema.additionalItems === "object" ? convertSchema(schema.additionalItems, ctx) : void 0;
        if (rest) {
          zodSchema = z.tuple(tupleItems).rest(rest);
        } else {
          zodSchema = z.tuple(tupleItems);
        }
        if (typeof schema.minItems === "number") {
          zodSchema = zodSchema.check(z.minLength(schema.minItems));
        }
        if (typeof schema.maxItems === "number") {
          zodSchema = zodSchema.check(z.maxLength(schema.maxItems));
        }
      } else if (items !== void 0) {
        const element = convertSchema(items, ctx);
        let arraySchema = z.array(element);
        if (typeof schema.minItems === "number") {
          arraySchema = arraySchema.min(schema.minItems);
        }
        if (typeof schema.maxItems === "number") {
          arraySchema = arraySchema.max(schema.maxItems);
        }
        zodSchema = arraySchema;
      } else {
        zodSchema = z.array(z.any());
      }
      break;
    }
    default:
      throw new Error(`Unsupported type: ${type}`);
  }
  if (schema.description) {
    zodSchema = zodSchema.describe(schema.description);
  }
  if (schema.default !== void 0) {
    zodSchema = zodSchema.default(schema.default);
  }
  return zodSchema;
}
function convertSchema(schema, ctx) {
  if (typeof schema === "boolean") {
    return schema ? z.any() : z.never();
  }
  let baseSchema = convertBaseSchema(schema, ctx);
  const hasExplicitType = schema.type || schema.enum !== void 0 || schema.const !== void 0;
  if (schema.anyOf && Array.isArray(schema.anyOf)) {
    const options = schema.anyOf.map((s) => convertSchema(s, ctx));
    const anyOfUnion = z.union(options);
    baseSchema = hasExplicitType ? z.intersection(baseSchema, anyOfUnion) : anyOfUnion;
  }
  if (schema.oneOf && Array.isArray(schema.oneOf)) {
    const options = schema.oneOf.map((s) => convertSchema(s, ctx));
    const oneOfUnion = z.xor(options);
    baseSchema = hasExplicitType ? z.intersection(baseSchema, oneOfUnion) : oneOfUnion;
  }
  if (schema.allOf && Array.isArray(schema.allOf)) {
    if (schema.allOf.length === 0) {
      baseSchema = hasExplicitType ? baseSchema : z.any();
    } else {
      let result = hasExplicitType ? baseSchema : convertSchema(schema.allOf[0], ctx);
      const startIdx = hasExplicitType ? 0 : 1;
      for (let i = startIdx; i < schema.allOf.length; i++) {
        result = z.intersection(result, convertSchema(schema.allOf[i], ctx));
      }
      baseSchema = result;
    }
  }
  if (schema.nullable === true && ctx.version === "openapi-3.0") {
    baseSchema = z.nullable(baseSchema);
  }
  if (schema.readOnly === true) {
    baseSchema = z.readonly(baseSchema);
  }
  const extraMeta = {};
  const coreMetadataKeys = ["$id", "id", "$comment", "$anchor", "$vocabulary", "$dynamicRef", "$dynamicAnchor"];
  for (const key of coreMetadataKeys) {
    if (key in schema) {
      extraMeta[key] = schema[key];
    }
  }
  const contentMetadataKeys = ["contentEncoding", "contentMediaType", "contentSchema"];
  for (const key of contentMetadataKeys) {
    if (key in schema) {
      extraMeta[key] = schema[key];
    }
  }
  for (const key of Object.keys(schema)) {
    if (!RECOGNIZED_KEYS.has(key)) {
      extraMeta[key] = schema[key];
    }
  }
  if (Object.keys(extraMeta).length > 0) {
    ctx.registry.add(baseSchema, extraMeta);
  }
  return baseSchema;
}
function fromJSONSchema(schema, params) {
  if (typeof schema === "boolean") {
    return schema ? z.any() : z.never();
  }
  const version = detectVersion(schema, params?.defaultTarget);
  const defs = schema.$defs || schema.definitions || {};
  const ctx = {
    version,
    defs,
    refs: /* @__PURE__ */ new Map(),
    processing: /* @__PURE__ */ new Set(),
    rootSchema: schema,
    registry: params?.registry ?? globalRegistry
  };
  return convertSchema(schema, ctx);
}

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/coerce.js
var coerce_exports = {};
__export(coerce_exports, {
  bigint: () => bigint2,
  boolean: () => boolean2,
  date: () => date3,
  number: () => number2,
  string: () => string2
});
function string2(params) {
  return _coercedString(ZodString, params);
}
function number2(params) {
  return _coercedNumber(ZodNumber, params);
}
function boolean2(params) {
  return _coercedBoolean(ZodBoolean, params);
}
function bigint2(params) {
  return _coercedBigint(ZodBigInt, params);
}
function date3(params) {
  return _coercedDate(ZodDate, params);
}

// node_modules/.pnpm/zod@4.3.6/node_modules/zod/v4/classic/external.js
config(en_default());

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/Options.mjs
var ignoreOverride = /* @__PURE__ */ Symbol("Let zodToJsonSchema decide on which parser to use");
var defaultOptions = {
  name: void 0,
  $refStrategy: "root",
  effectStrategy: "input",
  pipeStrategy: "all",
  dateStrategy: "format:date-time",
  mapStrategy: "entries",
  nullableStrategy: "from-target",
  removeAdditionalStrategy: "passthrough",
  definitionPath: "definitions",
  target: "jsonSchema7",
  strictUnions: false,
  errorMessages: false,
  markdownDescription: false,
  patternStrategy: "escape",
  applyRegexFlags: false,
  emailStrategy: "format:email",
  base64Strategy: "contentEncoding:base64",
  nameStrategy: "ref"
};
var getDefaultOptions = (options) => {
  return typeof options === "string" ? {
    ...defaultOptions,
    basePath: ["#"],
    definitions: {},
    name: options
  } : {
    ...defaultOptions,
    basePath: ["#"],
    definitions: {},
    ...options
  };
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/util.mjs
var zodDef = (zodSchema) => {
  return "_def" in zodSchema ? zodSchema._def : zodSchema;
};
function isEmptyObj2(obj) {
  if (!obj)
    return true;
  for (const _k in obj)
    return false;
  return true;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/Refs.mjs
var getRefs = (options) => {
  const _options = getDefaultOptions(options);
  const currentPath = _options.name !== void 0 ? [..._options.basePath, _options.definitionPath, _options.name] : _options.basePath;
  return {
    ..._options,
    currentPath,
    propertyPath: void 0,
    seenRefs: /* @__PURE__ */ new Set(),
    seen: new Map(Object.entries(_options.definitions).map(([name, def]) => [
      zodDef(def),
      {
        def: zodDef(def),
        path: [..._options.basePath, _options.definitionPath, name],
        // Resolution of references will be forced even though seen, so it's ok that the schema is undefined here for now.
        jsonSchema: void 0
      }
    ]))
  };
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/errorMessages.mjs
function addErrorMessage(res, key, errorMessage, refs) {
  if (!refs?.errorMessages)
    return;
  if (errorMessage) {
    res.errorMessage = {
      ...res.errorMessage,
      [key]: errorMessage
    };
  }
}
function setResponseValueAndErrors(res, key, value, errorMessage, refs) {
  res[key] = value;
  addErrorMessage(res, key, errorMessage, refs);
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/any.mjs
function parseAnyDef() {
  return {};
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/array.mjs
function parseArrayDef(def, refs) {
  const res = {
    type: "array"
  };
  if (def.type?._def?.typeName !== ZodFirstPartyTypeKind.ZodAny) {
    res.items = parseDef(def.type._def, {
      ...refs,
      currentPath: [...refs.currentPath, "items"]
    });
  }
  if (def.minLength) {
    setResponseValueAndErrors(res, "minItems", def.minLength.value, def.minLength.message, refs);
  }
  if (def.maxLength) {
    setResponseValueAndErrors(res, "maxItems", def.maxLength.value, def.maxLength.message, refs);
  }
  if (def.exactLength) {
    setResponseValueAndErrors(res, "minItems", def.exactLength.value, def.exactLength.message, refs);
    setResponseValueAndErrors(res, "maxItems", def.exactLength.value, def.exactLength.message, refs);
  }
  return res;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/bigint.mjs
function parseBigintDef(def, refs) {
  const res = {
    type: "integer",
    format: "int64"
  };
  if (!def.checks)
    return res;
  for (const check2 of def.checks) {
    switch (check2.kind) {
      case "min":
        if (refs.target === "jsonSchema7") {
          if (check2.inclusive) {
            setResponseValueAndErrors(res, "minimum", check2.value, check2.message, refs);
          } else {
            setResponseValueAndErrors(res, "exclusiveMinimum", check2.value, check2.message, refs);
          }
        } else {
          if (!check2.inclusive) {
            res.exclusiveMinimum = true;
          }
          setResponseValueAndErrors(res, "minimum", check2.value, check2.message, refs);
        }
        break;
      case "max":
        if (refs.target === "jsonSchema7") {
          if (check2.inclusive) {
            setResponseValueAndErrors(res, "maximum", check2.value, check2.message, refs);
          } else {
            setResponseValueAndErrors(res, "exclusiveMaximum", check2.value, check2.message, refs);
          }
        } else {
          if (!check2.inclusive) {
            res.exclusiveMaximum = true;
          }
          setResponseValueAndErrors(res, "maximum", check2.value, check2.message, refs);
        }
        break;
      case "multipleOf":
        setResponseValueAndErrors(res, "multipleOf", check2.value, check2.message, refs);
        break;
    }
  }
  return res;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/boolean.mjs
function parseBooleanDef() {
  return {
    type: "boolean"
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/branded.mjs
function parseBrandedDef(_def, refs) {
  return parseDef(_def.type._def, refs);
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/catch.mjs
var parseCatchDef = (def, refs) => {
  return parseDef(def.innerType._def, refs);
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/date.mjs
function parseDateDef(def, refs, overrideDateStrategy) {
  const strategy = overrideDateStrategy ?? refs.dateStrategy;
  if (Array.isArray(strategy)) {
    return {
      anyOf: strategy.map((item, i) => parseDateDef(def, refs, item))
    };
  }
  switch (strategy) {
    case "string":
    case "format:date-time":
      return {
        type: "string",
        format: "date-time"
      };
    case "format:date":
      return {
        type: "string",
        format: "date"
      };
    case "integer":
      return integerDateParser(def, refs);
  }
}
var integerDateParser = (def, refs) => {
  const res = {
    type: "integer",
    format: "unix-time"
  };
  if (refs.target === "openApi3") {
    return res;
  }
  for (const check2 of def.checks) {
    switch (check2.kind) {
      case "min":
        setResponseValueAndErrors(
          res,
          "minimum",
          check2.value,
          // This is in milliseconds
          check2.message,
          refs
        );
        break;
      case "max":
        setResponseValueAndErrors(
          res,
          "maximum",
          check2.value,
          // This is in milliseconds
          check2.message,
          refs
        );
        break;
    }
  }
  return res;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/default.mjs
function parseDefaultDef(_def, refs) {
  return {
    ...parseDef(_def.innerType._def, refs),
    default: _def.defaultValue()
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/effects.mjs
function parseEffectsDef(_def, refs, forceResolution) {
  return refs.effectStrategy === "input" ? parseDef(_def.schema._def, refs, forceResolution) : {};
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/enum.mjs
function parseEnumDef(def) {
  return {
    type: "string",
    enum: [...def.values]
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/intersection.mjs
var isJsonSchema7AllOfType = (type) => {
  if ("type" in type && type.type === "string")
    return false;
  return "allOf" in type;
};
function parseIntersectionDef(def, refs) {
  const allOf = [
    parseDef(def.left._def, {
      ...refs,
      currentPath: [...refs.currentPath, "allOf", "0"]
    }),
    parseDef(def.right._def, {
      ...refs,
      currentPath: [...refs.currentPath, "allOf", "1"]
    })
  ].filter((x) => !!x);
  let unevaluatedProperties = refs.target === "jsonSchema2019-09" ? { unevaluatedProperties: false } : void 0;
  const mergedAllOf = [];
  allOf.forEach((schema) => {
    if (isJsonSchema7AllOfType(schema)) {
      mergedAllOf.push(...schema.allOf);
      if (schema.unevaluatedProperties === void 0) {
        unevaluatedProperties = void 0;
      }
    } else {
      let nestedSchema = schema;
      if ("additionalProperties" in schema && schema.additionalProperties === false) {
        const { additionalProperties, ...rest } = schema;
        nestedSchema = rest;
      } else {
        unevaluatedProperties = void 0;
      }
      mergedAllOf.push(nestedSchema);
    }
  });
  return mergedAllOf.length ? {
    allOf: mergedAllOf,
    ...unevaluatedProperties
  } : void 0;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/literal.mjs
function parseLiteralDef(def, refs) {
  const parsedType = typeof def.value;
  if (parsedType !== "bigint" && parsedType !== "number" && parsedType !== "boolean" && parsedType !== "string") {
    return {
      type: Array.isArray(def.value) ? "array" : "object"
    };
  }
  if (refs.target === "openApi3") {
    return {
      type: parsedType === "bigint" ? "integer" : parsedType,
      enum: [def.value]
    };
  }
  return {
    type: parsedType === "bigint" ? "integer" : parsedType,
    const: def.value
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/string.mjs
var emojiRegex;
var zodPatterns = {
  /**
   * `c` was changed to `[cC]` to replicate /i flag
   */
  cuid: /^[cC][^\s-]{8,}$/,
  cuid2: /^[0-9a-z]+$/,
  ulid: /^[0-9A-HJKMNP-TV-Z]{26}$/,
  /**
   * `a-z` was added to replicate /i flag
   */
  email: /^(?!\.)(?!.*\.\.)([a-zA-Z0-9_'+\-\.]*)[a-zA-Z0-9_+-]@([a-zA-Z0-9][a-zA-Z0-9\-]*\.)+[a-zA-Z]{2,}$/,
  /**
   * Constructed a valid Unicode RegExp
   *
   * Lazily instantiate since this type of regex isn't supported
   * in all envs (e.g. React Native).
   *
   * See:
   * https://github.com/colinhacks/zod/issues/2433
   * Fix in Zod:
   * https://github.com/colinhacks/zod/commit/9340fd51e48576a75adc919bff65dbc4a5d4c99b
   */
  emoji: () => {
    if (emojiRegex === void 0) {
      emojiRegex = RegExp("^(\\p{Extended_Pictographic}|\\p{Emoji_Component})+$", "u");
    }
    return emojiRegex;
  },
  /**
   * Unused
   */
  uuid: /^[0-9a-fA-F]{8}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{12}$/,
  /**
   * Unused
   */
  ipv4: /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])$/,
  /**
   * Unused
   */
  ipv6: /^(([a-f0-9]{1,4}:){7}|::([a-f0-9]{1,4}:){0,6}|([a-f0-9]{1,4}:){1}:([a-f0-9]{1,4}:){0,5}|([a-f0-9]{1,4}:){2}:([a-f0-9]{1,4}:){0,4}|([a-f0-9]{1,4}:){3}:([a-f0-9]{1,4}:){0,3}|([a-f0-9]{1,4}:){4}:([a-f0-9]{1,4}:){0,2}|([a-f0-9]{1,4}:){5}:([a-f0-9]{1,4}:){0,1})([a-f0-9]{1,4}|(((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\.){3}((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2})))$/,
  base64: /^([0-9a-zA-Z+/]{4})*(([0-9a-zA-Z+/]{2}==)|([0-9a-zA-Z+/]{3}=))?$/,
  nanoid: /^[a-zA-Z0-9_-]{21}$/
};
function parseStringDef(def, refs) {
  const res = {
    type: "string"
  };
  function processPattern(value) {
    return refs.patternStrategy === "escape" ? escapeNonAlphaNumeric(value) : value;
  }
  if (def.checks) {
    for (const check2 of def.checks) {
      switch (check2.kind) {
        case "min":
          setResponseValueAndErrors(res, "minLength", typeof res.minLength === "number" ? Math.max(res.minLength, check2.value) : check2.value, check2.message, refs);
          break;
        case "max":
          setResponseValueAndErrors(res, "maxLength", typeof res.maxLength === "number" ? Math.min(res.maxLength, check2.value) : check2.value, check2.message, refs);
          break;
        case "email":
          switch (refs.emailStrategy) {
            case "format:email":
              addFormat(res, "email", check2.message, refs);
              break;
            case "format:idn-email":
              addFormat(res, "idn-email", check2.message, refs);
              break;
            case "pattern:zod":
              addPattern(res, zodPatterns.email, check2.message, refs);
              break;
          }
          break;
        case "url":
          addFormat(res, "uri", check2.message, refs);
          break;
        case "uuid":
          addFormat(res, "uuid", check2.message, refs);
          break;
        case "regex":
          addPattern(res, check2.regex, check2.message, refs);
          break;
        case "cuid":
          addPattern(res, zodPatterns.cuid, check2.message, refs);
          break;
        case "cuid2":
          addPattern(res, zodPatterns.cuid2, check2.message, refs);
          break;
        case "startsWith":
          addPattern(res, RegExp(`^${processPattern(check2.value)}`), check2.message, refs);
          break;
        case "endsWith":
          addPattern(res, RegExp(`${processPattern(check2.value)}$`), check2.message, refs);
          break;
        case "datetime":
          addFormat(res, "date-time", check2.message, refs);
          break;
        case "date":
          addFormat(res, "date", check2.message, refs);
          break;
        case "time":
          addFormat(res, "time", check2.message, refs);
          break;
        case "duration":
          addFormat(res, "duration", check2.message, refs);
          break;
        case "length":
          setResponseValueAndErrors(res, "minLength", typeof res.minLength === "number" ? Math.max(res.minLength, check2.value) : check2.value, check2.message, refs);
          setResponseValueAndErrors(res, "maxLength", typeof res.maxLength === "number" ? Math.min(res.maxLength, check2.value) : check2.value, check2.message, refs);
          break;
        case "includes": {
          addPattern(res, RegExp(processPattern(check2.value)), check2.message, refs);
          break;
        }
        case "ip": {
          if (check2.version !== "v6") {
            addFormat(res, "ipv4", check2.message, refs);
          }
          if (check2.version !== "v4") {
            addFormat(res, "ipv6", check2.message, refs);
          }
          break;
        }
        case "emoji":
          addPattern(res, zodPatterns.emoji, check2.message, refs);
          break;
        case "ulid": {
          addPattern(res, zodPatterns.ulid, check2.message, refs);
          break;
        }
        case "base64": {
          switch (refs.base64Strategy) {
            case "format:binary": {
              addFormat(res, "binary", check2.message, refs);
              break;
            }
            case "contentEncoding:base64": {
              setResponseValueAndErrors(res, "contentEncoding", "base64", check2.message, refs);
              break;
            }
            case "pattern:zod": {
              addPattern(res, zodPatterns.base64, check2.message, refs);
              break;
            }
          }
          break;
        }
        case "nanoid": {
          addPattern(res, zodPatterns.nanoid, check2.message, refs);
        }
        case "toLowerCase":
        case "toUpperCase":
        case "trim":
          break;
        default:
          /* @__PURE__ */ ((_) => {
          })(check2);
      }
    }
  }
  return res;
}
var escapeNonAlphaNumeric = (value) => Array.from(value).map((c) => /[a-zA-Z0-9]/.test(c) ? c : `\\${c}`).join("");
var addFormat = (schema, value, message, refs) => {
  if (schema.format || schema.anyOf?.some((x) => x.format)) {
    if (!schema.anyOf) {
      schema.anyOf = [];
    }
    if (schema.format) {
      schema.anyOf.push({
        format: schema.format,
        ...schema.errorMessage && refs.errorMessages && {
          errorMessage: { format: schema.errorMessage.format }
        }
      });
      delete schema.format;
      if (schema.errorMessage) {
        delete schema.errorMessage.format;
        if (Object.keys(schema.errorMessage).length === 0) {
          delete schema.errorMessage;
        }
      }
    }
    schema.anyOf.push({
      format: value,
      ...message && refs.errorMessages && { errorMessage: { format: message } }
    });
  } else {
    setResponseValueAndErrors(schema, "format", value, message, refs);
  }
};
var addPattern = (schema, regex, message, refs) => {
  if (schema.pattern || schema.allOf?.some((x) => x.pattern)) {
    if (!schema.allOf) {
      schema.allOf = [];
    }
    if (schema.pattern) {
      schema.allOf.push({
        pattern: schema.pattern,
        ...schema.errorMessage && refs.errorMessages && {
          errorMessage: { pattern: schema.errorMessage.pattern }
        }
      });
      delete schema.pattern;
      if (schema.errorMessage) {
        delete schema.errorMessage.pattern;
        if (Object.keys(schema.errorMessage).length === 0) {
          delete schema.errorMessage;
        }
      }
    }
    schema.allOf.push({
      pattern: processRegExp(regex, refs),
      ...message && refs.errorMessages && { errorMessage: { pattern: message } }
    });
  } else {
    setResponseValueAndErrors(schema, "pattern", processRegExp(regex, refs), message, refs);
  }
};
var processRegExp = (regexOrFunction, refs) => {
  const regex = typeof regexOrFunction === "function" ? regexOrFunction() : regexOrFunction;
  if (!refs.applyRegexFlags || !regex.flags)
    return regex.source;
  const flags = {
    i: regex.flags.includes("i"),
    // Case-insensitive
    m: regex.flags.includes("m"),
    // `^` and `$` matches adjacent to newline characters
    s: regex.flags.includes("s")
    // `.` matches newlines
  };
  const source = flags.i ? regex.source.toLowerCase() : regex.source;
  let pattern = "";
  let isEscaped = false;
  let inCharGroup = false;
  let inCharRange = false;
  for (let i = 0; i < source.length; i++) {
    if (isEscaped) {
      pattern += source[i];
      isEscaped = false;
      continue;
    }
    if (flags.i) {
      if (inCharGroup) {
        if (source[i].match(/[a-z]/)) {
          if (inCharRange) {
            pattern += source[i];
            pattern += `${source[i - 2]}-${source[i]}`.toUpperCase();
            inCharRange = false;
          } else if (source[i + 1] === "-" && source[i + 2]?.match(/[a-z]/)) {
            pattern += source[i];
            inCharRange = true;
          } else {
            pattern += `${source[i]}${source[i].toUpperCase()}`;
          }
          continue;
        }
      } else if (source[i].match(/[a-z]/)) {
        pattern += `[${source[i]}${source[i].toUpperCase()}]`;
        continue;
      }
    }
    if (flags.m) {
      if (source[i] === "^") {
        pattern += `(^|(?<=[\r
]))`;
        continue;
      } else if (source[i] === "$") {
        pattern += `($|(?=[\r
]))`;
        continue;
      }
    }
    if (flags.s && source[i] === ".") {
      pattern += inCharGroup ? `${source[i]}\r
` : `[${source[i]}\r
]`;
      continue;
    }
    pattern += source[i];
    if (source[i] === "\\") {
      isEscaped = true;
    } else if (inCharGroup && source[i] === "]") {
      inCharGroup = false;
    } else if (!inCharGroup && source[i] === "[") {
      inCharGroup = true;
    }
  }
  try {
    const regexTest = new RegExp(pattern);
  } catch {
    console.warn(`Could not convert regex pattern at ${refs.currentPath.join("/")} to a flag-independent form! Falling back to the flag-ignorant source`);
    return regex.source;
  }
  return pattern;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/record.mjs
function parseRecordDef(def, refs) {
  if (refs.target === "openApi3" && def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodEnum) {
    return {
      type: "object",
      required: def.keyType._def.values,
      properties: def.keyType._def.values.reduce((acc, key) => ({
        ...acc,
        [key]: parseDef(def.valueType._def, {
          ...refs,
          currentPath: [...refs.currentPath, "properties", key]
        }) ?? {}
      }), {}),
      additionalProperties: false
    };
  }
  const schema = {
    type: "object",
    additionalProperties: parseDef(def.valueType._def, {
      ...refs,
      currentPath: [...refs.currentPath, "additionalProperties"]
    }) ?? {}
  };
  if (refs.target === "openApi3") {
    return schema;
  }
  if (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodString && def.keyType._def.checks?.length) {
    const keyType = Object.entries(parseStringDef(def.keyType._def, refs)).reduce((acc, [key, value]) => key === "type" ? acc : { ...acc, [key]: value }, {});
    return {
      ...schema,
      propertyNames: keyType
    };
  } else if (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodEnum) {
    return {
      ...schema,
      propertyNames: {
        enum: def.keyType._def.values
      }
    };
  }
  return schema;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/map.mjs
function parseMapDef(def, refs) {
  if (refs.mapStrategy === "record") {
    return parseRecordDef(def, refs);
  }
  const keys = parseDef(def.keyType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items", "items", "0"]
  }) || {};
  const values = parseDef(def.valueType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items", "items", "1"]
  }) || {};
  return {
    type: "array",
    maxItems: 125,
    items: {
      type: "array",
      items: [keys, values],
      minItems: 2,
      maxItems: 2
    }
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/nativeEnum.mjs
function parseNativeEnumDef(def) {
  const object2 = def.values;
  const actualKeys = Object.keys(def.values).filter((key) => {
    return typeof object2[object2[key]] !== "number";
  });
  const actualValues = actualKeys.map((key) => object2[key]);
  const parsedTypes = Array.from(new Set(actualValues.map((values) => typeof values)));
  return {
    type: parsedTypes.length === 1 ? parsedTypes[0] === "string" ? "string" : "number" : ["string", "number"],
    enum: actualValues
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/never.mjs
function parseNeverDef() {
  return {
    not: {}
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/null.mjs
function parseNullDef(refs) {
  return refs.target === "openApi3" ? {
    enum: ["null"],
    nullable: true
  } : {
    type: "null"
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/union.mjs
var primitiveMappings = {
  ZodString: "string",
  ZodNumber: "number",
  ZodBigInt: "integer",
  ZodBoolean: "boolean",
  ZodNull: "null"
};
function parseUnionDef(def, refs) {
  if (refs.target === "openApi3")
    return asAnyOf(def, refs);
  const options = def.options instanceof Map ? Array.from(def.options.values()) : def.options;
  if (options.every((x) => x._def.typeName in primitiveMappings && (!x._def.checks || !x._def.checks.length))) {
    const types = options.reduce((types2, x) => {
      const type = primitiveMappings[x._def.typeName];
      return type && !types2.includes(type) ? [...types2, type] : types2;
    }, []);
    return {
      type: types.length > 1 ? types : types[0]
    };
  } else if (options.every((x) => x._def.typeName === "ZodLiteral" && !x.description)) {
    const types = options.reduce((acc, x) => {
      const type = typeof x._def.value;
      switch (type) {
        case "string":
        case "number":
        case "boolean":
          return [...acc, type];
        case "bigint":
          return [...acc, "integer"];
        case "object":
          if (x._def.value === null)
            return [...acc, "null"];
        case "symbol":
        case "undefined":
        case "function":
        default:
          return acc;
      }
    }, []);
    if (types.length === options.length) {
      const uniqueTypes = types.filter((x, i, a) => a.indexOf(x) === i);
      return {
        type: uniqueTypes.length > 1 ? uniqueTypes : uniqueTypes[0],
        enum: options.reduce((acc, x) => {
          return acc.includes(x._def.value) ? acc : [...acc, x._def.value];
        }, [])
      };
    }
  } else if (options.every((x) => x._def.typeName === "ZodEnum")) {
    return {
      type: "string",
      enum: options.reduce((acc, x) => [...acc, ...x._def.values.filter((x2) => !acc.includes(x2))], [])
    };
  }
  return asAnyOf(def, refs);
}
var asAnyOf = (def, refs) => {
  const anyOf = (def.options instanceof Map ? Array.from(def.options.values()) : def.options).map((x, i) => parseDef(x._def, {
    ...refs,
    currentPath: [...refs.currentPath, "anyOf", `${i}`]
  })).filter((x) => !!x && (!refs.strictUnions || typeof x === "object" && Object.keys(x).length > 0));
  return anyOf.length ? { anyOf } : void 0;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/nullable.mjs
function parseNullableDef(def, refs) {
  if (["ZodString", "ZodNumber", "ZodBigInt", "ZodBoolean", "ZodNull"].includes(def.innerType._def.typeName) && (!def.innerType._def.checks || !def.innerType._def.checks.length)) {
    if (refs.target === "openApi3" || refs.nullableStrategy === "property") {
      return {
        type: primitiveMappings[def.innerType._def.typeName],
        nullable: true
      };
    }
    return {
      type: [primitiveMappings[def.innerType._def.typeName], "null"]
    };
  }
  if (refs.target === "openApi3") {
    const base2 = parseDef(def.innerType._def, {
      ...refs,
      currentPath: [...refs.currentPath]
    });
    if (base2 && "$ref" in base2)
      return { allOf: [base2], nullable: true };
    return base2 && { ...base2, nullable: true };
  }
  const base = parseDef(def.innerType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "anyOf", "0"]
  });
  return base && { anyOf: [base, { type: "null" }] };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/number.mjs
function parseNumberDef(def, refs) {
  const res = {
    type: "number"
  };
  if (!def.checks)
    return res;
  for (const check2 of def.checks) {
    switch (check2.kind) {
      case "int":
        res.type = "integer";
        addErrorMessage(res, "type", check2.message, refs);
        break;
      case "min":
        if (refs.target === "jsonSchema7") {
          if (check2.inclusive) {
            setResponseValueAndErrors(res, "minimum", check2.value, check2.message, refs);
          } else {
            setResponseValueAndErrors(res, "exclusiveMinimum", check2.value, check2.message, refs);
          }
        } else {
          if (!check2.inclusive) {
            res.exclusiveMinimum = true;
          }
          setResponseValueAndErrors(res, "minimum", check2.value, check2.message, refs);
        }
        break;
      case "max":
        if (refs.target === "jsonSchema7") {
          if (check2.inclusive) {
            setResponseValueAndErrors(res, "maximum", check2.value, check2.message, refs);
          } else {
            setResponseValueAndErrors(res, "exclusiveMaximum", check2.value, check2.message, refs);
          }
        } else {
          if (!check2.inclusive) {
            res.exclusiveMaximum = true;
          }
          setResponseValueAndErrors(res, "maximum", check2.value, check2.message, refs);
        }
        break;
      case "multipleOf":
        setResponseValueAndErrors(res, "multipleOf", check2.value, check2.message, refs);
        break;
    }
  }
  return res;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/object.mjs
function decideAdditionalProperties(def, refs) {
  if (refs.removeAdditionalStrategy === "strict") {
    return def.catchall._def.typeName === "ZodNever" ? def.unknownKeys !== "strict" : parseDef(def.catchall._def, {
      ...refs,
      currentPath: [...refs.currentPath, "additionalProperties"]
    }) ?? true;
  } else {
    return def.catchall._def.typeName === "ZodNever" ? def.unknownKeys === "passthrough" : parseDef(def.catchall._def, {
      ...refs,
      currentPath: [...refs.currentPath, "additionalProperties"]
    }) ?? true;
  }
}
function parseObjectDef(def, refs) {
  const result = {
    type: "object",
    ...Object.entries(def.shape()).reduce((acc, [propName, propDef]) => {
      if (propDef === void 0 || propDef._def === void 0)
        return acc;
      const propertyPath = [...refs.currentPath, "properties", propName];
      const parsedDef = parseDef(propDef._def, {
        ...refs,
        currentPath: propertyPath,
        propertyPath
      });
      if (parsedDef === void 0)
        return acc;
      if (refs.openaiStrictMode && propDef.isOptional() && !propDef.isNullable() && typeof propDef._def?.defaultValue === "undefined") {
        throw new Error(`Zod field at \`${propertyPath.join("/")}\` uses \`.optional()\` without \`.nullable()\` which is not supported by the API. See: https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#all-fields-must-be-required`);
      }
      return {
        properties: {
          ...acc.properties,
          [propName]: parsedDef
        },
        required: propDef.isOptional() && !refs.openaiStrictMode ? acc.required : [...acc.required, propName]
      };
    }, { properties: {}, required: [] }),
    additionalProperties: decideAdditionalProperties(def, refs)
  };
  if (!result.required.length)
    delete result.required;
  return result;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/optional.mjs
var parseOptionalDef = (def, refs) => {
  if (refs.propertyPath && refs.currentPath.slice(0, refs.propertyPath.length).toString() === refs.propertyPath.toString()) {
    return parseDef(def.innerType._def, { ...refs, currentPath: refs.currentPath });
  }
  const innerSchema = parseDef(def.innerType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "anyOf", "1"]
  });
  return innerSchema ? {
    anyOf: [
      {
        not: {}
      },
      innerSchema
    ]
  } : {};
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/pipeline.mjs
var parsePipelineDef = (def, refs) => {
  if (refs.pipeStrategy === "input") {
    return parseDef(def.in._def, refs);
  } else if (refs.pipeStrategy === "output") {
    return parseDef(def.out._def, refs);
  }
  const a = parseDef(def.in._def, {
    ...refs,
    currentPath: [...refs.currentPath, "allOf", "0"]
  });
  const b = parseDef(def.out._def, {
    ...refs,
    currentPath: [...refs.currentPath, "allOf", a ? "1" : "0"]
  });
  return {
    allOf: [a, b].filter((x) => x !== void 0)
  };
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/promise.mjs
function parsePromiseDef(def, refs) {
  return parseDef(def.type._def, refs);
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/set.mjs
function parseSetDef(def, refs) {
  const items = parseDef(def.valueType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items"]
  });
  const schema = {
    type: "array",
    uniqueItems: true,
    items
  };
  if (def.minSize) {
    setResponseValueAndErrors(schema, "minItems", def.minSize.value, def.minSize.message, refs);
  }
  if (def.maxSize) {
    setResponseValueAndErrors(schema, "maxItems", def.maxSize.value, def.maxSize.message, refs);
  }
  return schema;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/tuple.mjs
function parseTupleDef(def, refs) {
  if (def.rest) {
    return {
      type: "array",
      minItems: def.items.length,
      items: def.items.map((x, i) => parseDef(x._def, {
        ...refs,
        currentPath: [...refs.currentPath, "items", `${i}`]
      })).reduce((acc, x) => x === void 0 ? acc : [...acc, x], []),
      additionalItems: parseDef(def.rest._def, {
        ...refs,
        currentPath: [...refs.currentPath, "additionalItems"]
      })
    };
  } else {
    return {
      type: "array",
      minItems: def.items.length,
      maxItems: def.items.length,
      items: def.items.map((x, i) => parseDef(x._def, {
        ...refs,
        currentPath: [...refs.currentPath, "items", `${i}`]
      })).reduce((acc, x) => x === void 0 ? acc : [...acc, x], [])
    };
  }
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/undefined.mjs
function parseUndefinedDef() {
  return {
    not: {}
  };
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/unknown.mjs
function parseUnknownDef() {
  return {};
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parsers/readonly.mjs
var parseReadonlyDef = (def, refs) => {
  return parseDef(def.innerType._def, refs);
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/parseDef.mjs
function parseDef(def, refs, forceResolution = false) {
  const seenItem = refs.seen.get(def);
  if (refs.override) {
    const overrideResult = refs.override?.(def, refs, seenItem, forceResolution);
    if (overrideResult !== ignoreOverride) {
      return overrideResult;
    }
  }
  if (seenItem && !forceResolution) {
    const seenSchema = get$ref(seenItem, refs);
    if (seenSchema !== void 0) {
      if ("$ref" in seenSchema) {
        refs.seenRefs.add(seenSchema.$ref);
      }
      return seenSchema;
    }
  }
  const newItem = { def, path: refs.currentPath, jsonSchema: void 0 };
  refs.seen.set(def, newItem);
  const jsonSchema = selectParser(def, def.typeName, refs, forceResolution);
  if (jsonSchema) {
    addMeta(def, refs, jsonSchema);
  }
  newItem.jsonSchema = jsonSchema;
  return jsonSchema;
}
var get$ref = (item, refs) => {
  switch (refs.$refStrategy) {
    case "root":
      return { $ref: item.path.join("/") };
    // this case is needed as OpenAI strict mode doesn't support top-level `$ref`s, i.e.
    // the top-level schema *must* be `{"type": "object", "properties": {...}}` but if we ever
    // need to define a `$ref`, relative `$ref`s aren't supported, so we need to extract
    // the schema to `#/definitions/` and reference that.
    //
    // e.g. if we need to reference a schema at
    // `["#","definitions","contactPerson","properties","person1","properties","name"]`
    // then we'll extract it out to `contactPerson_properties_person1_properties_name`
    case "extract-to-root":
      const name = item.path.slice(refs.basePath.length + 1).join("_");
      if (name !== refs.name && refs.nameStrategy === "duplicate-ref") {
        refs.definitions[name] = item.def;
      }
      return { $ref: [...refs.basePath, refs.definitionPath, name].join("/") };
    case "relative":
      return { $ref: getRelativePath(refs.currentPath, item.path) };
    case "none":
    case "seen": {
      if (item.path.length < refs.currentPath.length && item.path.every((value, index) => refs.currentPath[index] === value)) {
        console.warn(`Recursive reference detected at ${refs.currentPath.join("/")}! Defaulting to any`);
        return {};
      }
      return refs.$refStrategy === "seen" ? {} : void 0;
    }
  }
};
var getRelativePath = (pathA, pathB) => {
  let i = 0;
  for (; i < pathA.length && i < pathB.length; i++) {
    if (pathA[i] !== pathB[i])
      break;
  }
  return [(pathA.length - i).toString(), ...pathB.slice(i)].join("/");
};
var selectParser = (def, typeName, refs, forceResolution) => {
  switch (typeName) {
    case ZodFirstPartyTypeKind.ZodString:
      return parseStringDef(def, refs);
    case ZodFirstPartyTypeKind.ZodNumber:
      return parseNumberDef(def, refs);
    case ZodFirstPartyTypeKind.ZodObject:
      return parseObjectDef(def, refs);
    case ZodFirstPartyTypeKind.ZodBigInt:
      return parseBigintDef(def, refs);
    case ZodFirstPartyTypeKind.ZodBoolean:
      return parseBooleanDef();
    case ZodFirstPartyTypeKind.ZodDate:
      return parseDateDef(def, refs);
    case ZodFirstPartyTypeKind.ZodUndefined:
      return parseUndefinedDef();
    case ZodFirstPartyTypeKind.ZodNull:
      return parseNullDef(refs);
    case ZodFirstPartyTypeKind.ZodArray:
      return parseArrayDef(def, refs);
    case ZodFirstPartyTypeKind.ZodUnion:
    case ZodFirstPartyTypeKind.ZodDiscriminatedUnion:
      return parseUnionDef(def, refs);
    case ZodFirstPartyTypeKind.ZodIntersection:
      return parseIntersectionDef(def, refs);
    case ZodFirstPartyTypeKind.ZodTuple:
      return parseTupleDef(def, refs);
    case ZodFirstPartyTypeKind.ZodRecord:
      return parseRecordDef(def, refs);
    case ZodFirstPartyTypeKind.ZodLiteral:
      return parseLiteralDef(def, refs);
    case ZodFirstPartyTypeKind.ZodEnum:
      return parseEnumDef(def);
    case ZodFirstPartyTypeKind.ZodNativeEnum:
      return parseNativeEnumDef(def);
    case ZodFirstPartyTypeKind.ZodNullable:
      return parseNullableDef(def, refs);
    case ZodFirstPartyTypeKind.ZodOptional:
      return parseOptionalDef(def, refs);
    case ZodFirstPartyTypeKind.ZodMap:
      return parseMapDef(def, refs);
    case ZodFirstPartyTypeKind.ZodSet:
      return parseSetDef(def, refs);
    case ZodFirstPartyTypeKind.ZodLazy:
      return parseDef(def.getter()._def, refs);
    case ZodFirstPartyTypeKind.ZodPromise:
      return parsePromiseDef(def, refs);
    case ZodFirstPartyTypeKind.ZodNaN:
    case ZodFirstPartyTypeKind.ZodNever:
      return parseNeverDef();
    case ZodFirstPartyTypeKind.ZodEffects:
      return parseEffectsDef(def, refs, forceResolution);
    case ZodFirstPartyTypeKind.ZodAny:
      return parseAnyDef();
    case ZodFirstPartyTypeKind.ZodUnknown:
      return parseUnknownDef();
    case ZodFirstPartyTypeKind.ZodDefault:
      return parseDefaultDef(def, refs);
    case ZodFirstPartyTypeKind.ZodBranded:
      return parseBrandedDef(def, refs);
    case ZodFirstPartyTypeKind.ZodReadonly:
      return parseReadonlyDef(def, refs);
    case ZodFirstPartyTypeKind.ZodCatch:
      return parseCatchDef(def, refs);
    case ZodFirstPartyTypeKind.ZodPipeline:
      return parsePipelineDef(def, refs);
    case ZodFirstPartyTypeKind.ZodFunction:
    case ZodFirstPartyTypeKind.ZodVoid:
    case ZodFirstPartyTypeKind.ZodSymbol:
      return void 0;
    default:
      return /* @__PURE__ */ ((_) => void 0)(typeName);
  }
};
var addMeta = (def, refs, jsonSchema) => {
  if (def.description) {
    jsonSchema.description = def.description;
    if (refs.markdownDescription) {
      jsonSchema.markdownDescription = def.description;
    }
  }
  return jsonSchema;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/_vendor/zod-to-json-schema/zodToJsonSchema.mjs
var zodToJsonSchema = (schema, options) => {
  const refs = getRefs(options);
  const name = typeof options === "string" ? options : options?.nameStrategy === "title" ? void 0 : options?.name;
  const main = parseDef(schema._def, name === void 0 ? refs : {
    ...refs,
    currentPath: [...refs.basePath, refs.definitionPath, name]
  }, false) ?? {};
  const title = typeof options === "object" && options.name !== void 0 && options.nameStrategy === "title" ? options.name : void 0;
  if (title !== void 0) {
    main.title = title;
  }
  const definitions = (() => {
    if (isEmptyObj2(refs.definitions)) {
      return void 0;
    }
    const definitions2 = {};
    const processedDefinitions = /* @__PURE__ */ new Set();
    for (let i = 0; i < 500; i++) {
      const newDefinitions = Object.entries(refs.definitions).filter(([key]) => !processedDefinitions.has(key));
      if (newDefinitions.length === 0)
        break;
      for (const [key, schema2] of newDefinitions) {
        definitions2[key] = parseDef(zodDef(schema2), { ...refs, currentPath: [...refs.basePath, refs.definitionPath, key] }, true) ?? {};
        processedDefinitions.add(key);
      }
    }
    return definitions2;
  })();
  const combined = name === void 0 ? definitions ? {
    ...main,
    [refs.definitionPath]: definitions
  } : main : refs.nameStrategy === "duplicate-ref" ? {
    ...main,
    ...definitions || refs.seenRefs.size ? {
      [refs.definitionPath]: {
        ...definitions,
        // only actually duplicate the schema definition if it was ever referenced
        // otherwise the duplication is completely pointless
        ...refs.seenRefs.size ? { [name]: main } : void 0
      }
    } : void 0
  } : {
    $ref: [...refs.$refStrategy === "relative" ? [] : refs.basePath, refs.definitionPath, name].join("/"),
    [refs.definitionPath]: {
      ...definitions,
      [name]: main
    }
  };
  if (refs.target === "jsonSchema7") {
    combined.$schema = "http://json-schema.org/draft-07/schema#";
  } else if (refs.target === "jsonSchema2019-09") {
    combined.$schema = "https://json-schema.org/draft/2019-09/schema#";
  }
  return combined;
};

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/lib/transform.mjs
function toStrictJsonSchema(schema) {
  if (schema.type !== "object") {
    throw new Error(`Root schema must have type: 'object' but got type: ${schema.type ? `'${schema.type}'` : "undefined"}`);
  }
  const schemaCopy = structuredClone(schema);
  return ensureStrictJsonSchema(schemaCopy, [], schemaCopy);
}
function isNullable(schema) {
  if (typeof schema === "boolean") {
    return false;
  }
  if (schema.type === "null") {
    return true;
  }
  for (const oneOfVariant of schema.oneOf ?? []) {
    if (isNullable(oneOfVariant)) {
      return true;
    }
  }
  for (const allOfVariant of schema.anyOf ?? []) {
    if (isNullable(allOfVariant)) {
      return true;
    }
  }
  return false;
}
function ensureStrictJsonSchema(jsonSchema, path2, root) {
  if (typeof jsonSchema === "boolean") {
    throw new TypeError(`Expected object schema but got boolean; path=${path2.join("/")}`);
  }
  if (!isObject(jsonSchema)) {
    throw new TypeError(`Expected ${JSON.stringify(jsonSchema)} to be an object; path=${path2.join("/")}`);
  }
  const defs = jsonSchema.$defs;
  if (isObject(defs)) {
    for (const [defName, defSchema] of Object.entries(defs)) {
      ensureStrictJsonSchema(defSchema, [...path2, "$defs", defName], root);
    }
  }
  const definitions = jsonSchema.definitions;
  if (isObject(definitions)) {
    for (const [definitionName, definitionSchema] of Object.entries(definitions)) {
      ensureStrictJsonSchema(definitionSchema, [...path2, "definitions", definitionName], root);
    }
  }
  const typ = jsonSchema.type;
  if (typ === "object" && !("additionalProperties" in jsonSchema)) {
    jsonSchema.additionalProperties = false;
  }
  const required = jsonSchema.required ?? [];
  const properties = jsonSchema.properties;
  if (isObject(properties)) {
    for (const [key, value] of Object.entries(properties)) {
      if (!isNullable(value) && !required.includes(key)) {
        throw new Error(`Zod field at \`${[...path2, "properties", key].join("/")}\` uses \`.optional()\` without \`.nullable()\` which is not supported by the API. See: https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses#all-fields-must-be-required`);
      }
    }
    jsonSchema.required = Object.keys(properties);
    jsonSchema.properties = Object.fromEntries(Object.entries(properties).map(([key, propSchema]) => [
      key,
      ensureStrictJsonSchema(propSchema, [...path2, "properties", key], root)
    ]));
  }
  const items = jsonSchema.items;
  if (isObject(items)) {
    jsonSchema.items = ensureStrictJsonSchema(items, [...path2, "items"], root);
  }
  const anyOf = jsonSchema.anyOf;
  if (Array.isArray(anyOf)) {
    jsonSchema.anyOf = anyOf.map((variant, i) => ensureStrictJsonSchema(variant, [...path2, "anyOf", String(i)], root));
  }
  const allOf = jsonSchema.allOf;
  if (Array.isArray(allOf)) {
    if (allOf.length === 1) {
      const resolved = ensureStrictJsonSchema(allOf[0], [...path2, "allOf", "0"], root);
      Object.assign(jsonSchema, resolved);
      delete jsonSchema.allOf;
    } else {
      jsonSchema.allOf = allOf.map((entry, i) => ensureStrictJsonSchema(entry, [...path2, "allOf", String(i)], root));
    }
  }
  if (jsonSchema.default === null) {
    delete jsonSchema.default;
  }
  const ref = jsonSchema.$ref;
  if (ref && hasMoreThanNKeys(jsonSchema, 1)) {
    if (typeof ref !== "string") {
      throw new TypeError(`Received non-string $ref - ${ref}; path=${path2.join("/")}`);
    }
    const resolved = resolveRef2(root, ref);
    if (typeof resolved === "boolean") {
      throw new Error(`Expected \`$ref: ${ref}\` to resolve to an object schema but got boolean`);
    }
    if (!isObject(resolved)) {
      throw new Error(`Expected \`$ref: ${ref}\` to resolve to an object but got ${JSON.stringify(resolved)}`);
    }
    Object.assign(jsonSchema, { ...resolved, ...jsonSchema });
    delete jsonSchema.$ref;
    return ensureStrictJsonSchema(jsonSchema, path2, root);
  }
  return jsonSchema;
}
function resolveRef2(root, ref) {
  if (!ref.startsWith("#/")) {
    throw new Error(`Unexpected $ref format ${JSON.stringify(ref)}; Does not start with #/`);
  }
  const pathParts = ref.slice(2).split("/");
  let resolved = root;
  for (const key of pathParts) {
    if (!isObject(resolved)) {
      throw new Error(`encountered non-object entry while resolving ${ref} - ${JSON.stringify(resolved)}`);
    }
    const value = resolved[key];
    if (value === void 0) {
      throw new Error(`Key ${key} not found while resolving ${ref}`);
    }
    resolved = value;
  }
  return resolved;
}
function isObject(obj) {
  return typeof obj === "object" && obj !== null && !Array.isArray(obj);
}
function hasMoreThanNKeys(obj, n) {
  let i = 0;
  for (const _ in obj) {
    i++;
    if (i > n) {
      return true;
    }
  }
  return false;
}

// node_modules/.pnpm/openai@6.25.0_ws@8.19.0_zod@4.3.6/node_modules/openai/helpers/zod.mjs
function zodV3ToJsonSchema(schema, options) {
  return zodToJsonSchema(schema, {
    openaiStrictMode: true,
    name: options.name,
    nameStrategy: "duplicate-ref",
    $refStrategy: "extract-to-root",
    nullableStrategy: "property"
  });
}
function zodV4ToJsonSchema(schema) {
  return toStrictJsonSchema(toJSONSchema(schema, {
    target: "draft-7"
  }));
}
function isZodV4(zodObject) {
  return "_zod" in zodObject;
}
function zodResponseFormat(zodObject, name, props) {
  return makeParseableResponseFormat({
    type: "json_schema",
    json_schema: {
      ...props,
      name,
      strict: true,
      schema: isZodV4(zodObject) ? zodV4ToJsonSchema(zodObject) : zodV3ToJsonSchema(zodObject, { name })
    }
  }, (content) => zodObject.parse(JSON.parse(content)));
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/utils/output.js
var SUPPORTED_METHODS = [
  "jsonSchema",
  "functionCalling",
  "jsonMode"
];
function getStructuredOutputMethod(model, method) {
  if (typeof method !== "undefined" && !SUPPORTED_METHODS.includes(method)) throw new Error(`Invalid method: ${method}. Supported methods are: ${SUPPORTED_METHODS.join(", ")}`);
  const hasSupportForJsonSchema = !model.startsWith("gpt-3") && !model.startsWith("gpt-4-") && model !== "gpt-4";
  if (hasSupportForJsonSchema && !method) return "jsonSchema";
  if (!hasSupportForJsonSchema && method === "jsonSchema") throw new Error(`JSON Schema is not supported for model "${model}". Please use a different method, e.g. "functionCalling" or "jsonMode".`);
  return method ?? "functionCalling";
}
function makeParseableResponseFormat2(response_format, parser) {
  const obj = { ...response_format };
  Object.defineProperties(obj, {
    $brand: {
      value: "auto-parseable-response-format",
      enumerable: false
    },
    $parseRaw: {
      value: parser,
      enumerable: false
    }
  });
  return obj;
}
function interopZodResponseFormat(zodSchema, name, props) {
  if (isZodSchemaV3(zodSchema)) return zodResponseFormat(zodSchema, name, props);
  if (isZodSchemaV4(zodSchema)) return makeParseableResponseFormat2({
    type: "json_schema",
    json_schema: {
      ...props,
      name,
      strict: true,
      schema: toJsonSchema(zodSchema, {
        cycles: "ref",
        reused: "ref",
        override(ctx) {
          ctx.jsonSchema.title = name;
        }
      })
    }
  }, (content) => parse(zodSchema, JSON.parse(content)));
  throw new Error("Unsupported schema response format");
}
function handleMultiModalOutput(content, messages) {
  if (messages && typeof messages === "object" && "images" in messages && Array.isArray(messages.images)) {
    const images = messages.images.filter((image) => typeof image?.image_url?.url === "string").map((image) => ({
      type: "image",
      url: image.image_url.url
    }));
    return [{
      type: "text",
      text: content
    }, ...images];
  }
  return content;
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/chat_models/profiles.js
var PROFILES = {
  "gpt-4o-2024-11-20": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.3-codex": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5-codex": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5-pro": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 272e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4o-mini": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "text-embedding-ada-002": {
    maxInputTokens: 8192,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1536,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5-chat-latest": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "codex-mini-latest": {
    maxInputTokens: 2e5,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.1-codex-max": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4o-2024-05-13": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 4096,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.2-chat-latest": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.2-codex": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "o3-deep-research": {
    maxInputTokens: 2e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  o1: {
    maxInputTokens: 2e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.1": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "o4-mini-deep-research": {
    maxInputTokens: 2e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.3-codex-spark": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 32e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  o3: {
    maxInputTokens: 2e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "text-embedding-3-small": {
    maxInputTokens: 8191,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1536,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4.1-nano": {
    maxInputTokens: 1047576,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 32768,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "text-embedding-3-large": {
    maxInputTokens: 8191,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 3072,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-3.5-turbo": {
    maxInputTokens: 16385,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: false,
    videoInputs: false,
    maxOutputTokens: 4096,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: false,
    imageUrlInputs: false,
    pdfToolMessage: false,
    imageToolMessage: false,
    toolChoice: true
  },
  "gpt-5.1-codex-mini": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.2": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4.1": {
    maxInputTokens: 1047576,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 32768,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "o3-pro": {
    maxInputTokens: 2e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4-turbo": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 4096,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "o4-mini": {
    maxInputTokens: 2e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4.1-mini": {
    maxInputTokens: 1047576,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 32768,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "o1-preview": {
    maxInputTokens: 128e3,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 32768,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "o1-pro": {
    maxInputTokens: 2e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.1-codex": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.2-pro": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "o3-mini": {
    maxInputTokens: 2e5,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 1e5,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4o-2024-08-06": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5-mini": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5.1-chat-latest": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4": {
    maxInputTokens: 8192,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 8192,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-5-nano": {
    maxInputTokens: 4e5,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 128e3,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "o1-mini": {
    maxInputTokens: 128e3,
    imageInputs: false,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 65536,
    reasoningOutput: true,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: false,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  },
  "gpt-4o": {
    maxInputTokens: 128e3,
    imageInputs: true,
    audioInputs: false,
    pdfInputs: true,
    videoInputs: false,
    maxOutputTokens: 16384,
    reasoningOutput: false,
    imageOutputs: false,
    audioOutputs: false,
    videoOutputs: false,
    toolCalling: true,
    structuredOutput: true,
    imageUrlInputs: true,
    pdfToolMessage: true,
    imageToolMessage: true,
    toolChoice: true
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/utils/js-sha256/hash.js
var HEX_CHARS = "0123456789abcdef".split("");
var EXTRA = [
  -2147483648,
  8388608,
  32768,
  128
];
var SHIFT = [
  24,
  16,
  8,
  0
];
var K = [
  1116352408,
  1899447441,
  3049323471,
  3921009573,
  961987163,
  1508970993,
  2453635748,
  2870763221,
  3624381080,
  310598401,
  607225278,
  1426881987,
  1925078388,
  2162078206,
  2614888103,
  3248222580,
  3835390401,
  4022224774,
  264347078,
  604807628,
  770255983,
  1249150122,
  1555081692,
  1996064986,
  2554220882,
  2821834349,
  2952996808,
  3210313671,
  3336571891,
  3584528711,
  113926993,
  338241895,
  666307205,
  773529912,
  1294757372,
  1396182291,
  1695183700,
  1986661051,
  2177026350,
  2456956037,
  2730485921,
  2820302411,
  3259730800,
  3345764771,
  3516065817,
  3600352804,
  4094571909,
  275423344,
  430227734,
  506948616,
  659060556,
  883997877,
  958139571,
  1322822218,
  1537002063,
  1747873779,
  1955562222,
  2024104815,
  2227730452,
  2361852424,
  2428436474,
  2756734187,
  3204031479,
  3329325298
];
var blocks = [];
function Sha256(is224, sharedMemory) {
  if (sharedMemory) {
    blocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
    this.blocks = blocks;
  } else this.blocks = [
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0
  ];
  if (is224) {
    this.h0 = 3238371032;
    this.h1 = 914150663;
    this.h2 = 812702999;
    this.h3 = 4144912697;
    this.h4 = 4290775857;
    this.h5 = 1750603025;
    this.h6 = 1694076839;
    this.h7 = 3204075428;
  } else {
    this.h0 = 1779033703;
    this.h1 = 3144134277;
    this.h2 = 1013904242;
    this.h3 = 2773480762;
    this.h4 = 1359893119;
    this.h5 = 2600822924;
    this.h6 = 528734635;
    this.h7 = 1541459225;
  }
  this.block = this.start = this.bytes = this.hBytes = 0;
  this.finalized = this.hashed = false;
  this.first = true;
  this.is224 = is224;
}
Sha256.prototype.update = function(message) {
  if (this.finalized) return;
  var notString, type = typeof message;
  if (type !== "string") {
    if (type === "object") {
      if (message === null) throw new Error(ERROR);
      else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) message = new Uint8Array(message);
      else if (!Array.isArray(message)) {
        if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) throw new Error(ERROR);
      }
    } else throw new Error(ERROR);
    notString = true;
  }
  var code, index = 0, i, length = message.length, blocks2 = this.blocks;
  while (index < length) {
    if (this.hashed) {
      this.hashed = false;
      blocks2[0] = this.block;
      this.block = blocks2[16] = blocks2[1] = blocks2[2] = blocks2[3] = blocks2[4] = blocks2[5] = blocks2[6] = blocks2[7] = blocks2[8] = blocks2[9] = blocks2[10] = blocks2[11] = blocks2[12] = blocks2[13] = blocks2[14] = blocks2[15] = 0;
    }
    if (notString) for (i = this.start; index < length && i < 64; ++index) blocks2[i >>> 2] |= message[index] << SHIFT[i++ & 3];
    else for (i = this.start; index < length && i < 64; ++index) {
      code = message.charCodeAt(index);
      if (code < 128) blocks2[i >>> 2] |= code << SHIFT[i++ & 3];
      else if (code < 2048) {
        blocks2[i >>> 2] |= (192 | code >>> 6) << SHIFT[i++ & 3];
        blocks2[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      } else if (code < 55296 || code >= 57344) {
        blocks2[i >>> 2] |= (224 | code >>> 12) << SHIFT[i++ & 3];
        blocks2[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT[i++ & 3];
        blocks2[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      } else {
        code = 65536 + ((code & 1023) << 10 | message.charCodeAt(++index) & 1023);
        blocks2[i >>> 2] |= (240 | code >>> 18) << SHIFT[i++ & 3];
        blocks2[i >>> 2] |= (128 | code >>> 12 & 63) << SHIFT[i++ & 3];
        blocks2[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT[i++ & 3];
        blocks2[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      }
    }
    this.lastByteIndex = i;
    this.bytes += i - this.start;
    if (i >= 64) {
      this.block = blocks2[16];
      this.start = i - 64;
      this.hash();
      this.hashed = true;
    } else this.start = i;
  }
  if (this.bytes > 4294967295) {
    this.hBytes += this.bytes / 4294967296 << 0;
    this.bytes = this.bytes % 4294967296;
  }
  return this;
};
Sha256.prototype.finalize = function() {
  if (this.finalized) return;
  this.finalized = true;
  var blocks2 = this.blocks, i = this.lastByteIndex;
  blocks2[16] = this.block;
  blocks2[i >>> 2] |= EXTRA[i & 3];
  this.block = blocks2[16];
  if (i >= 56) {
    if (!this.hashed) this.hash();
    blocks2[0] = this.block;
    blocks2[16] = blocks2[1] = blocks2[2] = blocks2[3] = blocks2[4] = blocks2[5] = blocks2[6] = blocks2[7] = blocks2[8] = blocks2[9] = blocks2[10] = blocks2[11] = blocks2[12] = blocks2[13] = blocks2[14] = blocks2[15] = 0;
  }
  blocks2[14] = this.hBytes << 3 | this.bytes >>> 29;
  blocks2[15] = this.bytes << 3;
  this.hash();
};
Sha256.prototype.hash = function() {
  var a = this.h0, b = this.h1, c = this.h2, d = this.h3, e = this.h4, f = this.h5, g = this.h6, h = this.h7, blocks2 = this.blocks, j, s0, s1, maj, t1, t2, ch, ab, da, cd, bc;
  for (j = 16; j < 64; ++j) {
    t1 = blocks2[j - 15];
    s0 = (t1 >>> 7 | t1 << 25) ^ (t1 >>> 18 | t1 << 14) ^ t1 >>> 3;
    t1 = blocks2[j - 2];
    s1 = (t1 >>> 17 | t1 << 15) ^ (t1 >>> 19 | t1 << 13) ^ t1 >>> 10;
    blocks2[j] = blocks2[j - 16] + s0 + blocks2[j - 7] + s1 << 0;
  }
  bc = b & c;
  for (j = 0; j < 64; j += 4) {
    if (this.first) {
      if (this.is224) {
        ab = 300032;
        t1 = blocks2[0] - 1413257819;
        h = t1 - 150054599 << 0;
        d = t1 + 24177077 << 0;
      } else {
        ab = 704751109;
        t1 = blocks2[0] - 210244248;
        h = t1 - 1521486534 << 0;
        d = t1 + 143694565 << 0;
      }
      this.first = false;
    } else {
      s0 = (a >>> 2 | a << 30) ^ (a >>> 13 | a << 19) ^ (a >>> 22 | a << 10);
      s1 = (e >>> 6 | e << 26) ^ (e >>> 11 | e << 21) ^ (e >>> 25 | e << 7);
      ab = a & b;
      maj = ab ^ a & c ^ bc;
      ch = e & f ^ ~e & g;
      t1 = h + s1 + ch + K[j] + blocks2[j];
      t2 = s0 + maj;
      h = d + t1 << 0;
      d = t1 + t2 << 0;
    }
    s0 = (d >>> 2 | d << 30) ^ (d >>> 13 | d << 19) ^ (d >>> 22 | d << 10);
    s1 = (h >>> 6 | h << 26) ^ (h >>> 11 | h << 21) ^ (h >>> 25 | h << 7);
    da = d & a;
    maj = da ^ d & b ^ ab;
    ch = g & h ^ ~g & e;
    t1 = f + s1 + ch + K[j + 1] + blocks2[j + 1];
    t2 = s0 + maj;
    g = c + t1 << 0;
    c = t1 + t2 << 0;
    s0 = (c >>> 2 | c << 30) ^ (c >>> 13 | c << 19) ^ (c >>> 22 | c << 10);
    s1 = (g >>> 6 | g << 26) ^ (g >>> 11 | g << 21) ^ (g >>> 25 | g << 7);
    cd = c & d;
    maj = cd ^ c & a ^ da;
    ch = f & g ^ ~f & h;
    t1 = e + s1 + ch + K[j + 2] + blocks2[j + 2];
    t2 = s0 + maj;
    f = b + t1 << 0;
    b = t1 + t2 << 0;
    s0 = (b >>> 2 | b << 30) ^ (b >>> 13 | b << 19) ^ (b >>> 22 | b << 10);
    s1 = (f >>> 6 | f << 26) ^ (f >>> 11 | f << 21) ^ (f >>> 25 | f << 7);
    bc = b & c;
    maj = bc ^ b & d ^ cd;
    ch = f & g ^ ~f & h;
    t1 = e + s1 + ch + K[j + 3] + blocks2[j + 3];
    t2 = s0 + maj;
    e = a + t1 << 0;
    a = t1 + t2 << 0;
    this.chromeBugWorkAround = true;
  }
  this.h0 = this.h0 + a << 0;
  this.h1 = this.h1 + b << 0;
  this.h2 = this.h2 + c << 0;
  this.h3 = this.h3 + d << 0;
  this.h4 = this.h4 + e << 0;
  this.h5 = this.h5 + f << 0;
  this.h6 = this.h6 + g << 0;
  this.h7 = this.h7 + h << 0;
};
Sha256.prototype.hex = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var hex2 = HEX_CHARS[h0 >>> 28 & 15] + HEX_CHARS[h0 >>> 24 & 15] + HEX_CHARS[h0 >>> 20 & 15] + HEX_CHARS[h0 >>> 16 & 15] + HEX_CHARS[h0 >>> 12 & 15] + HEX_CHARS[h0 >>> 8 & 15] + HEX_CHARS[h0 >>> 4 & 15] + HEX_CHARS[h0 & 15] + HEX_CHARS[h1 >>> 28 & 15] + HEX_CHARS[h1 >>> 24 & 15] + HEX_CHARS[h1 >>> 20 & 15] + HEX_CHARS[h1 >>> 16 & 15] + HEX_CHARS[h1 >>> 12 & 15] + HEX_CHARS[h1 >>> 8 & 15] + HEX_CHARS[h1 >>> 4 & 15] + HEX_CHARS[h1 & 15] + HEX_CHARS[h2 >>> 28 & 15] + HEX_CHARS[h2 >>> 24 & 15] + HEX_CHARS[h2 >>> 20 & 15] + HEX_CHARS[h2 >>> 16 & 15] + HEX_CHARS[h2 >>> 12 & 15] + HEX_CHARS[h2 >>> 8 & 15] + HEX_CHARS[h2 >>> 4 & 15] + HEX_CHARS[h2 & 15] + HEX_CHARS[h3 >>> 28 & 15] + HEX_CHARS[h3 >>> 24 & 15] + HEX_CHARS[h3 >>> 20 & 15] + HEX_CHARS[h3 >>> 16 & 15] + HEX_CHARS[h3 >>> 12 & 15] + HEX_CHARS[h3 >>> 8 & 15] + HEX_CHARS[h3 >>> 4 & 15] + HEX_CHARS[h3 & 15] + HEX_CHARS[h4 >>> 28 & 15] + HEX_CHARS[h4 >>> 24 & 15] + HEX_CHARS[h4 >>> 20 & 15] + HEX_CHARS[h4 >>> 16 & 15] + HEX_CHARS[h4 >>> 12 & 15] + HEX_CHARS[h4 >>> 8 & 15] + HEX_CHARS[h4 >>> 4 & 15] + HEX_CHARS[h4 & 15] + HEX_CHARS[h5 >>> 28 & 15] + HEX_CHARS[h5 >>> 24 & 15] + HEX_CHARS[h5 >>> 20 & 15] + HEX_CHARS[h5 >>> 16 & 15] + HEX_CHARS[h5 >>> 12 & 15] + HEX_CHARS[h5 >>> 8 & 15] + HEX_CHARS[h5 >>> 4 & 15] + HEX_CHARS[h5 & 15] + HEX_CHARS[h6 >>> 28 & 15] + HEX_CHARS[h6 >>> 24 & 15] + HEX_CHARS[h6 >>> 20 & 15] + HEX_CHARS[h6 >>> 16 & 15] + HEX_CHARS[h6 >>> 12 & 15] + HEX_CHARS[h6 >>> 8 & 15] + HEX_CHARS[h6 >>> 4 & 15] + HEX_CHARS[h6 & 15];
  if (!this.is224) hex2 += HEX_CHARS[h7 >>> 28 & 15] + HEX_CHARS[h7 >>> 24 & 15] + HEX_CHARS[h7 >>> 20 & 15] + HEX_CHARS[h7 >>> 16 & 15] + HEX_CHARS[h7 >>> 12 & 15] + HEX_CHARS[h7 >>> 8 & 15] + HEX_CHARS[h7 >>> 4 & 15] + HEX_CHARS[h7 & 15];
  return hex2;
};
Sha256.prototype.toString = Sha256.prototype.hex;
Sha256.prototype.digest = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var arr = [
    h0 >>> 24 & 255,
    h0 >>> 16 & 255,
    h0 >>> 8 & 255,
    h0 & 255,
    h1 >>> 24 & 255,
    h1 >>> 16 & 255,
    h1 >>> 8 & 255,
    h1 & 255,
    h2 >>> 24 & 255,
    h2 >>> 16 & 255,
    h2 >>> 8 & 255,
    h2 & 255,
    h3 >>> 24 & 255,
    h3 >>> 16 & 255,
    h3 >>> 8 & 255,
    h3 & 255,
    h4 >>> 24 & 255,
    h4 >>> 16 & 255,
    h4 >>> 8 & 255,
    h4 & 255,
    h5 >>> 24 & 255,
    h5 >>> 16 & 255,
    h5 >>> 8 & 255,
    h5 & 255,
    h6 >>> 24 & 255,
    h6 >>> 16 & 255,
    h6 >>> 8 & 255,
    h6 & 255
  ];
  if (!this.is224) arr.push(h7 >>> 24 & 255, h7 >>> 16 & 255, h7 >>> 8 & 255, h7 & 255);
  return arr;
};
Sha256.prototype.array = Sha256.prototype.digest;
Sha256.prototype.arrayBuffer = function() {
  this.finalize();
  var buffer = new ArrayBuffer(this.is224 ? 28 : 32);
  var dataView = new DataView(buffer);
  dataView.setUint32(0, this.h0);
  dataView.setUint32(4, this.h1);
  dataView.setUint32(8, this.h2);
  dataView.setUint32(12, this.h3);
  dataView.setUint32(16, this.h4);
  dataView.setUint32(20, this.h5);
  dataView.setUint32(24, this.h6);
  if (!this.is224) dataView.setUint32(28, this.h7);
  return buffer;
};
var sha256 = (...strings) => {
  return new Sha256(false, true).update(strings.join("")).hex();
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/utils/hash.js
var hash_exports = __exportAll({ sha256: () => sha256 });

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/caches/index.js
var caches_exports = __exportAll({
  BaseCache: () => BaseCache,
  InMemoryCache: () => InMemoryCache,
  defaultHashKeyEncoder: () => defaultHashKeyEncoder,
  deserializeStoredGeneration: () => deserializeStoredGeneration,
  serializeGeneration: () => serializeGeneration
});
var defaultHashKeyEncoder = (...strings) => sha256(strings.join("_"));
function deserializeStoredGeneration(storedGeneration) {
  if (storedGeneration.message !== void 0) return {
    text: storedGeneration.text,
    message: mapStoredMessageToChatMessage(storedGeneration.message)
  };
  else return { text: storedGeneration.text };
}
function serializeGeneration(generation) {
  const serializedValue = { text: generation.text };
  if (generation.message !== void 0) serializedValue.message = generation.message.toDict();
  return serializedValue;
}
var BaseCache = class {
  keyEncoder = defaultHashKeyEncoder;
  /**
  * Sets a custom key encoder function for the cache.
  * This function should take a prompt and an LLM key and return a string
  * that will be used as the cache key.
  * @param keyEncoderFn The custom key encoder function.
  */
  makeDefaultKeyEncoder(keyEncoderFn) {
    this.keyEncoder = keyEncoderFn;
  }
};
var GLOBAL_MAP = /* @__PURE__ */ new Map();
var InMemoryCache = class InMemoryCache2 extends BaseCache {
  cache;
  constructor(map2) {
    super();
    this.cache = map2 ?? /* @__PURE__ */ new Map();
  }
  /**
  * Retrieves data from the cache using a prompt and an LLM key. If the
  * data is not found, it returns null.
  * @param prompt The prompt used to find the data.
  * @param llmKey The LLM key used to find the data.
  * @returns The data corresponding to the prompt and LLM key, or null if not found.
  */
  lookup(prompt, llmKey) {
    return Promise.resolve(this.cache.get(this.keyEncoder(prompt, llmKey)) ?? null);
  }
  /**
  * Updates the cache with new data using a prompt and an LLM key.
  * @param prompt The prompt used to store the data.
  * @param llmKey The LLM key used to store the data.
  * @param value The data to be stored.
  */
  async update(prompt, llmKey, value) {
    this.cache.set(this.keyEncoder(prompt, llmKey), value);
  }
  /**
  * Returns a global instance of InMemoryCache using a predefined global
  * map as the initial cache.
  * @returns A global instance of InMemoryCache.
  */
  static global() {
    return new InMemoryCache2(GLOBAL_MAP);
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/prompt_values.js
var prompt_values_exports = __exportAll({
  BasePromptValue: () => BasePromptValue,
  ChatPromptValue: () => ChatPromptValue,
  ImagePromptValue: () => ImagePromptValue,
  StringPromptValue: () => StringPromptValue
});
var BasePromptValue = class extends Serializable {
};
var StringPromptValue = class extends BasePromptValue {
  static lc_name() {
    return "StringPromptValue";
  }
  lc_namespace = ["langchain_core", "prompt_values"];
  lc_serializable = true;
  value;
  constructor(value) {
    super({ value });
    this.value = value;
  }
  toString() {
    return this.value;
  }
  toChatMessages() {
    return [new HumanMessage(this.value)];
  }
};
var ChatPromptValue = class extends BasePromptValue {
  lc_namespace = ["langchain_core", "prompt_values"];
  lc_serializable = true;
  static lc_name() {
    return "ChatPromptValue";
  }
  messages;
  constructor(fields) {
    if (Array.isArray(fields)) fields = { messages: fields };
    super(fields);
    this.messages = fields.messages;
  }
  toString() {
    return getBufferString(this.messages);
  }
  toChatMessages() {
    return this.messages;
  }
};
var ImagePromptValue = class extends BasePromptValue {
  lc_namespace = ["langchain_core", "prompt_values"];
  lc_serializable = true;
  static lc_name() {
    return "ImagePromptValue";
  }
  imageUrl;
  /** @ignore */
  value;
  constructor(fields) {
    if (!("imageUrl" in fields)) fields = { imageUrl: fields };
    super(fields);
    this.imageUrl = fields.imageUrl;
  }
  toString() {
    return this.imageUrl.url;
  }
  toChatMessages() {
    return [new HumanMessage({ content: [{
      type: "image_url",
      image_url: {
        detail: this.imageUrl.detail,
        url: this.imageUrl.url
      }
    }] })];
  }
};

// node_modules/.pnpm/js-tiktoken@1.0.21/node_modules/js-tiktoken/dist/chunk-VL2OQCWN.js
var import_base64_js = __toESM(require_base64_js(), 1);
var __defProp = Object.defineProperty;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
function bytePairMerge(piece, ranks) {
  let parts = Array.from(
    { length: piece.length },
    (_, i) => ({ start: i, end: i + 1 })
  );
  while (parts.length > 1) {
    let minRank = null;
    for (let i = 0; i < parts.length - 1; i++) {
      const slice = piece.slice(parts[i].start, parts[i + 1].end);
      const rank = ranks.get(slice.join(","));
      if (rank == null)
        continue;
      if (minRank == null || rank < minRank[0]) {
        minRank = [rank, i];
      }
    }
    if (minRank != null) {
      const i = minRank[1];
      parts[i] = { start: parts[i].start, end: parts[i + 1].end };
      parts.splice(i + 1, 1);
    } else {
      break;
    }
  }
  return parts;
}
function bytePairEncode(piece, ranks) {
  if (piece.length === 1)
    return [ranks.get(piece.join(","))];
  return bytePairMerge(piece, ranks).map((p) => ranks.get(piece.slice(p.start, p.end).join(","))).filter((x) => x != null);
}
function escapeRegex(str2) {
  return str2.replace(/[\\^$*+?.()|[\]{}]/g, "\\$&");
}
var _Tiktoken = class {
  /** @internal */
  specialTokens;
  /** @internal */
  inverseSpecialTokens;
  /** @internal */
  patStr;
  /** @internal */
  textEncoder = new TextEncoder();
  /** @internal */
  textDecoder = new TextDecoder("utf-8");
  /** @internal */
  rankMap = /* @__PURE__ */ new Map();
  /** @internal */
  textMap = /* @__PURE__ */ new Map();
  constructor(ranks, extendedSpecialTokens) {
    this.patStr = ranks.pat_str;
    const uncompressed = ranks.bpe_ranks.split("\n").filter(Boolean).reduce((memo, x) => {
      const [_, offsetStr, ...tokens] = x.split(" ");
      const offset = Number.parseInt(offsetStr, 10);
      tokens.forEach((token, i) => memo[token] = offset + i);
      return memo;
    }, {});
    for (const [token, rank] of Object.entries(uncompressed)) {
      const bytes = import_base64_js.default.toByteArray(token);
      this.rankMap.set(bytes.join(","), rank);
      this.textMap.set(rank, bytes);
    }
    this.specialTokens = { ...ranks.special_tokens, ...extendedSpecialTokens };
    this.inverseSpecialTokens = Object.entries(this.specialTokens).reduce((memo, [text, rank]) => {
      memo[rank] = this.textEncoder.encode(text);
      return memo;
    }, {});
  }
  encode(text, allowedSpecial = [], disallowedSpecial = "all") {
    const regexes = new RegExp(this.patStr, "ug");
    const specialRegex = _Tiktoken.specialTokenRegex(
      Object.keys(this.specialTokens)
    );
    const ret = [];
    const allowedSpecialSet = new Set(
      allowedSpecial === "all" ? Object.keys(this.specialTokens) : allowedSpecial
    );
    const disallowedSpecialSet = new Set(
      disallowedSpecial === "all" ? Object.keys(this.specialTokens).filter(
        (x) => !allowedSpecialSet.has(x)
      ) : disallowedSpecial
    );
    if (disallowedSpecialSet.size > 0) {
      const disallowedSpecialRegex = _Tiktoken.specialTokenRegex([
        ...disallowedSpecialSet
      ]);
      const specialMatch = text.match(disallowedSpecialRegex);
      if (specialMatch != null) {
        throw new Error(
          `The text contains a special token that is not allowed: ${specialMatch[0]}`
        );
      }
    }
    let start = 0;
    while (true) {
      let nextSpecial = null;
      let startFind = start;
      while (true) {
        specialRegex.lastIndex = startFind;
        nextSpecial = specialRegex.exec(text);
        if (nextSpecial == null || allowedSpecialSet.has(nextSpecial[0]))
          break;
        startFind = nextSpecial.index + 1;
      }
      const end = nextSpecial?.index ?? text.length;
      for (const match of text.substring(start, end).matchAll(regexes)) {
        const piece = this.textEncoder.encode(match[0]);
        const token2 = this.rankMap.get(piece.join(","));
        if (token2 != null) {
          ret.push(token2);
          continue;
        }
        ret.push(...bytePairEncode(piece, this.rankMap));
      }
      if (nextSpecial == null)
        break;
      let token = this.specialTokens[nextSpecial[0]];
      ret.push(token);
      start = nextSpecial.index + nextSpecial[0].length;
    }
    return ret;
  }
  decode(tokens) {
    const res = [];
    let length = 0;
    for (let i2 = 0; i2 < tokens.length; ++i2) {
      const token = tokens[i2];
      const bytes = this.textMap.get(token) ?? this.inverseSpecialTokens[token];
      if (bytes != null) {
        res.push(bytes);
        length += bytes.length;
      }
    }
    const mergedArray = new Uint8Array(length);
    let i = 0;
    for (const bytes of res) {
      mergedArray.set(bytes, i);
      i += bytes.length;
    }
    return this.textDecoder.decode(mergedArray);
  }
};
var Tiktoken = _Tiktoken;
__publicField(Tiktoken, "specialTokenRegex", (tokens) => {
  return new RegExp(tokens.map((i) => escapeRegex(i)).join("|"), "g");
});
function getEncodingNameForModel(model) {
  switch (model) {
    case "gpt2": {
      return "gpt2";
    }
    case "code-cushman-001":
    case "code-cushman-002":
    case "code-davinci-001":
    case "code-davinci-002":
    case "cushman-codex":
    case "davinci-codex":
    case "davinci-002":
    case "text-davinci-002":
    case "text-davinci-003": {
      return "p50k_base";
    }
    case "code-davinci-edit-001":
    case "text-davinci-edit-001": {
      return "p50k_edit";
    }
    case "ada":
    case "babbage":
    case "babbage-002":
    case "code-search-ada-code-001":
    case "code-search-babbage-code-001":
    case "curie":
    case "davinci":
    case "text-ada-001":
    case "text-babbage-001":
    case "text-curie-001":
    case "text-davinci-001":
    case "text-search-ada-doc-001":
    case "text-search-babbage-doc-001":
    case "text-search-curie-doc-001":
    case "text-search-davinci-doc-001":
    case "text-similarity-ada-001":
    case "text-similarity-babbage-001":
    case "text-similarity-curie-001":
    case "text-similarity-davinci-001": {
      return "r50k_base";
    }
    case "gpt-3.5-turbo-instruct-0914":
    case "gpt-3.5-turbo-instruct":
    case "gpt-3.5-turbo-16k-0613":
    case "gpt-3.5-turbo-16k":
    case "gpt-3.5-turbo-0613":
    case "gpt-3.5-turbo-0301":
    case "gpt-3.5-turbo":
    case "gpt-4-32k-0613":
    case "gpt-4-32k-0314":
    case "gpt-4-32k":
    case "gpt-4-0613":
    case "gpt-4-0314":
    case "gpt-4":
    case "gpt-3.5-turbo-1106":
    case "gpt-35-turbo":
    case "gpt-4-1106-preview":
    case "gpt-4-vision-preview":
    case "gpt-3.5-turbo-0125":
    case "gpt-4-turbo":
    case "gpt-4-turbo-2024-04-09":
    case "gpt-4-turbo-preview":
    case "gpt-4-0125-preview":
    case "text-embedding-ada-002":
    case "text-embedding-3-small":
    case "text-embedding-3-large": {
      return "cl100k_base";
    }
    case "gpt-4o":
    case "gpt-4o-2024-05-13":
    case "gpt-4o-2024-08-06":
    case "gpt-4o-2024-11-20":
    case "gpt-4o-mini-2024-07-18":
    case "gpt-4o-mini":
    case "gpt-4o-search-preview":
    case "gpt-4o-search-preview-2025-03-11":
    case "gpt-4o-mini-search-preview":
    case "gpt-4o-mini-search-preview-2025-03-11":
    case "gpt-4o-audio-preview":
    case "gpt-4o-audio-preview-2024-12-17":
    case "gpt-4o-audio-preview-2024-10-01":
    case "gpt-4o-mini-audio-preview":
    case "gpt-4o-mini-audio-preview-2024-12-17":
    case "o1":
    case "o1-2024-12-17":
    case "o1-mini":
    case "o1-mini-2024-09-12":
    case "o1-preview":
    case "o1-preview-2024-09-12":
    case "o1-pro":
    case "o1-pro-2025-03-19":
    case "o3":
    case "o3-2025-04-16":
    case "o3-mini":
    case "o3-mini-2025-01-31":
    case "o4-mini":
    case "o4-mini-2025-04-16":
    case "chatgpt-4o-latest":
    case "gpt-4o-realtime":
    case "gpt-4o-realtime-preview-2024-10-01":
    case "gpt-4o-realtime-preview-2024-12-17":
    case "gpt-4o-mini-realtime-preview":
    case "gpt-4o-mini-realtime-preview-2024-12-17":
    case "gpt-4.1":
    case "gpt-4.1-2025-04-14":
    case "gpt-4.1-mini":
    case "gpt-4.1-mini-2025-04-14":
    case "gpt-4.1-nano":
    case "gpt-4.1-nano-2025-04-14":
    case "gpt-4.5-preview":
    case "gpt-4.5-preview-2025-02-27":
    case "gpt-5":
    case "gpt-5-2025-08-07":
    case "gpt-5-nano":
    case "gpt-5-nano-2025-08-07":
    case "gpt-5-mini":
    case "gpt-5-mini-2025-08-07":
    case "gpt-5-chat-latest": {
      return "o200k_base";
    }
    default:
      throw new Error("Unknown model");
  }
}

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/utils/tiktoken.js
var tiktoken_exports = __exportAll({
  encodingForModel: () => encodingForModel,
  getEncoding: () => getEncoding
});
var cache = {};
var caller = new AsyncCaller({});
async function getEncoding(encoding) {
  if (!(encoding in cache)) cache[encoding] = caller.fetch(`https://tiktoken.pages.dev/js/${encoding}.json`).then((res) => res.json()).then((data) => new Tiktoken(data)).catch((e) => {
    delete cache[encoding];
    throw e;
  });
  return await cache[encoding];
}
async function encodingForModel(model) {
  return getEncoding(getEncodingNameForModel(model));
}

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/language_models/base.js
var base_exports = __exportAll({
  BaseLangChain: () => BaseLangChain,
  BaseLanguageModel: () => BaseLanguageModel,
  calculateMaxTokens: () => calculateMaxTokens,
  getEmbeddingContextSize: () => getEmbeddingContextSize,
  getModelContextSize: () => getModelContextSize,
  getModelNameForTiktoken: () => getModelNameForTiktoken,
  isOpenAITool: () => isOpenAITool
});
var getModelNameForTiktoken = (modelName) => {
  if (modelName.startsWith("gpt-5")) return "gpt-5";
  if (modelName.startsWith("gpt-3.5-turbo-16k")) return "gpt-3.5-turbo-16k";
  if (modelName.startsWith("gpt-3.5-turbo-")) return "gpt-3.5-turbo";
  if (modelName.startsWith("gpt-4-32k")) return "gpt-4-32k";
  if (modelName.startsWith("gpt-4-")) return "gpt-4";
  if (modelName.startsWith("gpt-4o")) return "gpt-4o";
  return modelName;
};
var getEmbeddingContextSize = (modelName) => {
  switch (modelName) {
    case "text-embedding-ada-002":
      return 8191;
    default:
      return 2046;
  }
};
var getModelContextSize = (modelName) => {
  switch (getModelNameForTiktoken(modelName)) {
    case "gpt-5":
    case "gpt-5-turbo":
    case "gpt-5-turbo-preview":
      return 4e5;
    case "gpt-4o":
    case "gpt-4o-mini":
    case "gpt-4o-2024-05-13":
    case "gpt-4o-2024-08-06":
      return 128e3;
    case "gpt-4-turbo":
    case "gpt-4-turbo-preview":
    case "gpt-4-turbo-2024-04-09":
    case "gpt-4-0125-preview":
    case "gpt-4-1106-preview":
      return 128e3;
    case "gpt-4-32k":
    case "gpt-4-32k-0314":
    case "gpt-4-32k-0613":
      return 32768;
    case "gpt-4":
    case "gpt-4-0314":
    case "gpt-4-0613":
      return 8192;
    case "gpt-3.5-turbo-16k":
    case "gpt-3.5-turbo-16k-0613":
      return 16384;
    case "gpt-3.5-turbo":
    case "gpt-3.5-turbo-0301":
    case "gpt-3.5-turbo-0613":
    case "gpt-3.5-turbo-1106":
    case "gpt-3.5-turbo-0125":
      return 4096;
    case "text-davinci-003":
    case "text-davinci-002":
      return 4097;
    case "text-davinci-001":
      return 2049;
    case "text-curie-001":
    case "text-babbage-001":
    case "text-ada-001":
      return 2048;
    case "code-davinci-002":
    case "code-davinci-001":
      return 8e3;
    case "code-cushman-001":
      return 2048;
    case "claude-3-5-sonnet-20241022":
    case "claude-3-5-sonnet-20240620":
    case "claude-3-opus-20240229":
    case "claude-3-sonnet-20240229":
    case "claude-3-haiku-20240307":
    case "claude-2.1":
      return 2e5;
    case "claude-2.0":
    case "claude-instant-1.2":
      return 1e5;
    case "gemini-1.5-pro":
    case "gemini-1.5-pro-latest":
    case "gemini-1.5-flash":
    case "gemini-1.5-flash-latest":
      return 1e6;
    case "gemini-pro":
    case "gemini-pro-vision":
      return 32768;
    default:
      return 4097;
  }
};
function isOpenAITool(tool2) {
  if (typeof tool2 !== "object" || !tool2) return false;
  if ("type" in tool2 && tool2.type === "function" && "function" in tool2 && typeof tool2.function === "object" && tool2.function && "name" in tool2.function && "parameters" in tool2.function) return true;
  return false;
}
var calculateMaxTokens = async ({ prompt, modelName }) => {
  let numTokens;
  try {
    numTokens = (await encodingForModel(getModelNameForTiktoken(modelName))).encode(prompt).length;
  } catch {
    console.warn("Failed to calculate number of tokens, falling back to approximate count");
    numTokens = Math.ceil(prompt.length / 4);
  }
  return getModelContextSize(modelName) - numTokens;
};
var getVerbosity = () => false;
var BaseLangChain = class extends Runnable {
  /**
  * Whether to print out response text.
  */
  verbose;
  callbacks;
  tags;
  metadata;
  get lc_attributes() {
    return {
      callbacks: void 0,
      verbose: void 0
    };
  }
  constructor(params) {
    super(params);
    this.verbose = params.verbose ?? getVerbosity();
    this.callbacks = params.callbacks;
    this.tags = params.tags ?? [];
    this.metadata = params.metadata ?? {};
  }
};
var BaseLanguageModel = class extends BaseLangChain {
  /**
  * Keys that the language model accepts as call options.
  */
  get callKeys() {
    return [
      "stop",
      "timeout",
      "signal",
      "tags",
      "metadata",
      "callbacks"
    ];
  }
  /**
  * The async caller should be used by subclasses to make any async calls,
  * which will thus benefit from the concurrency and retry logic.
  */
  caller;
  cache;
  constructor({ callbacks, callbackManager, ...params }) {
    const { cache: cache2, ...rest } = params;
    super({
      callbacks: callbacks ?? callbackManager,
      ...rest
    });
    if (typeof cache2 === "object") this.cache = cache2;
    else if (cache2) this.cache = InMemoryCache.global();
    else this.cache = void 0;
    this.caller = new AsyncCaller(params ?? {});
  }
  _encoding;
  /**
  * Get the number of tokens in the content.
  * @param content The content to get the number of tokens for.
  * @returns The number of tokens in the content.
  */
  async getNumTokens(content) {
    let textContent;
    if (typeof content === "string") textContent = content;
    else
      textContent = content.map((item) => {
        if (typeof item === "string") return item;
        if (item.type === "text" && "text" in item) return item.text;
        return "";
      }).join("");
    let numTokens = Math.ceil(textContent.length / 4);
    if (!this._encoding) try {
      this._encoding = await encodingForModel("modelName" in this ? getModelNameForTiktoken(this.modelName) : "gpt2");
    } catch (error) {
      console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
    }
    if (this._encoding) try {
      numTokens = this._encoding.encode(textContent).length;
    } catch (error) {
      console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
    }
    return numTokens;
  }
  static _convertInputToPromptValue(input) {
    if (typeof input === "string") return new StringPromptValue(input);
    else if (Array.isArray(input)) return new ChatPromptValue(input.map(coerceMessageLikeToMessage));
    else return input;
  }
  /**
  * Get the identifying parameters of the LLM.
  */
  _identifyingParams() {
    return {};
  }
  /**
  * Create a unique cache key for a specific call to a specific language model.
  * @param callOptions Call options for the model
  * @returns A unique cache key.
  */
  _getSerializedCacheKeyParametersForCall({ config: config2, ...callOptions }) {
    const params = {
      ...this._identifyingParams(),
      ...callOptions,
      _type: this._llmType(),
      _model: this._modelType()
    };
    return Object.entries(params).filter(([_, value]) => value !== void 0).map(([key, value]) => `${key}:${JSON.stringify(value)}`).sort().join(",");
  }
  /**
  * @deprecated
  * Return a json-like object representing this LLM.
  */
  serialize() {
    return {
      ...this._identifyingParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  /**
  * @deprecated
  * Load an LLM from a json-like object describing it.
  */
  static async deserialize(_data) {
    throw new Error("Use .toJSON() instead");
  }
  /**
  * Return profiling information for the model.
  *
  * @returns {ModelProfile} An object describing the model's capabilities and constraints
  */
  get profile() {
    return {};
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/runnables/passthrough.js
var RunnablePassthrough = class extends Runnable {
  static lc_name() {
    return "RunnablePassthrough";
  }
  lc_namespace = ["langchain_core", "runnables"];
  lc_serializable = true;
  func;
  constructor(fields) {
    super(fields);
    if (fields) this.func = fields.func;
  }
  async invoke(input, options) {
    const config2 = ensureConfig(options);
    if (this.func) await this.func(input, config2);
    return this._callWithConfig((input2) => Promise.resolve(input2), input, config2);
  }
  async *transform(generator, options) {
    const config2 = ensureConfig(options);
    let finalOutput;
    let finalOutputSupported = true;
    for await (const chunk of this._transformStreamWithConfig(generator, (input) => input, config2)) {
      yield chunk;
      if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
      else try {
        finalOutput = concat(finalOutput, chunk);
      } catch {
        finalOutput = void 0;
        finalOutputSupported = false;
      }
    }
    if (this.func && finalOutput !== void 0) await this.func(finalOutput, config2);
  }
  /**
  * A runnable that assigns key-value pairs to the input.
  *
  * The example below shows how you could use it with an inline function.
  *
  * @example
  * ```typescript
  * const prompt =
  *   PromptTemplate.fromTemplate(`Write a SQL query to answer the question using the following schema: {schema}
  * Question: {question}
  * SQL Query:`);
  *
  * // The `RunnablePassthrough.assign()` is used here to passthrough the input from the `.invoke()`
  * // call (in this example it's the question), along with any inputs passed to the `.assign()` method.
  * // In this case, we're passing the schema.
  * const sqlQueryGeneratorChain = RunnableSequence.from([
  *   RunnablePassthrough.assign({
  *     schema: async () => db.getTableInfo(),
  *   }),
  *   prompt,
  *   new ChatOpenAI({ model: "gpt-4o-mini" }).withConfig({ stop: ["\nSQLResult:"] }),
  *   new StringOutputParser(),
  * ]);
  * const result = await sqlQueryGeneratorChain.invoke({
  *   question: "How many employees are there?",
  * });
  * ```
  */
  static assign(mapping) {
    return new RunnableAssign(new RunnableMap({ steps: mapping }));
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/language_models/utils.js
var iife2 = (fn) => fn();
function castStandardMessageContent(message) {
  const Cls = message.constructor;
  return new Cls({
    ...message,
    content: message.contentBlocks,
    response_metadata: {
      ...message.response_metadata,
      output_version: "v1"
    }
  });
}

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/language_models/chat_models.js
var chat_models_exports = __exportAll({
  BaseChatModel: () => BaseChatModel,
  SimpleChatModel: () => SimpleChatModel
});
function _formatForTracing(messages) {
  const messagesToTrace = [];
  for (const message of messages) {
    let messageToTrace = message;
    if (Array.isArray(message.content)) for (let idx = 0; idx < message.content.length; idx++) {
      const block = message.content[idx];
      if (isURLContentBlock(block) || isBase64ContentBlock(block)) {
        if (messageToTrace === message) messageToTrace = new message.constructor({
          ...messageToTrace,
          content: [
            ...message.content.slice(0, idx),
            convertToOpenAIImageBlock(block),
            ...message.content.slice(idx + 1)
          ]
        });
      }
    }
    messagesToTrace.push(messageToTrace);
  }
  return messagesToTrace;
}
var BaseChatModel = class BaseChatModel2 extends BaseLanguageModel {
  lc_namespace = [
    "langchain",
    "chat_models",
    this._llmType()
  ];
  disableStreaming = false;
  outputVersion;
  get callKeys() {
    return [...super.callKeys, "outputVersion"];
  }
  constructor(fields) {
    super(fields);
    this.outputVersion = iife2(() => {
      const outputVersion = fields.outputVersion ?? getEnvironmentVariable("LC_OUTPUT_VERSION");
      if (outputVersion && ["v0", "v1"].includes(outputVersion)) return outputVersion;
      return "v0";
    });
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  /**
  * Invokes the chat model with a single input.
  * @param input The input for the language model.
  * @param options The call options.
  * @returns A Promise that resolves to a BaseMessageChunk.
  */
  async invoke(input, options) {
    const promptValue = BaseChatModel2._convertInputToPromptValue(input);
    return (await this.generatePrompt([promptValue], options, options?.callbacks)).generations[0][0].message;
  }
  async *_streamResponseChunks(_messages, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  async *_streamIterator(input, options) {
    if (this._streamResponseChunks === BaseChatModel2.prototype._streamResponseChunks || this.disableStreaming) yield this.invoke(input, options);
    else {
      const messages = BaseChatModel2._convertInputToPromptValue(input).toChatMessages();
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const inheritableMetadata = {
        ...runnableConfig.metadata,
        ...this.getLsParams(callOptions)
      };
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this?.invocationParams(callOptions),
        batch_size: 1
      };
      const outputVersion = callOptions.outputVersion ?? this.outputVersion;
      const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), [_formatForTracing(messages)], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName);
      let generationChunk;
      let llmOutput;
      try {
        for await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers?.[0])) {
          callOptions.signal?.throwIfAborted();
          if (chunk.message.id == null) {
            const runId = runManagers?.at(0)?.runId;
            if (runId != null) chunk.message._updateId(`run-${runId}`);
          }
          chunk.message.response_metadata = {
            ...chunk.generationInfo,
            ...chunk.message.response_metadata
          };
          if (outputVersion === "v1") yield castStandardMessageContent(chunk.message);
          else yield chunk.message;
          if (!generationChunk) generationChunk = chunk;
          else generationChunk = generationChunk.concat(chunk);
          if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) llmOutput = { tokenUsage: {
            promptTokens: chunk.message.usage_metadata.input_tokens,
            completionTokens: chunk.message.usage_metadata.output_tokens,
            totalTokens: chunk.message.usage_metadata.total_tokens
          } };
        }
        callOptions.signal?.throwIfAborted();
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));
        throw err;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({
        generations: [[generationChunk]],
        llmOutput
      })));
    }
  }
  getLsParams(options) {
    const providerName = this.getName().startsWith("Chat") ? this.getName().replace("Chat", "") : this.getName();
    return {
      ls_model_type: "chat",
      ls_stop: options.stop,
      ls_provider: providerName
    };
  }
  /** @ignore */
  async _generateUncached(messages, parsedOptions, handledOptions, startedRunManagers) {
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === baseMessages.length) runManagers = startedRunManagers;
    else {
      const inheritableMetadata = {
        ...handledOptions.metadata,
        ...this.getLsParams(parsedOptions)
      };
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this?.invocationParams(parsedOptions),
        batch_size: 1
      };
      runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName);
    }
    const outputVersion = parsedOptions.outputVersion ?? this.outputVersion;
    const generations = [];
    const llmOutputs = [];
    if (!!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming) && !this.disableStreaming && baseMessages.length === 1 && this._streamResponseChunks !== BaseChatModel2.prototype._streamResponseChunks) try {
      const stream = await this._streamResponseChunks(baseMessages[0], parsedOptions, runManagers?.[0]);
      let aggregated;
      let llmOutput;
      for await (const chunk of stream) {
        if (parsedOptions.signal?.aborted) {
          const partialMessage = aggregated?.message;
          throw new ModelAbortError("Model invocation was aborted.", partialMessage);
        }
        if (chunk.message.id == null) {
          const runId = runManagers?.at(0)?.runId;
          if (runId != null) chunk.message._updateId(`run-${runId}`);
        }
        if (aggregated === void 0) aggregated = chunk;
        else aggregated = concat(aggregated, chunk);
        if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) llmOutput = { tokenUsage: {
          promptTokens: chunk.message.usage_metadata.input_tokens,
          completionTokens: chunk.message.usage_metadata.output_tokens,
          totalTokens: chunk.message.usage_metadata.total_tokens
        } };
      }
      if (parsedOptions.signal?.aborted) {
        const partialMessage = aggregated?.message;
        throw new ModelAbortError("Model invocation was aborted.", partialMessage);
      }
      if (aggregated === void 0) throw new Error("Received empty response from chat model call.");
      generations.push([aggregated]);
      await runManagers?.[0].handleLLMEnd({
        generations,
        llmOutput
      });
    } catch (e) {
      await runManagers?.[0].handleLLMError(e);
      throw e;
    }
    else {
      const results = await Promise.allSettled(baseMessages.map(async (messageList, i) => {
        const generateResults = await this._generate(messageList, {
          ...parsedOptions,
          promptIndex: i
        }, runManagers?.[i]);
        if (outputVersion === "v1") for (const generation of generateResults.generations) generation.message = castStandardMessageContent(generation.message);
        return generateResults;
      }));
      await Promise.all(results.map(async (pResult, i) => {
        if (pResult.status === "fulfilled") {
          const result = pResult.value;
          for (const generation of result.generations) {
            if (generation.message.id == null) {
              const runId = runManagers?.at(0)?.runId;
              if (runId != null) generation.message._updateId(`run-${runId}`);
            }
            generation.message.response_metadata = {
              ...generation.generationInfo,
              ...generation.message.response_metadata
            };
          }
          if (result.generations.length === 1) result.generations[0].message.response_metadata = {
            ...result.llmOutput,
            ...result.generations[0].message.response_metadata
          };
          generations[i] = result.generations;
          llmOutputs[i] = result.llmOutput;
          return runManagers?.[i]?.handleLLMEnd({
            generations: [result.generations],
            llmOutput: result.llmOutput
          });
        } else {
          await runManagers?.[i]?.handleLLMError(pResult.reason);
          return Promise.reject(pResult.reason);
        }
      }));
    }
    const output = {
      generations,
      llmOutput: llmOutputs.length ? this._combineLLMOutput?.(...llmOutputs) : void 0
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ messages, cache: cache2, llmStringKey, parsedOptions, handledOptions }) {
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const inheritableMetadata = {
      ...handledOptions.metadata,
      ...this.getLsParams(parsedOptions)
    };
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this?.invocationParams(parsedOptions),
      batch_size: 1
    };
    const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName);
    const missingPromptIndices = [];
    const cachedResults = (await Promise.allSettled(baseMessages.map(async (baseMessage, index) => {
      const prompt = BaseChatModel2._convertInputToPromptValue(baseMessage).toString();
      const result = await cache2.lookup(prompt, llmStringKey);
      if (result == null) missingPromptIndices.push(index);
      return result;
    }))).map((result, index) => ({
      result,
      runManager: runManagers?.[index]
    })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const outputVersion = parsedOptions.outputVersion ?? this.outputVersion;
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i] = result.map((result2) => {
          if ("message" in result2 && isBaseMessage(result2.message) && isAIMessage(result2.message)) {
            result2.message.usage_metadata = {
              input_tokens: 0,
              output_tokens: 0,
              total_tokens: 0
            };
            if (outputVersion === "v1") result2.message = castStandardMessageContent(result2.message);
          }
          result2.generationInfo = {
            ...result2.generationInfo,
            tokenUsage: {}
          };
          return result2;
        });
        if (result.length) await runManager?.handleLLMNewToken(result[0].text);
        return runManager?.handleLLMEnd({ generations: [result] }, void 0, void 0, void 0, { cached: true });
      } else {
        await runManager?.handleLLMError(promiseResult.reason, void 0, void 0, void 0, { cached: true });
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
  * Generates chat based on the input messages.
  * @param messages An array of arrays of BaseMessage instances.
  * @param options The call options or an array of stop sequences.
  * @param callbacks The callbacks for the language model.
  * @returns A Promise that resolves to an LLMResult.
  */
  async generate(messages, options, callbacks) {
    let parsedOptions;
    if (Array.isArray(options)) parsedOptions = { stop: options };
    else parsedOptions = options;
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) return this._generateUncached(baseMessages, callOptions, runnableConfig);
    const { cache: cache2 } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      messages: baseMessages,
      cache: cache2,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i) => baseMessages[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers?.[i]) : void 0);
      await Promise.all(results.generations.map(async (generation, index) => {
        const promptIndex = missingPromptIndices[index];
        generations[promptIndex] = generation;
        const prompt = BaseChatModel2._convertInputToPromptValue(baseMessages[promptIndex]).toString();
        return cache2.update(prompt, llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return {
      generations,
      llmOutput
    };
  }
  /**
  * Get the parameters used to invoke the model
  */
  invocationParams(_options) {
    return {};
  }
  _modelType() {
    return "base_chat_model";
  }
  /**
  * Generates a prompt based on the input prompt values.
  * @param promptValues An array of BasePromptValue instances.
  * @param options The call options or an array of stop sequences.
  * @param callbacks The callbacks for the language model.
  * @returns A Promise that resolves to an LLMResult.
  */
  async generatePrompt(promptValues, options, callbacks) {
    const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());
    return this.generate(promptMessages, options, callbacks);
  }
  withStructuredOutput(outputSchema, config2) {
    if (typeof this.bindTools !== "function") throw new Error(`Chat model must implement ".bindTools()" to use withStructuredOutput.`);
    if (config2?.strict) throw new Error(`"strict" mode is not supported for this model by default.`);
    const schema = outputSchema;
    const name = config2?.name;
    const description = getSchemaDescription(schema) ?? "A function available to call.";
    const method = config2?.method;
    const includeRaw = config2?.includeRaw;
    if (method === "jsonMode") throw new Error(`Base withStructuredOutput implementation only supports "functionCalling" as a method.`);
    let functionName = name ?? "extract";
    let tools2;
    if (isInteropZodSchema(schema)) tools2 = [{
      type: "function",
      function: {
        name: functionName,
        description,
        parameters: toJsonSchema(schema)
      }
    }];
    else {
      if ("name" in schema) functionName = schema.name;
      tools2 = [{
        type: "function",
        function: {
          name: functionName,
          description,
          parameters: schema
        }
      }];
    }
    const llm = this.bindTools(tools2);
    const outputParser = RunnableLambda.from((input) => {
      if (!AIMessageChunk.isInstance(input)) throw new Error("Input is not an AIMessageChunk.");
      if (!input.tool_calls || input.tool_calls.length === 0) throw new Error("No tool calls found in the response.");
      const toolCall = input.tool_calls.find((tc) => tc.name === functionName);
      if (!toolCall) throw new Error(`No tool call found with name ${functionName}.`);
      return toolCall.args;
    });
    if (!includeRaw) return llm.pipe(outputParser).withConfig({ runName: "StructuredOutput" });
    const parserAssign = RunnablePassthrough.assign({ parsed: (input, config3) => outputParser.invoke(input.raw, config3) });
    const parserNone = RunnablePassthrough.assign({ parsed: () => null });
    const parsedWithFallback = parserAssign.withFallbacks({ fallbacks: [parserNone] });
    return RunnableSequence.from([{ raw: llm }, parsedWithFallback]).withConfig({ runName: "StructuredOutputRunnable" });
  }
};
var SimpleChatModel = class extends BaseChatModel {
  async _generate(messages, options, runManager) {
    const message = new AIMessage(await this._call(messages, options, runManager));
    if (typeof message.content !== "string") throw new Error("Cannot generate with a simple chat model when output is not a string.");
    return { generations: [{
      text: message.content,
      message
    }] };
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/runnables/router.js
var RouterRunnable = class extends Runnable {
  static lc_name() {
    return "RouterRunnable";
  }
  lc_namespace = ["langchain_core", "runnables"];
  lc_serializable = true;
  runnables;
  constructor(fields) {
    super(fields);
    this.runnables = fields.runnables;
  }
  async invoke(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) throw new Error(`No runnable associated with key "${key}".`);
    return runnable.invoke(actualInput, ensureConfig(options));
  }
  async batch(inputs, options, batchOptions) {
    const keys = inputs.map((input) => input.key);
    const actualInputs = inputs.map((input) => input.input);
    if (keys.find((key) => this.runnables[key] === void 0) !== void 0) throw new Error(`One or more keys do not have a corresponding runnable.`);
    const runnables = keys.map((key) => this.runnables[key]);
    const optionsList = this._getOptionsList(options ?? {}, inputs.length);
    const maxConcurrency = optionsList[0]?.maxConcurrency ?? batchOptions?.maxConcurrency;
    const batchSize = maxConcurrency && maxConcurrency > 0 ? maxConcurrency : inputs.length;
    const batchResults = [];
    for (let i = 0; i < actualInputs.length; i += batchSize) {
      const batchPromises = actualInputs.slice(i, i + batchSize).map((actualInput, i2) => runnables[i2].invoke(actualInput, optionsList[i2]));
      const batchResult = await Promise.all(batchPromises);
      batchResults.push(batchResult);
    }
    return batchResults.flat();
  }
  async stream(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) throw new Error(`No runnable associated with key "${key}".`);
    return runnable.stream(actualInput, options);
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/runnables/branch.js
var RunnableBranch = class extends Runnable {
  static lc_name() {
    return "RunnableBranch";
  }
  lc_namespace = ["langchain_core", "runnables"];
  lc_serializable = true;
  default;
  branches;
  constructor(fields) {
    super(fields);
    this.branches = fields.branches;
    this.default = fields.default;
  }
  /**
  * Convenience method for instantiating a RunnableBranch from
  * RunnableLikes (objects, functions, or Runnables).
  *
  * Each item in the input except for the last one should be a
  * tuple with two items. The first is a "condition" RunnableLike that
  * returns "true" if the second RunnableLike in the tuple should run.
  *
  * The final item in the input should be a RunnableLike that acts as a
  * default branch if no other branches match.
  *
  * @example
  * ```ts
  * import { RunnableBranch } from "@langchain/core/runnables";
  *
  * const branch = RunnableBranch.from([
  *   [(x: number) => x > 0, (x: number) => x + 1],
  *   [(x: number) => x < 0, (x: number) => x - 1],
  *   (x: number) => x
  * ]);
  * ```
  * @param branches An array where the every item except the last is a tuple of [condition, runnable]
  *   pairs. The last item is a default runnable which is invoked if no other condition matches.
  * @returns A new RunnableBranch.
  */
  static from(branches) {
    if (branches.length < 1) throw new Error("RunnableBranch requires at least one branch");
    const coercedBranches = branches.slice(0, -1).map(([condition, runnable]) => [_coerceToRunnable(condition), _coerceToRunnable(runnable)]);
    const defaultBranch = _coerceToRunnable(branches[branches.length - 1]);
    return new this({
      branches: coercedBranches,
      default: defaultBranch
    });
  }
  async _invoke(input, config2, runManager) {
    let result;
    for (let i = 0; i < this.branches.length; i += 1) {
      const [condition, branchRunnable] = this.branches[i];
      if (await condition.invoke(input, patchConfig(config2, { callbacks: runManager?.getChild(`condition:${i + 1}`) }))) {
        result = await branchRunnable.invoke(input, patchConfig(config2, { callbacks: runManager?.getChild(`branch:${i + 1}`) }));
        break;
      }
    }
    if (!result) result = await this.default.invoke(input, patchConfig(config2, { callbacks: runManager?.getChild("branch:default") }));
    return result;
  }
  async invoke(input, config2 = {}) {
    return this._callWithConfig(this._invoke, input, config2);
  }
  async *_streamIterator(input, config2) {
    const runManager = await (await getCallbackManagerForConfig(config2))?.handleChainStart(this.toJSON(), _coerceToDict(input, "input"), config2?.runId, void 0, void 0, void 0, config2?.runName);
    let finalOutput;
    let finalOutputSupported = true;
    let stream;
    try {
      for (let i = 0; i < this.branches.length; i += 1) {
        const [condition, branchRunnable] = this.branches[i];
        if (await condition.invoke(input, patchConfig(config2, { callbacks: runManager?.getChild(`condition:${i + 1}`) }))) {
          stream = await branchRunnable.stream(input, patchConfig(config2, { callbacks: runManager?.getChild(`branch:${i + 1}`) }));
          for await (const chunk of stream) {
            yield chunk;
            if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
            else try {
              finalOutput = concat(finalOutput, chunk);
            } catch {
              finalOutput = void 0;
              finalOutputSupported = false;
            }
          }
          break;
        }
      }
      if (stream === void 0) {
        stream = await this.default.stream(input, patchConfig(config2, { callbacks: runManager?.getChild("branch:default") }));
        for await (const chunk of stream) {
          yield chunk;
          if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
          else try {
            finalOutput = concat(finalOutput, chunk);
          } catch {
            finalOutput = void 0;
            finalOutputSupported = false;
          }
        }
      }
    } catch (e) {
      await runManager?.handleChainError(e);
      throw e;
    }
    await runManager?.handleChainEnd(finalOutput ?? {});
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/runnables/history.js
var RunnableWithMessageHistory = class extends RunnableBinding {
  runnable;
  inputMessagesKey;
  outputMessagesKey;
  historyMessagesKey;
  getMessageHistory;
  constructor(fields) {
    let historyChain = RunnableLambda.from((input, options) => this._enterHistory(input, options ?? {})).withConfig({ runName: "loadHistory" });
    const messagesKey = fields.historyMessagesKey ?? fields.inputMessagesKey;
    if (messagesKey) historyChain = RunnablePassthrough.assign({ [messagesKey]: historyChain }).withConfig({ runName: "insertHistory" });
    const bound = historyChain.pipe(fields.runnable.withListeners({ onEnd: (run, config3) => this._exitHistory(run, config3 ?? {}) })).withConfig({ runName: "RunnableWithMessageHistory" });
    const config2 = fields.config ?? {};
    super({
      ...fields,
      config: config2,
      bound
    });
    this.runnable = fields.runnable;
    this.getMessageHistory = fields.getMessageHistory;
    this.inputMessagesKey = fields.inputMessagesKey;
    this.outputMessagesKey = fields.outputMessagesKey;
    this.historyMessagesKey = fields.historyMessagesKey;
  }
  _getInputMessages(inputValue) {
    let parsedInputValue;
    if (typeof inputValue === "object" && !Array.isArray(inputValue) && !isBaseMessage(inputValue)) {
      let key;
      if (this.inputMessagesKey) key = this.inputMessagesKey;
      else if (Object.keys(inputValue).length === 1) key = Object.keys(inputValue)[0];
      else key = "input";
      if (Array.isArray(inputValue[key]) && Array.isArray(inputValue[key][0])) parsedInputValue = inputValue[key][0];
      else parsedInputValue = inputValue[key];
    } else parsedInputValue = inputValue;
    if (typeof parsedInputValue === "string") return [new HumanMessage(parsedInputValue)];
    else if (Array.isArray(parsedInputValue)) return parsedInputValue;
    else if (isBaseMessage(parsedInputValue)) return [parsedInputValue];
    else throw new Error(`Expected a string, BaseMessage, or array of BaseMessages.
Got ${JSON.stringify(parsedInputValue, null, 2)}`);
  }
  _getOutputMessages(outputValue) {
    let parsedOutputValue;
    if (!Array.isArray(outputValue) && !isBaseMessage(outputValue) && typeof outputValue !== "string") {
      let key;
      if (this.outputMessagesKey !== void 0) key = this.outputMessagesKey;
      else if (Object.keys(outputValue).length === 1) key = Object.keys(outputValue)[0];
      else key = "output";
      if (outputValue.generations !== void 0) parsedOutputValue = outputValue.generations[0][0].message;
      else parsedOutputValue = outputValue[key];
    } else parsedOutputValue = outputValue;
    if (typeof parsedOutputValue === "string") return [new AIMessage(parsedOutputValue)];
    else if (Array.isArray(parsedOutputValue)) return parsedOutputValue;
    else if (isBaseMessage(parsedOutputValue)) return [parsedOutputValue];
    else throw new Error(`Expected a string, BaseMessage, or array of BaseMessages. Received: ${JSON.stringify(parsedOutputValue, null, 2)}`);
  }
  async _enterHistory(input, kwargs) {
    const messages = await (kwargs?.configurable?.messageHistory).getMessages();
    if (this.historyMessagesKey === void 0) return messages.concat(this._getInputMessages(input));
    return messages;
  }
  async _exitHistory(run, config2) {
    const history = config2.configurable?.messageHistory;
    let inputs;
    if (Array.isArray(run.inputs) && Array.isArray(run.inputs[0])) inputs = run.inputs[0];
    else inputs = run.inputs;
    let inputMessages = this._getInputMessages(inputs);
    if (this.historyMessagesKey === void 0) {
      const existingMessages = await history.getMessages();
      inputMessages = inputMessages.slice(existingMessages.length);
    }
    const outputValue = run.outputs;
    if (!outputValue) throw new Error(`Output values from 'Run' undefined. Run: ${JSON.stringify(run, null, 2)}`);
    const outputMessages = this._getOutputMessages(outputValue);
    await history.addMessages([...inputMessages, ...outputMessages]);
  }
  async _mergeConfig(...configs) {
    const config2 = await super._mergeConfig(...configs);
    if (!config2.configurable || !config2.configurable.sessionId) {
      const exampleInput = { [this.inputMessagesKey ?? "input"]: "foo" };
      throw new Error(`sessionId is required. Pass it in as part of the config argument to .invoke() or .stream()
eg. chain.invoke(${JSON.stringify(exampleInput)}, ${JSON.stringify({ configurable: { sessionId: "123" } })})`);
    }
    const { sessionId } = config2.configurable;
    config2.configurable.messageHistory = await this.getMessageHistory(sessionId);
    return config2;
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/runnables/index.js
var runnables_exports = __exportAll({
  RouterRunnable: () => RouterRunnable,
  Runnable: () => Runnable,
  RunnableAssign: () => RunnableAssign,
  RunnableBinding: () => RunnableBinding,
  RunnableBranch: () => RunnableBranch,
  RunnableEach: () => RunnableEach,
  RunnableLambda: () => RunnableLambda,
  RunnableMap: () => RunnableMap,
  RunnableParallel: () => RunnableParallel,
  RunnablePassthrough: () => RunnablePassthrough,
  RunnablePick: () => RunnablePick,
  RunnableRetry: () => RunnableRetry,
  RunnableSequence: () => RunnableSequence,
  RunnableToolLike: () => RunnableToolLike,
  RunnableWithFallbacks: () => RunnableWithFallbacks,
  RunnableWithMessageHistory: () => RunnableWithMessageHistory,
  _coerceToRunnable: () => _coerceToRunnable,
  ensureConfig: () => ensureConfig,
  getCallbackManagerForConfig: () => getCallbackManagerForConfig,
  mergeConfigs: () => mergeConfigs,
  patchConfig: () => patchConfig,
  pickRunnableConfigKeys: () => pickRunnableConfigKeys,
  raceWithSignal: () => raceWithSignal
});

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/base.js
var BaseLLMOutputParser = class extends Runnable {
  /**
  * Parses the result of an LLM call with a given prompt. By default, it
  * simply calls `parseResult`.
  * @param generations The generations from an LLM call.
  * @param _prompt The prompt used in the LLM call.
  * @param callbacks Optional callbacks.
  * @returns A promise of the parsed output.
  */
  parseResultWithPrompt(generations, _prompt, callbacks) {
    return this.parseResult(generations, callbacks);
  }
  _baseMessageToString(message) {
    return typeof message.content === "string" ? message.content : this._baseMessageContentToString(message.content);
  }
  _baseMessageContentToString(content) {
    return JSON.stringify(content);
  }
  /**
  * Calls the parser with a given input and optional configuration options.
  * If the input is a string, it creates a generation with the input as
  * text and calls `parseResult`. If the input is a `BaseMessage`, it
  * creates a generation with the input as a message and the content of the
  * input as text, and then calls `parseResult`.
  * @param input The input to the parser, which can be a string or a `BaseMessage`.
  * @param options Optional configuration options.
  * @returns A promise of the parsed output.
  */
  async invoke(input, options) {
    if (typeof input === "string") return this._callWithConfig(async (input2, options2) => this.parseResult([{ text: input2 }], options2?.callbacks), input, {
      ...options,
      runType: "parser"
    });
    else return this._callWithConfig(async (input2, options2) => this.parseResult([{
      message: input2,
      text: this._baseMessageToString(input2)
    }], options2?.callbacks), input, {
      ...options,
      runType: "parser"
    });
  }
};
var BaseOutputParser = class extends BaseLLMOutputParser {
  parseResult(generations, callbacks) {
    return this.parse(generations[0].text, callbacks);
  }
  async parseWithPrompt(text, _prompt, callbacks) {
    return this.parse(text, callbacks);
  }
  /**
  * Return the string type key uniquely identifying this class of parser
  */
  _type() {
    throw new Error("_type not implemented");
  }
};
var OutputParserException = class extends Error {
  llmOutput;
  observation;
  sendToLLM;
  constructor(message, llmOutput, observation, sendToLLM = false) {
    super(message);
    this.llmOutput = llmOutput;
    this.observation = observation;
    this.sendToLLM = sendToLLM;
    if (sendToLLM) {
      if (observation === void 0 || llmOutput === void 0) throw new Error("Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true");
    }
    addLangChainErrorFields(this, "OUTPUT_PARSING_FAILURE");
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/transform.js
var BaseTransformOutputParser = class extends BaseOutputParser {
  async *_transform(inputGenerator) {
    for await (const chunk of inputGenerator) if (typeof chunk === "string") yield this.parseResult([{ text: chunk }]);
    else yield this.parseResult([{
      message: chunk,
      text: this._baseMessageToString(chunk)
    }]);
  }
  /**
  * Transforms an asynchronous generator of input into an asynchronous
  * generator of parsed output.
  * @param inputGenerator An asynchronous generator of input.
  * @param options A configuration object.
  * @returns An asynchronous generator of parsed output.
  */
  async *transform(inputGenerator, options) {
    yield* this._transformStreamWithConfig(inputGenerator, this._transform.bind(this), {
      ...options,
      runType: "parser"
    });
  }
};
var BaseCumulativeTransformOutputParser = class extends BaseTransformOutputParser {
  diff = false;
  constructor(fields) {
    super(fields);
    this.diff = fields?.diff ?? this.diff;
  }
  async *_transform(inputGenerator) {
    let prevParsed;
    let accGen;
    for await (const chunk of inputGenerator) {
      if (typeof chunk !== "string" && typeof chunk.content !== "string") throw new Error("Cannot handle non-string output.");
      let chunkGen;
      if (isBaseMessageChunk(chunk)) {
        if (typeof chunk.content !== "string") throw new Error("Cannot handle non-string message output.");
        chunkGen = new ChatGenerationChunk({
          message: chunk,
          text: chunk.content
        });
      } else if (isBaseMessage(chunk)) {
        if (typeof chunk.content !== "string") throw new Error("Cannot handle non-string message output.");
        chunkGen = new ChatGenerationChunk({
          message: convertToChunk(chunk),
          text: chunk.content
        });
      } else chunkGen = new GenerationChunk({ text: chunk });
      if (accGen === void 0) accGen = chunkGen;
      else accGen = accGen.concat(chunkGen);
      const parsed = await this.parsePartialResult([accGen]);
      if (parsed !== void 0 && parsed !== null && !deepCompareStrict(parsed, prevParsed)) {
        if (this.diff) yield this._diff(prevParsed, parsed);
        else yield parsed;
        prevParsed = parsed;
      }
    }
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/bytes.js
var BytesOutputParser = class extends BaseTransformOutputParser {
  static lc_name() {
    return "BytesOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "bytes"
  ];
  lc_serializable = true;
  textEncoder = new TextEncoder();
  parse(text) {
    return Promise.resolve(this.textEncoder.encode(text));
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/list.js
var ListOutputParser = class extends BaseTransformOutputParser {
  re;
  async *_transform(inputGenerator) {
    let buffer = "";
    for await (const input of inputGenerator) {
      if (typeof input === "string") buffer += input;
      else buffer += input.content;
      if (!this.re) {
        const parts = await this.parse(buffer);
        if (parts.length > 1) {
          for (const part of parts.slice(0, -1)) yield [part];
          buffer = parts[parts.length - 1];
        }
      } else {
        const matches = [...buffer.matchAll(this.re)];
        if (matches.length > 1) {
          let doneIdx = 0;
          for (const match of matches.slice(0, -1)) {
            yield [match[1]];
            doneIdx += (match.index ?? 0) + match[0].length;
          }
          buffer = buffer.slice(doneIdx);
        }
      }
    }
    for (const part of await this.parse(buffer)) yield [part];
  }
};
var CommaSeparatedListOutputParser = class extends ListOutputParser {
  static lc_name() {
    return "CommaSeparatedListOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "list"
  ];
  lc_serializable = true;
  /**
  * Parses the given text into an array of strings, using a comma as the
  * separator. If the parsing fails, throws an OutputParserException.
  * @param text The text to parse.
  * @returns An array of strings obtained by splitting the input text at each comma.
  */
  async parse(text) {
    try {
      return text.trim().split(",").map((s) => s.trim());
    } catch {
      throw new OutputParserException(`Could not parse output: ${text}`, text);
    }
  }
  /**
  * Provides instructions on the expected format of the response for the
  * CommaSeparatedListOutputParser.
  * @returns A string containing instructions on the expected format of the response.
  */
  getFormatInstructions() {
    return `Your response should be a list of comma separated values, eg: \`foo, bar, baz\``;
  }
};
var CustomListOutputParser = class extends ListOutputParser {
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "list"
  ];
  length;
  separator;
  constructor({ length, separator }) {
    super(...arguments);
    this.length = length;
    this.separator = separator || ",";
  }
  /**
  * Parses the given text into an array of strings, using the specified
  * separator. If the parsing fails or the number of items in the list
  * doesn't match the expected length, throws an OutputParserException.
  * @param text The text to parse.
  * @returns An array of strings obtained by splitting the input text at each occurrence of the specified separator.
  */
  async parse(text) {
    try {
      const items = text.trim().split(this.separator).map((s) => s.trim());
      if (this.length !== void 0 && items.length !== this.length) throw new OutputParserException(`Incorrect number of items. Expected ${this.length}, got ${items.length}.`);
      return items;
    } catch (e) {
      if (Object.getPrototypeOf(e) === OutputParserException.prototype) throw e;
      throw new OutputParserException(`Could not parse output: ${text}`);
    }
  }
  /**
  * Provides instructions on the expected format of the response for the
  * CustomListOutputParser, including the number of items and the
  * separator.
  * @returns A string containing instructions on the expected format of the response.
  */
  getFormatInstructions() {
    return `Your response should be a list of ${this.length === void 0 ? "" : `${this.length} `}items separated by "${this.separator}" (eg: \`foo${this.separator} bar${this.separator} baz\`)`;
  }
};
var NumberedListOutputParser = class extends ListOutputParser {
  static lc_name() {
    return "NumberedListOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "list"
  ];
  lc_serializable = true;
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  re = /\d+\.\s([^\n]+)/g;
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m) => m[1]);
  }
};
var MarkdownListOutputParser = class extends ListOutputParser {
  static lc_name() {
    return "NumberedListOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "list"
  ];
  lc_serializable = true;
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  re = /^\s*[-*]\s([^\n]+)$/gm;
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m) => m[1]);
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/string.js
var StringOutputParser = class extends BaseTransformOutputParser {
  static lc_name() {
    return "StrOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "string"
  ];
  lc_serializable = true;
  /**
  * Parses a string output from an LLM call. This method is meant to be
  * implemented by subclasses to define how a string output from an LLM
  * should be parsed.
  * @param text The string output from an LLM call.
  * @param callbacks Optional callbacks.
  * @returns A promise of the parsed output.
  */
  parse(text) {
    return Promise.resolve(text);
  }
  getFormatInstructions() {
    return "";
  }
  _textContentToString(content) {
    return content.text;
  }
  _imageUrlContentToString(_content) {
    throw new Error(`Cannot coerce a multimodal "image_url" message part into a string.`);
  }
  _messageContentToString(content) {
    switch (content.type) {
      case "text":
      case "text_delta":
        if ("text" in content) return this._textContentToString(content);
        break;
      case "image_url":
        if ("image_url" in content) return this._imageUrlContentToString(content);
        break;
      case "reasoning":
      case "thinking":
      case "redacted_thinking":
        return "";
      default:
        throw new Error(`Cannot coerce "${content.type}" message part into a string.`);
    }
    throw new Error(`Invalid content type: ${content.type}`);
  }
  _baseMessageContentToString(content) {
    return content.reduce((acc, item) => acc + this._messageContentToString(item), "");
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/structured.js
var StructuredOutputParser = class extends BaseOutputParser {
  static lc_name() {
    return "StructuredOutputParser";
  }
  lc_namespace = [
    "langchain",
    "output_parsers",
    "structured"
  ];
  toJSON() {
    return this.toJSONNotImplemented();
  }
  constructor(schema) {
    super(schema);
    this.schema = schema;
  }
  /**
  * Creates a new StructuredOutputParser from a Zod schema.
  * @param schema The Zod schema which the output should match
  * @returns A new instance of StructuredOutputParser.
  */
  static fromZodSchema(schema) {
    return new this(schema);
  }
  /**
  * Creates a new StructuredOutputParser from a set of names and
  * descriptions.
  * @param schemas An object where each key is a name and each value is a description
  * @returns A new instance of StructuredOutputParser.
  */
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
  /**
  * Returns a markdown code snippet with a JSON object formatted according
  * to the schema.
  * @param options Optional. The options for formatting the instructions
  * @returns A markdown code snippet with a JSON object formatted according to the schema.
  */
  getFormatInstructions() {
    return `You must format your output as a JSON value that adheres to a given "JSON Schema" instance.

"JSON Schema" is a declarative language that allows you to annotate and validate JSON documents.

For example, the example "JSON Schema" instance {{"properties": {{"foo": {{"description": "a list of test words", "type": "array", "items": {{"type": "string"}}}}}}, "required": ["foo"]}}
would match an object with one required property, "foo". The "type" property specifies "foo" must be an "array", and the "description" property semantically describes it as "a list of test words". The items within "foo" must be strings.
Thus, the object {{"foo": ["bar", "baz"]}} is a well-formatted instance of this example "JSON Schema". The object {{"properties": {{"foo": ["bar", "baz"]}}}} is not well-formatted.

Your output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match the schema exactly and there are no trailing commas!

Here is the JSON Schema instance your output must adhere to. Include the enclosing markdown codeblock:
\`\`\`json
${JSON.stringify(toJsonSchema(this.schema))}
\`\`\`
`;
  }
  /**
  * Parses the given text according to the schema.
  * @param text The text to parse
  * @returns The parsed output.
  */
  async parse(text) {
    try {
      const trimmedText = text.trim();
      const escapedJson = (trimmedText.match(/^```(?:json)?\s*([\s\S]*?)```/)?.[1] || trimmedText.match(/```json\s*([\s\S]*?)```/)?.[1] || trimmedText).replace(/"([^"\\]*(\\.[^"\\]*)*)"/g, (_match, capturedGroup) => {
        return `"${capturedGroup.replace(/\n/g, "\\n")}"`;
      }).replace(/\n/g, "");
      return await interopParseAsync(this.schema, JSON.parse(escapedJson));
    } catch (e) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e}`, text);
    }
  }
};
var JsonMarkdownStructuredOutputParser = class extends StructuredOutputParser {
  static lc_name() {
    return "JsonMarkdownStructuredOutputParser";
  }
  getFormatInstructions(options) {
    const interpolationDepth = options?.interpolationDepth ?? 1;
    if (interpolationDepth < 1) throw new Error("f string interpolation depth must be at least 1");
    return `Return a markdown code snippet with a JSON object formatted to look like:
\`\`\`json
${this._schemaToInstruction(toJsonSchema(this.schema)).replaceAll("{", "{".repeat(interpolationDepth)).replaceAll("}", "}".repeat(interpolationDepth))}
\`\`\``;
  }
  _schemaToInstruction(schemaInput, indent = 2) {
    const schema = schemaInput;
    if ("type" in schema) {
      let nullable2 = false;
      let type;
      if (Array.isArray(schema.type)) {
        const nullIdx = schema.type.findIndex((type2) => type2 === "null");
        if (nullIdx !== -1) {
          nullable2 = true;
          schema.type.splice(nullIdx, 1);
        }
        type = schema.type.join(" | ");
      } else type = schema.type;
      if (schema.type === "object" && schema.properties) {
        const description2 = schema.description ? ` // ${schema.description}` : "";
        return `{
${Object.entries(schema.properties).map(([key, value]) => {
          const isOptional = schema.required?.includes(key) ? "" : " (optional)";
          return `${" ".repeat(indent)}"${key}": ${this._schemaToInstruction(value, indent + 2)}${isOptional}`;
        }).join("\n")}
${" ".repeat(indent - 2)}}${description2}`;
      }
      if (schema.type === "array" && schema.items) {
        const description2 = schema.description ? ` // ${schema.description}` : "";
        return `array[
${" ".repeat(indent)}${this._schemaToInstruction(schema.items, indent + 2)}
${" ".repeat(indent - 2)}] ${description2}`;
      }
      const isNullable2 = nullable2 ? " (nullable)" : "";
      const description = schema.description ? ` // ${schema.description}` : "";
      return `${type}${description}${isNullable2}`;
    }
    if ("anyOf" in schema) return schema.anyOf.map((s) => this._schemaToInstruction(s, indent)).join(`
${" ".repeat(indent - 2)}`);
    throw new Error("unsupported schema type");
  }
  static fromZodSchema(schema) {
    return new this(schema);
  }
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
};
var AsymmetricStructuredOutputParser = class extends BaseOutputParser {
  structuredInputParser;
  constructor({ inputSchema }) {
    super(...arguments);
    this.structuredInputParser = new JsonMarkdownStructuredOutputParser(inputSchema);
  }
  async parse(text) {
    let parsedInput;
    try {
      parsedInput = await this.structuredInputParser.parse(text);
    } catch (e) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e}`, text);
    }
    return this.outputProcessor(parsedInput);
  }
  getFormatInstructions() {
    return this.structuredInputParser.getFormatInstructions();
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/utils/json_patch.js
var json_patch_exports = __exportAll({
  applyPatch: () => applyPatch,
  compare: () => compare
});

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/json.js
var JsonOutputParser = class extends BaseCumulativeTransformOutputParser {
  static lc_name() {
    return "JsonOutputParser";
  }
  lc_namespace = ["langchain_core", "output_parsers"];
  lc_serializable = true;
  /** @internal */
  _concatOutputChunks(first, second) {
    if (this.diff) return super._concatOutputChunks(first, second);
    return second;
  }
  _diff(prev, next) {
    if (!next) return;
    if (!prev) return [{
      op: "replace",
      path: "",
      value: next
    }];
    return compare(prev, next);
  }
  async parsePartialResult(generations) {
    return parseJsonMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseJsonMarkdown(text, JSON.parse);
  }
  getFormatInstructions() {
    return "";
  }
  /**
  * Extracts text content from a message for JSON parsing.
  * Uses the message's `.text` accessor which properly handles both
  * string content and ContentBlock[] arrays (extracting text from text blocks).
  * @param message The message to extract text from
  * @returns The text content of the message
  */
  _baseMessageToString(message) {
    return message.text;
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/utils/sax-js/sax.js
var initializeSax = function() {
  const sax2 = {};
  sax2.parser = function(strict, opt) {
    return new SAXParser(strict, opt);
  };
  sax2.SAXParser = SAXParser;
  sax2.SAXStream = SAXStream;
  sax2.createStream = createStream;
  sax2.MAX_BUFFER_LENGTH = 64 * 1024;
  const buffers = [
    "comment",
    "sgmlDecl",
    "textNode",
    "tagName",
    "doctype",
    "procInstName",
    "procInstBody",
    "entity",
    "attribName",
    "attribValue",
    "cdata",
    "script"
  ];
  sax2.EVENTS = [
    "text",
    "processinginstruction",
    "sgmldeclaration",
    "doctype",
    "comment",
    "opentagstart",
    "attribute",
    "opentag",
    "closetag",
    "opencdata",
    "cdata",
    "closecdata",
    "error",
    "end",
    "ready",
    "script",
    "opennamespace",
    "closenamespace"
  ];
  function SAXParser(strict, opt) {
    if (!(this instanceof SAXParser)) return new SAXParser(strict, opt);
    var parser = this;
    clearBuffers(parser);
    parser.q = parser.c = "";
    parser.bufferCheckPosition = sax2.MAX_BUFFER_LENGTH;
    parser.opt = opt || {};
    parser.opt.lowercase = parser.opt.lowercase || parser.opt.lowercasetags;
    parser.looseCase = parser.opt.lowercase ? "toLowerCase" : "toUpperCase";
    parser.tags = [];
    parser.closed = parser.closedRoot = parser.sawRoot = false;
    parser.tag = parser.error = null;
    parser.strict = !!strict;
    parser.noscript = !!(strict || parser.opt.noscript);
    parser.state = S.BEGIN;
    parser.strictEntities = parser.opt.strictEntities;
    parser.ENTITIES = parser.strictEntities ? Object.create(sax2.XML_ENTITIES) : Object.create(sax2.ENTITIES);
    parser.attribList = [];
    if (parser.opt.xmlns) parser.ns = Object.create(rootNS);
    parser.trackPosition = parser.opt.position !== false;
    if (parser.trackPosition) parser.position = parser.line = parser.column = 0;
    emit(parser, "onready");
  }
  if (!Object.create) Object.create = function(o) {
    function F() {
    }
    F.prototype = o;
    return new F();
  };
  if (!Object.keys) Object.keys = function(o) {
    var a = [];
    for (var i in o) if (o.hasOwnProperty(i)) a.push(i);
    return a;
  };
  function checkBufferLength(parser) {
    var maxAllowed = Math.max(sax2.MAX_BUFFER_LENGTH, 10);
    var maxActual = 0;
    for (var i = 0, l = buffers.length; i < l; i++) {
      var len = parser[buffers[i]].length;
      if (len > maxAllowed) switch (buffers[i]) {
        case "textNode":
          closeText(parser);
          break;
        case "cdata":
          emitNode(parser, "oncdata", parser.cdata);
          parser.cdata = "";
          break;
        case "script":
          emitNode(parser, "onscript", parser.script);
          parser.script = "";
          break;
        default:
          error(parser, "Max buffer length exceeded: " + buffers[i]);
      }
      maxActual = Math.max(maxActual, len);
    }
    parser.bufferCheckPosition = sax2.MAX_BUFFER_LENGTH - maxActual + parser.position;
  }
  function clearBuffers(parser) {
    for (var i = 0, l = buffers.length; i < l; i++) parser[buffers[i]] = "";
  }
  function flushBuffers(parser) {
    closeText(parser);
    if (parser.cdata !== "") {
      emitNode(parser, "oncdata", parser.cdata);
      parser.cdata = "";
    }
    if (parser.script !== "") {
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
  }
  SAXParser.prototype = {
    end: function() {
      end(this);
    },
    write,
    resume: function() {
      this.error = null;
      return this;
    },
    close: function() {
      return this.write(null);
    },
    flush: function() {
      flushBuffers(this);
    }
  };
  var Stream2 = ReadableStream;
  if (!Stream2) Stream2 = function() {
  };
  var streamWraps = sax2.EVENTS.filter(function(ev) {
    return ev !== "error" && ev !== "end";
  });
  function createStream(strict, opt) {
    return new SAXStream(strict, opt);
  }
  function SAXStream(strict, opt) {
    if (!(this instanceof SAXStream)) return new SAXStream(strict, opt);
    Stream2.apply(this);
    this._parser = new SAXParser(strict, opt);
    this.writable = true;
    this.readable = true;
    var me = this;
    this._parser.onend = function() {
      me.emit("end");
    };
    this._parser.onerror = function(er) {
      me.emit("error", er);
      me._parser.error = null;
    };
    this._decoder = null;
    streamWraps.forEach(function(ev) {
      Object.defineProperty(me, "on" + ev, {
        get: function() {
          return me._parser["on" + ev];
        },
        set: function(h) {
          if (!h) {
            me.removeAllListeners(ev);
            me._parser["on" + ev] = h;
            return h;
          }
          me.on(ev, h);
        },
        enumerable: true,
        configurable: false
      });
    });
  }
  SAXStream.prototype = Object.create(Stream2.prototype, { constructor: { value: SAXStream } });
  SAXStream.prototype.write = function(data) {
    this._parser.write(data.toString());
    this.emit("data", data);
    return true;
  };
  SAXStream.prototype.end = function(chunk) {
    if (chunk && chunk.length) this.write(chunk);
    this._parser.end();
    return true;
  };
  SAXStream.prototype.on = function(ev, handler) {
    var me = this;
    if (!me._parser["on" + ev] && streamWraps.indexOf(ev) !== -1) me._parser["on" + ev] = function() {
      var args = arguments.length === 1 ? [arguments[0]] : Array.apply(null, arguments);
      args.splice(0, 0, ev);
      me.emit.apply(me, args);
    };
    return Stream2.prototype.on.call(me, ev, handler);
  };
  var CDATA = "[CDATA[";
  var DOCTYPE = "DOCTYPE";
  var XML_NAMESPACE = "http://www.w3.org/XML/1998/namespace";
  var XMLNS_NAMESPACE = "http://www.w3.org/2000/xmlns/";
  var rootNS = {
    xml: XML_NAMESPACE,
    xmlns: XMLNS_NAMESPACE
  };
  var nameStart = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var nameBody = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  var entityStart = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var entityBody = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  function isWhitespace(c) {
    return c === " " || c === "\n" || c === "\r" || c === "	";
  }
  function isQuote(c) {
    return c === '"' || c === "'";
  }
  function isAttribEnd(c) {
    return c === ">" || isWhitespace(c);
  }
  function isMatch(regex, c) {
    return regex.test(c);
  }
  function notMatch(regex, c) {
    return !isMatch(regex, c);
  }
  var S = 0;
  sax2.STATE = {
    BEGIN: S++,
    BEGIN_WHITESPACE: S++,
    TEXT: S++,
    TEXT_ENTITY: S++,
    OPEN_WAKA: S++,
    SGML_DECL: S++,
    SGML_DECL_QUOTED: S++,
    DOCTYPE: S++,
    DOCTYPE_QUOTED: S++,
    DOCTYPE_DTD: S++,
    DOCTYPE_DTD_QUOTED: S++,
    COMMENT_STARTING: S++,
    COMMENT: S++,
    COMMENT_ENDING: S++,
    COMMENT_ENDED: S++,
    CDATA: S++,
    CDATA_ENDING: S++,
    CDATA_ENDING_2: S++,
    PROC_INST: S++,
    PROC_INST_BODY: S++,
    PROC_INST_ENDING: S++,
    OPEN_TAG: S++,
    OPEN_TAG_SLASH: S++,
    ATTRIB: S++,
    ATTRIB_NAME: S++,
    ATTRIB_NAME_SAW_WHITE: S++,
    ATTRIB_VALUE: S++,
    ATTRIB_VALUE_QUOTED: S++,
    ATTRIB_VALUE_CLOSED: S++,
    ATTRIB_VALUE_UNQUOTED: S++,
    ATTRIB_VALUE_ENTITY_Q: S++,
    ATTRIB_VALUE_ENTITY_U: S++,
    CLOSE_TAG: S++,
    CLOSE_TAG_SAW_WHITE: S++,
    SCRIPT: S++,
    SCRIPT_ENDING: S++
  };
  sax2.XML_ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'"
  };
  sax2.ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'",
    AElig: 198,
    Aacute: 193,
    Acirc: 194,
    Agrave: 192,
    Aring: 197,
    Atilde: 195,
    Auml: 196,
    Ccedil: 199,
    ETH: 208,
    Eacute: 201,
    Ecirc: 202,
    Egrave: 200,
    Euml: 203,
    Iacute: 205,
    Icirc: 206,
    Igrave: 204,
    Iuml: 207,
    Ntilde: 209,
    Oacute: 211,
    Ocirc: 212,
    Ograve: 210,
    Oslash: 216,
    Otilde: 213,
    Ouml: 214,
    THORN: 222,
    Uacute: 218,
    Ucirc: 219,
    Ugrave: 217,
    Uuml: 220,
    Yacute: 221,
    aacute: 225,
    acirc: 226,
    aelig: 230,
    agrave: 224,
    aring: 229,
    atilde: 227,
    auml: 228,
    ccedil: 231,
    eacute: 233,
    ecirc: 234,
    egrave: 232,
    eth: 240,
    euml: 235,
    iacute: 237,
    icirc: 238,
    igrave: 236,
    iuml: 239,
    ntilde: 241,
    oacute: 243,
    ocirc: 244,
    ograve: 242,
    oslash: 248,
    otilde: 245,
    ouml: 246,
    szlig: 223,
    thorn: 254,
    uacute: 250,
    ucirc: 251,
    ugrave: 249,
    uuml: 252,
    yacute: 253,
    yuml: 255,
    copy: 169,
    reg: 174,
    nbsp: 160,
    iexcl: 161,
    cent: 162,
    pound: 163,
    curren: 164,
    yen: 165,
    brvbar: 166,
    sect: 167,
    uml: 168,
    ordf: 170,
    laquo: 171,
    not: 172,
    shy: 173,
    macr: 175,
    deg: 176,
    plusmn: 177,
    sup1: 185,
    sup2: 178,
    sup3: 179,
    acute: 180,
    micro: 181,
    para: 182,
    middot: 183,
    cedil: 184,
    ordm: 186,
    raquo: 187,
    frac14: 188,
    frac12: 189,
    frac34: 190,
    iquest: 191,
    times: 215,
    divide: 247,
    OElig: 338,
    oelig: 339,
    Scaron: 352,
    scaron: 353,
    Yuml: 376,
    fnof: 402,
    circ: 710,
    tilde: 732,
    Alpha: 913,
    Beta: 914,
    Gamma: 915,
    Delta: 916,
    Epsilon: 917,
    Zeta: 918,
    Eta: 919,
    Theta: 920,
    Iota: 921,
    Kappa: 922,
    Lambda: 923,
    Mu: 924,
    Nu: 925,
    Xi: 926,
    Omicron: 927,
    Pi: 928,
    Rho: 929,
    Sigma: 931,
    Tau: 932,
    Upsilon: 933,
    Phi: 934,
    Chi: 935,
    Psi: 936,
    Omega: 937,
    alpha: 945,
    beta: 946,
    gamma: 947,
    delta: 948,
    epsilon: 949,
    zeta: 950,
    eta: 951,
    theta: 952,
    iota: 953,
    kappa: 954,
    lambda: 955,
    mu: 956,
    nu: 957,
    xi: 958,
    omicron: 959,
    pi: 960,
    rho: 961,
    sigmaf: 962,
    sigma: 963,
    tau: 964,
    upsilon: 965,
    phi: 966,
    chi: 967,
    psi: 968,
    omega: 969,
    thetasym: 977,
    upsih: 978,
    piv: 982,
    ensp: 8194,
    emsp: 8195,
    thinsp: 8201,
    zwnj: 8204,
    zwj: 8205,
    lrm: 8206,
    rlm: 8207,
    ndash: 8211,
    mdash: 8212,
    lsquo: 8216,
    rsquo: 8217,
    sbquo: 8218,
    ldquo: 8220,
    rdquo: 8221,
    bdquo: 8222,
    dagger: 8224,
    Dagger: 8225,
    bull: 8226,
    hellip: 8230,
    permil: 8240,
    prime: 8242,
    Prime: 8243,
    lsaquo: 8249,
    rsaquo: 8250,
    oline: 8254,
    frasl: 8260,
    euro: 8364,
    image: 8465,
    weierp: 8472,
    real: 8476,
    trade: 8482,
    alefsym: 8501,
    larr: 8592,
    uarr: 8593,
    rarr: 8594,
    darr: 8595,
    harr: 8596,
    crarr: 8629,
    lArr: 8656,
    uArr: 8657,
    rArr: 8658,
    dArr: 8659,
    hArr: 8660,
    forall: 8704,
    part: 8706,
    exist: 8707,
    empty: 8709,
    nabla: 8711,
    isin: 8712,
    notin: 8713,
    ni: 8715,
    prod: 8719,
    sum: 8721,
    minus: 8722,
    lowast: 8727,
    radic: 8730,
    prop: 8733,
    infin: 8734,
    ang: 8736,
    and: 8743,
    or: 8744,
    cap: 8745,
    cup: 8746,
    int: 8747,
    there4: 8756,
    sim: 8764,
    cong: 8773,
    asymp: 8776,
    ne: 8800,
    equiv: 8801,
    le: 8804,
    ge: 8805,
    sub: 8834,
    sup: 8835,
    nsub: 8836,
    sube: 8838,
    supe: 8839,
    oplus: 8853,
    otimes: 8855,
    perp: 8869,
    sdot: 8901,
    lceil: 8968,
    rceil: 8969,
    lfloor: 8970,
    rfloor: 8971,
    lang: 9001,
    rang: 9002,
    loz: 9674,
    spades: 9824,
    clubs: 9827,
    hearts: 9829,
    diams: 9830
  };
  Object.keys(sax2.ENTITIES).forEach(function(key) {
    var e = sax2.ENTITIES[key];
    var s2 = typeof e === "number" ? String.fromCharCode(e) : e;
    sax2.ENTITIES[key] = s2;
  });
  for (var s in sax2.STATE) sax2.STATE[sax2.STATE[s]] = s;
  S = sax2.STATE;
  function emit(parser, event, data) {
    parser[event] && parser[event](data);
  }
  function emitNode(parser, nodeType, data) {
    if (parser.textNode) closeText(parser);
    emit(parser, nodeType, data);
  }
  function closeText(parser) {
    parser.textNode = textopts(parser.opt, parser.textNode);
    if (parser.textNode) emit(parser, "ontext", parser.textNode);
    parser.textNode = "";
  }
  function textopts(opt, text) {
    if (opt.trim) text = text.trim();
    if (opt.normalize) text = text.replace(/\s+/g, " ");
    return text;
  }
  function error(parser, er) {
    closeText(parser);
    if (parser.trackPosition) er += "\nLine: " + parser.line + "\nColumn: " + parser.column + "\nChar: " + parser.c;
    er = new Error(er);
    parser.error = er;
    emit(parser, "onerror", er);
    return parser;
  }
  function end(parser) {
    if (parser.sawRoot && !parser.closedRoot) strictFail(parser, "Unclosed root tag");
    if (parser.state !== S.BEGIN && parser.state !== S.BEGIN_WHITESPACE && parser.state !== S.TEXT) error(parser, "Unexpected end");
    closeText(parser);
    parser.c = "";
    parser.closed = true;
    emit(parser, "onend");
    SAXParser.call(parser, parser.strict, parser.opt);
    return parser;
  }
  function strictFail(parser, message) {
    if (typeof parser !== "object" || !(parser instanceof SAXParser)) throw new Error("bad call to strictFail");
    if (parser.strict) error(parser, message);
  }
  function newTag(parser) {
    if (!parser.strict) parser.tagName = parser.tagName[parser.looseCase]();
    var parent = parser.tags[parser.tags.length - 1] || parser;
    var tag = parser.tag = {
      name: parser.tagName,
      attributes: {}
    };
    if (parser.opt.xmlns) tag.ns = parent.ns;
    parser.attribList.length = 0;
    emitNode(parser, "onopentagstart", tag);
  }
  function qname(name, attribute) {
    var qualName = name.indexOf(":") < 0 ? ["", name] : name.split(":");
    var prefix = qualName[0];
    var local = qualName[1];
    if (attribute && name === "xmlns") {
      prefix = "xmlns";
      local = "";
    }
    return {
      prefix,
      local
    };
  }
  function attrib(parser) {
    if (!parser.strict) parser.attribName = parser.attribName[parser.looseCase]();
    if (parser.attribList.indexOf(parser.attribName) !== -1 || parser.tag.attributes.hasOwnProperty(parser.attribName)) {
      parser.attribName = parser.attribValue = "";
      return;
    }
    if (parser.opt.xmlns) {
      var qn = qname(parser.attribName, true);
      var prefix = qn.prefix;
      var local = qn.local;
      if (prefix === "xmlns") if (local === "xml" && parser.attribValue !== XML_NAMESPACE) strictFail(parser, "xml: prefix must be bound to " + XML_NAMESPACE + "\nActual: " + parser.attribValue);
      else if (local === "xmlns" && parser.attribValue !== XMLNS_NAMESPACE) strictFail(parser, "xmlns: prefix must be bound to " + XMLNS_NAMESPACE + "\nActual: " + parser.attribValue);
      else {
        var tag = parser.tag;
        var parent = parser.tags[parser.tags.length - 1] || parser;
        if (tag.ns === parent.ns) tag.ns = Object.create(parent.ns);
        tag.ns[local] = parser.attribValue;
      }
      parser.attribList.push([parser.attribName, parser.attribValue]);
    } else {
      parser.tag.attributes[parser.attribName] = parser.attribValue;
      emitNode(parser, "onattribute", {
        name: parser.attribName,
        value: parser.attribValue
      });
    }
    parser.attribName = parser.attribValue = "";
  }
  function openTag(parser, selfClosing) {
    if (parser.opt.xmlns) {
      var tag = parser.tag;
      var qn = qname(parser.tagName);
      tag.prefix = qn.prefix;
      tag.local = qn.local;
      tag.uri = tag.ns[qn.prefix] || "";
      if (tag.prefix && !tag.uri) {
        strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(parser.tagName));
        tag.uri = qn.prefix;
      }
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (tag.ns && parent.ns !== tag.ns) Object.keys(tag.ns).forEach(function(p) {
        emitNode(parser, "onopennamespace", {
          prefix: p,
          uri: tag.ns[p]
        });
      });
      for (var i = 0, l = parser.attribList.length; i < l; i++) {
        var nv = parser.attribList[i];
        var name = nv[0];
        var value = nv[1];
        var qualName = qname(name, true);
        var prefix = qualName.prefix;
        var local = qualName.local;
        var uri = prefix === "" ? "" : tag.ns[prefix] || "";
        var a = {
          name,
          value,
          prefix,
          local,
          uri
        };
        if (prefix && prefix !== "xmlns" && !uri) {
          strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(prefix));
          a.uri = prefix;
        }
        parser.tag.attributes[name] = a;
        emitNode(parser, "onattribute", a);
      }
      parser.attribList.length = 0;
    }
    parser.tag.isSelfClosing = !!selfClosing;
    parser.sawRoot = true;
    parser.tags.push(parser.tag);
    emitNode(parser, "onopentag", parser.tag);
    if (!selfClosing) {
      if (!parser.noscript && parser.tagName.toLowerCase() === "script") parser.state = S.SCRIPT;
      else parser.state = S.TEXT;
      parser.tag = null;
      parser.tagName = "";
    }
    parser.attribName = parser.attribValue = "";
    parser.attribList.length = 0;
  }
  function closeTag(parser) {
    if (!parser.tagName) {
      strictFail(parser, "Weird empty close tag.");
      parser.textNode += "</>";
      parser.state = S.TEXT;
      return;
    }
    if (parser.script) {
      if (parser.tagName !== "script") {
        parser.script += "</" + parser.tagName + ">";
        parser.tagName = "";
        parser.state = S.SCRIPT;
        return;
      }
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
    var t = parser.tags.length;
    var tagName = parser.tagName;
    if (!parser.strict) tagName = tagName[parser.looseCase]();
    var closeTo = tagName;
    while (t--) if (parser.tags[t].name !== closeTo) strictFail(parser, "Unexpected close tag");
    else break;
    if (t < 0) {
      strictFail(parser, "Unmatched closing tag: " + parser.tagName);
      parser.textNode += "</" + parser.tagName + ">";
      parser.state = S.TEXT;
      return;
    }
    parser.tagName = tagName;
    var s2 = parser.tags.length;
    while (s2-- > t) {
      var tag = parser.tag = parser.tags.pop();
      parser.tagName = parser.tag.name;
      emitNode(parser, "onclosetag", parser.tagName);
      var x = {};
      for (var i in tag.ns) x[i] = tag.ns[i];
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (parser.opt.xmlns && tag.ns !== parent.ns) Object.keys(tag.ns).forEach(function(p) {
        var n = tag.ns[p];
        emitNode(parser, "onclosenamespace", {
          prefix: p,
          uri: n
        });
      });
    }
    if (t === 0) parser.closedRoot = true;
    parser.tagName = parser.attribValue = parser.attribName = "";
    parser.attribList.length = 0;
    parser.state = S.TEXT;
  }
  function parseEntity(parser) {
    var entity = parser.entity;
    var entityLC = entity.toLowerCase();
    var num;
    var numStr = "";
    if (parser.ENTITIES[entity]) return parser.ENTITIES[entity];
    if (parser.ENTITIES[entityLC]) return parser.ENTITIES[entityLC];
    entity = entityLC;
    if (entity.charAt(0) === "#") if (entity.charAt(1) === "x") {
      entity = entity.slice(2);
      num = parseInt(entity, 16);
      numStr = num.toString(16);
    } else {
      entity = entity.slice(1);
      num = parseInt(entity, 10);
      numStr = num.toString(10);
    }
    entity = entity.replace(/^0+/, "");
    if (isNaN(num) || numStr.toLowerCase() !== entity) {
      strictFail(parser, "Invalid character entity");
      return "&" + parser.entity + ";";
    }
    return String.fromCodePoint(num);
  }
  function beginWhiteSpace(parser, c) {
    if (c === "<") {
      parser.state = S.OPEN_WAKA;
      parser.startTagPosition = parser.position;
    } else if (!isWhitespace(c)) {
      strictFail(parser, "Non-whitespace before first tag.");
      parser.textNode = c;
      parser.state = S.TEXT;
    }
  }
  function charAt(chunk, i) {
    var result = "";
    if (i < chunk.length) result = chunk.charAt(i);
    return result;
  }
  function write(chunk) {
    var parser = this;
    if (this.error) throw this.error;
    if (parser.closed) return error(parser, "Cannot write after close. Assign an onready handler.");
    if (chunk === null) return end(parser);
    if (typeof chunk === "object") chunk = chunk.toString();
    var i = 0;
    var c = "";
    while (true) {
      c = charAt(chunk, i++);
      parser.c = c;
      if (!c) break;
      if (parser.trackPosition) {
        parser.position++;
        if (c === "\n") {
          parser.line++;
          parser.column = 0;
        } else parser.column++;
      }
      switch (parser.state) {
        case S.BEGIN:
          parser.state = S.BEGIN_WHITESPACE;
          if (c === "\uFEFF") continue;
          beginWhiteSpace(parser, c);
          continue;
        case S.BEGIN_WHITESPACE:
          beginWhiteSpace(parser, c);
          continue;
        case S.TEXT:
          if (parser.sawRoot && !parser.closedRoot) {
            var starti = i - 1;
            while (c && c !== "<" && c !== "&") {
              c = charAt(chunk, i++);
              if (c && parser.trackPosition) {
                parser.position++;
                if (c === "\n") {
                  parser.line++;
                  parser.column = 0;
                } else parser.column++;
              }
            }
            parser.textNode += chunk.substring(starti, i - 1);
          }
          if (c === "<" && !(parser.sawRoot && parser.closedRoot && !parser.strict)) {
            parser.state = S.OPEN_WAKA;
            parser.startTagPosition = parser.position;
          } else {
            if (!isWhitespace(c) && (!parser.sawRoot || parser.closedRoot)) strictFail(parser, "Text data outside of root node.");
            if (c === "&") parser.state = S.TEXT_ENTITY;
            else parser.textNode += c;
          }
          continue;
        case S.SCRIPT:
          if (c === "<") parser.state = S.SCRIPT_ENDING;
          else parser.script += c;
          continue;
        case S.SCRIPT_ENDING:
          if (c === "/") parser.state = S.CLOSE_TAG;
          else {
            parser.script += "<" + c;
            parser.state = S.SCRIPT;
          }
          continue;
        case S.OPEN_WAKA:
          if (c === "!") {
            parser.state = S.SGML_DECL;
            parser.sgmlDecl = "";
          } else if (isWhitespace(c)) {
          } else if (isMatch(nameStart, c)) {
            parser.state = S.OPEN_TAG;
            parser.tagName = c;
          } else if (c === "/") {
            parser.state = S.CLOSE_TAG;
            parser.tagName = "";
          } else if (c === "?") {
            parser.state = S.PROC_INST;
            parser.procInstName = parser.procInstBody = "";
          } else {
            strictFail(parser, "Unencoded <");
            if (parser.startTagPosition + 1 < parser.position) {
              var pad = parser.position - parser.startTagPosition;
              c = new Array(pad).join(" ") + c;
            }
            parser.textNode += "<" + c;
            parser.state = S.TEXT;
          }
          continue;
        case S.SGML_DECL:
          if ((parser.sgmlDecl + c).toUpperCase() === CDATA) {
            emitNode(parser, "onopencdata");
            parser.state = S.CDATA;
            parser.sgmlDecl = "";
            parser.cdata = "";
          } else if (parser.sgmlDecl + c === "--") {
            parser.state = S.COMMENT;
            parser.comment = "";
            parser.sgmlDecl = "";
          } else if ((parser.sgmlDecl + c).toUpperCase() === DOCTYPE) {
            parser.state = S.DOCTYPE;
            if (parser.doctype || parser.sawRoot) strictFail(parser, "Inappropriately located doctype declaration");
            parser.doctype = "";
            parser.sgmlDecl = "";
          } else if (c === ">") {
            emitNode(parser, "onsgmldeclaration", parser.sgmlDecl);
            parser.sgmlDecl = "";
            parser.state = S.TEXT;
          } else if (isQuote(c)) {
            parser.state = S.SGML_DECL_QUOTED;
            parser.sgmlDecl += c;
          } else parser.sgmlDecl += c;
          continue;
        case S.SGML_DECL_QUOTED:
          if (c === parser.q) {
            parser.state = S.SGML_DECL;
            parser.q = "";
          }
          parser.sgmlDecl += c;
          continue;
        case S.DOCTYPE:
          if (c === ">") {
            parser.state = S.TEXT;
            emitNode(parser, "ondoctype", parser.doctype);
            parser.doctype = true;
          } else {
            parser.doctype += c;
            if (c === "[") parser.state = S.DOCTYPE_DTD;
            else if (isQuote(c)) {
              parser.state = S.DOCTYPE_QUOTED;
              parser.q = c;
            }
          }
          continue;
        case S.DOCTYPE_QUOTED:
          parser.doctype += c;
          if (c === parser.q) {
            parser.q = "";
            parser.state = S.DOCTYPE;
          }
          continue;
        case S.DOCTYPE_DTD:
          parser.doctype += c;
          if (c === "]") parser.state = S.DOCTYPE;
          else if (isQuote(c)) {
            parser.state = S.DOCTYPE_DTD_QUOTED;
            parser.q = c;
          }
          continue;
        case S.DOCTYPE_DTD_QUOTED:
          parser.doctype += c;
          if (c === parser.q) {
            parser.state = S.DOCTYPE_DTD;
            parser.q = "";
          }
          continue;
        case S.COMMENT:
          if (c === "-") parser.state = S.COMMENT_ENDING;
          else parser.comment += c;
          continue;
        case S.COMMENT_ENDING:
          if (c === "-") {
            parser.state = S.COMMENT_ENDED;
            parser.comment = textopts(parser.opt, parser.comment);
            if (parser.comment) emitNode(parser, "oncomment", parser.comment);
            parser.comment = "";
          } else {
            parser.comment += "-" + c;
            parser.state = S.COMMENT;
          }
          continue;
        case S.COMMENT_ENDED:
          if (c !== ">") {
            strictFail(parser, "Malformed comment");
            parser.comment += "--" + c;
            parser.state = S.COMMENT;
          } else parser.state = S.TEXT;
          continue;
        case S.CDATA:
          if (c === "]") parser.state = S.CDATA_ENDING;
          else parser.cdata += c;
          continue;
        case S.CDATA_ENDING:
          if (c === "]") parser.state = S.CDATA_ENDING_2;
          else {
            parser.cdata += "]" + c;
            parser.state = S.CDATA;
          }
          continue;
        case S.CDATA_ENDING_2:
          if (c === ">") {
            if (parser.cdata) emitNode(parser, "oncdata", parser.cdata);
            emitNode(parser, "onclosecdata");
            parser.cdata = "";
            parser.state = S.TEXT;
          } else if (c === "]") parser.cdata += "]";
          else {
            parser.cdata += "]]" + c;
            parser.state = S.CDATA;
          }
          continue;
        case S.PROC_INST:
          if (c === "?") parser.state = S.PROC_INST_ENDING;
          else if (isWhitespace(c)) parser.state = S.PROC_INST_BODY;
          else parser.procInstName += c;
          continue;
        case S.PROC_INST_BODY:
          if (!parser.procInstBody && isWhitespace(c)) continue;
          else if (c === "?") parser.state = S.PROC_INST_ENDING;
          else parser.procInstBody += c;
          continue;
        case S.PROC_INST_ENDING:
          if (c === ">") {
            emitNode(parser, "onprocessinginstruction", {
              name: parser.procInstName,
              body: parser.procInstBody
            });
            parser.procInstName = parser.procInstBody = "";
            parser.state = S.TEXT;
          } else {
            parser.procInstBody += "?" + c;
            parser.state = S.PROC_INST_BODY;
          }
          continue;
        case S.OPEN_TAG:
          if (isMatch(nameBody, c)) parser.tagName += c;
          else {
            newTag(parser);
            if (c === ">") openTag(parser);
            else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
            else {
              if (!isWhitespace(c)) strictFail(parser, "Invalid character in tag name");
              parser.state = S.ATTRIB;
            }
          }
          continue;
        case S.OPEN_TAG_SLASH:
          if (c === ">") {
            openTag(parser, true);
            closeTag(parser);
          } else {
            strictFail(parser, "Forward-slash in opening tag not followed by >");
            parser.state = S.ATTRIB;
          }
          continue;
        case S.ATTRIB:
          if (isWhitespace(c)) continue;
          else if (c === ">") openTag(parser);
          else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
          else if (isMatch(nameStart, c)) {
            parser.attribName = c;
            parser.attribValue = "";
            parser.state = S.ATTRIB_NAME;
          } else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_NAME:
          if (c === "=") parser.state = S.ATTRIB_VALUE;
          else if (c === ">") {
            strictFail(parser, "Attribute without value");
            parser.attribValue = parser.attribName;
            attrib(parser);
            openTag(parser);
          } else if (isWhitespace(c)) parser.state = S.ATTRIB_NAME_SAW_WHITE;
          else if (isMatch(nameBody, c)) parser.attribName += c;
          else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_NAME_SAW_WHITE:
          if (c === "=") parser.state = S.ATTRIB_VALUE;
          else if (isWhitespace(c)) continue;
          else {
            strictFail(parser, "Attribute without value");
            parser.tag.attributes[parser.attribName] = "";
            parser.attribValue = "";
            emitNode(parser, "onattribute", {
              name: parser.attribName,
              value: ""
            });
            parser.attribName = "";
            if (c === ">") openTag(parser);
            else if (isMatch(nameStart, c)) {
              parser.attribName = c;
              parser.state = S.ATTRIB_NAME;
            } else {
              strictFail(parser, "Invalid attribute name");
              parser.state = S.ATTRIB;
            }
          }
          continue;
        case S.ATTRIB_VALUE:
          if (isWhitespace(c)) continue;
          else if (isQuote(c)) {
            parser.q = c;
            parser.state = S.ATTRIB_VALUE_QUOTED;
          } else {
            strictFail(parser, "Unquoted attribute value");
            parser.state = S.ATTRIB_VALUE_UNQUOTED;
            parser.attribValue = c;
          }
          continue;
        case S.ATTRIB_VALUE_QUOTED:
          if (c !== parser.q) {
            if (c === "&") parser.state = S.ATTRIB_VALUE_ENTITY_Q;
            else parser.attribValue += c;
            continue;
          }
          attrib(parser);
          parser.q = "";
          parser.state = S.ATTRIB_VALUE_CLOSED;
          continue;
        case S.ATTRIB_VALUE_CLOSED:
          if (isWhitespace(c)) parser.state = S.ATTRIB;
          else if (c === ">") openTag(parser);
          else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
          else if (isMatch(nameStart, c)) {
            strictFail(parser, "No whitespace between attributes");
            parser.attribName = c;
            parser.attribValue = "";
            parser.state = S.ATTRIB_NAME;
          } else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_VALUE_UNQUOTED:
          if (!isAttribEnd(c)) {
            if (c === "&") parser.state = S.ATTRIB_VALUE_ENTITY_U;
            else parser.attribValue += c;
            continue;
          }
          attrib(parser);
          if (c === ">") openTag(parser);
          else parser.state = S.ATTRIB;
          continue;
        case S.CLOSE_TAG:
          if (!parser.tagName) if (isWhitespace(c)) continue;
          else if (notMatch(nameStart, c)) if (parser.script) {
            parser.script += "</" + c;
            parser.state = S.SCRIPT;
          } else strictFail(parser, "Invalid tagname in closing tag.");
          else parser.tagName = c;
          else if (c === ">") closeTag(parser);
          else if (isMatch(nameBody, c)) parser.tagName += c;
          else if (parser.script) {
            parser.script += "</" + parser.tagName;
            parser.tagName = "";
            parser.state = S.SCRIPT;
          } else {
            if (!isWhitespace(c)) strictFail(parser, "Invalid tagname in closing tag");
            parser.state = S.CLOSE_TAG_SAW_WHITE;
          }
          continue;
        case S.CLOSE_TAG_SAW_WHITE:
          if (isWhitespace(c)) continue;
          if (c === ">") closeTag(parser);
          else strictFail(parser, "Invalid characters in closing tag");
          continue;
        case S.TEXT_ENTITY:
        case S.ATTRIB_VALUE_ENTITY_Q:
        case S.ATTRIB_VALUE_ENTITY_U:
          var returnState;
          var buffer;
          switch (parser.state) {
            case S.TEXT_ENTITY:
              returnState = S.TEXT;
              buffer = "textNode";
              break;
            case S.ATTRIB_VALUE_ENTITY_Q:
              returnState = S.ATTRIB_VALUE_QUOTED;
              buffer = "attribValue";
              break;
            case S.ATTRIB_VALUE_ENTITY_U:
              returnState = S.ATTRIB_VALUE_UNQUOTED;
              buffer = "attribValue";
              break;
          }
          if (c === ";") if (parser.opt.unparsedEntities) {
            var parsedEntity = parseEntity(parser);
            parser.entity = "";
            parser.state = returnState;
            parser.write(parsedEntity);
          } else {
            parser[buffer] += parseEntity(parser);
            parser.entity = "";
            parser.state = returnState;
          }
          else if (isMatch(parser.entity.length ? entityBody : entityStart, c)) parser.entity += c;
          else {
            strictFail(parser, "Invalid character in entity name");
            parser[buffer] += "&" + parser.entity + c;
            parser.entity = "";
            parser.state = returnState;
          }
          continue;
        default:
          throw new Error(parser, "Unknown state: " + parser.state);
      }
    }
    if (parser.position >= parser.bufferCheckPosition) checkBufferLength(parser);
    return parser;
  }
  if (!String.fromCodePoint) (function() {
    var stringFromCharCode = String.fromCharCode;
    var floor = Math.floor;
    var fromCodePoint = function() {
      var MAX_SIZE = 16384;
      var codeUnits = [];
      var highSurrogate;
      var lowSurrogate;
      var index = -1;
      var length = arguments.length;
      if (!length) return "";
      var result = "";
      while (++index < length) {
        var codePoint = Number(arguments[index]);
        if (!isFinite(codePoint) || codePoint < 0 || codePoint > 1114111 || floor(codePoint) !== codePoint) throw RangeError("Invalid code point: " + codePoint);
        if (codePoint <= 65535) codeUnits.push(codePoint);
        else {
          codePoint -= 65536;
          highSurrogate = (codePoint >> 10) + 55296;
          lowSurrogate = codePoint % 1024 + 56320;
          codeUnits.push(highSurrogate, lowSurrogate);
        }
        if (index + 1 === length || codeUnits.length > MAX_SIZE) {
          result += stringFromCharCode.apply(null, codeUnits);
          codeUnits.length = 0;
        }
      }
      return result;
    };
    if (Object.defineProperty) Object.defineProperty(String, "fromCodePoint", {
      value: fromCodePoint,
      configurable: true,
      writable: true
    });
    else String.fromCodePoint = fromCodePoint;
  })();
  return sax2;
};
var sax = initializeSax();

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/xml.js
var XML_FORMAT_INSTRUCTIONS = `The output should be formatted as a XML file.
1. Output should conform to the tags below. 
2. If tags are not given, make them on your own.
3. Remember to always open and close all the tags.

As an example, for the tags ["foo", "bar", "baz"]:
1. String "<foo>
   <bar>
      <baz></baz>
   </bar>
</foo>" is a well-formatted instance of the schema. 
2. String "<foo>
   <bar>
   </foo>" is a badly-formatted instance.
3. String "<foo>
   <tag>
   </tag>
</foo>" is a badly-formatted instance.

Here are the output tags:
\`\`\`
{tags}
\`\`\``;
var XMLOutputParser = class extends BaseCumulativeTransformOutputParser {
  tags;
  constructor(fields) {
    super(fields);
    this.tags = fields?.tags;
  }
  static lc_name() {
    return "XMLOutputParser";
  }
  lc_namespace = ["langchain_core", "output_parsers"];
  lc_serializable = true;
  _diff(prev, next) {
    if (!next) return;
    if (!prev) return [{
      op: "replace",
      path: "",
      value: next
    }];
    return compare(prev, next);
  }
  async parsePartialResult(generations) {
    return parseXMLMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseXMLMarkdown(text);
  }
  getFormatInstructions() {
    return !!(this.tags && this.tags.length > 0) ? XML_FORMAT_INSTRUCTIONS.replace("{tags}", this.tags?.join(", ") ?? "") : XML_FORMAT_INSTRUCTIONS;
  }
};
var strip = (text) => text.split("\n").map((line) => line.replace(/^\s+/, "")).join("\n").trim();
var parseParsedResult = (input) => {
  if (Object.keys(input).length === 0) return {};
  const result = {};
  if (input.children.length > 0) {
    result[input.name] = input.children.map(parseParsedResult);
    return result;
  } else {
    result[input.name] = input.text ?? void 0;
    return result;
  }
};
function parseXMLMarkdown(s) {
  const cleanedString = strip(s);
  const parser = sax.parser(true);
  let parsedResult = {};
  const elementStack = [];
  parser.onopentag = (node) => {
    const element = {
      name: node.name,
      attributes: node.attributes,
      children: [],
      text: "",
      isSelfClosing: node.isSelfClosing
    };
    if (elementStack.length > 0) elementStack[elementStack.length - 1].children.push(element);
    else parsedResult = element;
    if (!node.isSelfClosing) elementStack.push(element);
  };
  parser.onclosetag = () => {
    if (elementStack.length > 0) {
      const lastElement = elementStack.pop();
      if (elementStack.length === 0 && lastElement) parsedResult = lastElement;
    }
  };
  parser.ontext = (text) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.text += text;
    }
  };
  parser.onattribute = (attr) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.attributes[attr.name] = attr.value;
    }
  };
  const match = /```(xml)?(.*)```/s.exec(cleanedString);
  const xmlString = match ? match[2] : cleanedString;
  parser.write(xmlString).close();
  if (parsedResult && parsedResult.name === "?xml") parsedResult = parsedResult.children[0];
  return parseParsedResult(parsedResult);
}

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/index.js
var output_parsers_exports = __exportAll({
  AsymmetricStructuredOutputParser: () => AsymmetricStructuredOutputParser,
  BaseCumulativeTransformOutputParser: () => BaseCumulativeTransformOutputParser,
  BaseLLMOutputParser: () => BaseLLMOutputParser,
  BaseOutputParser: () => BaseOutputParser,
  BaseTransformOutputParser: () => BaseTransformOutputParser,
  BytesOutputParser: () => BytesOutputParser,
  CommaSeparatedListOutputParser: () => CommaSeparatedListOutputParser,
  CustomListOutputParser: () => CustomListOutputParser,
  JsonMarkdownStructuredOutputParser: () => JsonMarkdownStructuredOutputParser,
  JsonOutputParser: () => JsonOutputParser,
  ListOutputParser: () => ListOutputParser,
  MarkdownListOutputParser: () => MarkdownListOutputParser,
  NumberedListOutputParser: () => NumberedListOutputParser,
  OutputParserException: () => OutputParserException,
  StringOutputParser: () => StringOutputParser,
  StructuredOutputParser: () => StructuredOutputParser,
  XMLOutputParser: () => XMLOutputParser,
  XML_FORMAT_INSTRUCTIONS: () => XML_FORMAT_INSTRUCTIONS,
  parseJsonMarkdown: () => parseJsonMarkdown,
  parsePartialJson: () => parsePartialJson,
  parseXMLMarkdown: () => parseXMLMarkdown
});

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/openai_tools/json_output_tools_parsers.js
function parseToolCall3(rawToolCall, options) {
  if (rawToolCall.function === void 0) return;
  let functionArgs;
  if (options?.partial) try {
    functionArgs = parsePartialJson(rawToolCall.function.arguments ?? "{}");
  } catch {
    return;
  }
  else try {
    functionArgs = JSON.parse(rawToolCall.function.arguments);
  } catch (e) {
    throw new OutputParserException([
      `Function "${rawToolCall.function.name}" arguments:`,
      ``,
      rawToolCall.function.arguments,
      ``,
      `are not valid JSON.`,
      `Error: ${e.message}`
    ].join("\n"));
  }
  const parsedToolCall = {
    name: rawToolCall.function.name,
    args: functionArgs,
    type: "tool_call"
  };
  if (options?.returnId) parsedToolCall.id = rawToolCall.id;
  return parsedToolCall;
}
function convertLangChainToolCallToOpenAI(toolCall) {
  if (toolCall.id === void 0) throw new Error(`All OpenAI tool calls must have an "id" field.`);
  return {
    id: toolCall.id,
    type: "function",
    function: {
      name: toolCall.name,
      arguments: JSON.stringify(toolCall.args)
    }
  };
}
function makeInvalidToolCall(rawToolCall, errorMsg) {
  return {
    name: rawToolCall.function?.name,
    args: rawToolCall.function?.arguments,
    id: rawToolCall.id,
    error: errorMsg,
    type: "invalid_tool_call"
  };
}
var JsonOutputToolsParser = class extends BaseCumulativeTransformOutputParser {
  static lc_name() {
    return "JsonOutputToolsParser";
  }
  returnId = false;
  lc_namespace = [
    "langchain",
    "output_parsers",
    "openai_tools"
  ];
  lc_serializable = true;
  constructor(fields) {
    super(fields);
    this.returnId = fields?.returnId ?? this.returnId;
  }
  _diff() {
    throw new Error("Not supported.");
  }
  async parse() {
    throw new Error("Not implemented.");
  }
  async parseResult(generations) {
    return await this.parsePartialResult(generations, false);
  }
  /**
  * Parses the output and returns a JSON object. If `argsOnly` is true,
  * only the arguments of the function call are returned.
  * @param generations The output of the LLM to parse.
  * @returns A JSON object representation of the function call or its arguments.
  */
  async parsePartialResult(generations, partial = true) {
    const message = generations[0].message;
    let toolCalls;
    if (isAIMessage(message) && message.tool_calls?.length) toolCalls = message.tool_calls.map((toolCall) => {
      const { id, ...rest } = toolCall;
      if (!this.returnId) return rest;
      return {
        id,
        ...rest
      };
    });
    else if (message.additional_kwargs.tool_calls !== void 0) toolCalls = JSON.parse(JSON.stringify(message.additional_kwargs.tool_calls)).map((rawToolCall) => {
      return parseToolCall3(rawToolCall, {
        returnId: this.returnId,
        partial
      });
    });
    if (!toolCalls) return [];
    const parsedToolCalls = [];
    for (const toolCall of toolCalls) if (toolCall !== void 0) {
      const backwardsCompatibleToolCall = {
        type: toolCall.name,
        args: toolCall.args,
        id: toolCall.id
      };
      parsedToolCalls.push(backwardsCompatibleToolCall);
    }
    return parsedToolCalls;
  }
};
var JsonOutputKeyToolsParser = class extends JsonOutputToolsParser {
  static lc_name() {
    return "JsonOutputKeyToolsParser";
  }
  lc_namespace = [
    "langchain",
    "output_parsers",
    "openai_tools"
  ];
  lc_serializable = true;
  returnId = false;
  /** The type of tool calls to return. */
  keyName;
  /** Whether to return only the first tool call. */
  returnSingle = false;
  zodSchema;
  constructor(params) {
    super(params);
    this.keyName = params.keyName;
    this.returnSingle = params.returnSingle ?? this.returnSingle;
    this.zodSchema = params.zodSchema;
  }
  async _validateResult(result) {
    if (this.zodSchema === void 0) return result;
    const zodParsedResult = await interopSafeParseAsync(this.zodSchema, result);
    if (zodParsedResult.success) return zodParsedResult.data;
    else throw new OutputParserException(`Failed to parse. Text: "${JSON.stringify(result, null, 2)}". Error: ${JSON.stringify(zodParsedResult.error?.issues)}`, JSON.stringify(result, null, 2));
  }
  async parsePartialResult(generations) {
    const matchingResults = (await super.parsePartialResult(generations)).filter((result) => result.type === this.keyName);
    let returnedValues = matchingResults;
    if (!matchingResults.length) return;
    if (!this.returnId) returnedValues = matchingResults.map((result) => result.args);
    if (this.returnSingle) return returnedValues[0];
    return returnedValues;
  }
  async parseResult(generations) {
    const matchingResults = (await super.parsePartialResult(generations, false)).filter((result) => result.type === this.keyName);
    let returnedValues = matchingResults;
    if (!matchingResults.length) return;
    if (!this.returnId) returnedValues = matchingResults.map((result) => result.args);
    if (this.returnSingle) return this._validateResult(returnedValues[0]);
    return await Promise.all(returnedValues.map((value) => this._validateResult(value)));
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/output_parsers/openai_tools/index.js
var openai_tools_exports = __exportAll({
  JsonOutputKeyToolsParser: () => JsonOutputKeyToolsParser,
  JsonOutputToolsParser: () => JsonOutputToolsParser,
  convertLangChainToolCallToOpenAI: () => convertLangChainToolCallToOpenAI,
  makeInvalidToolCall: () => makeInvalidToolCall,
  parseToolCall: () => parseToolCall3
});

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/chat_models/base.js
function getChatOpenAIModelParams(modelOrParams, paramsArg) {
  if (typeof modelOrParams === "string") return {
    model: modelOrParams,
    ...paramsArg ?? {}
  };
  if (modelOrParams == null) return paramsArg;
  return modelOrParams;
}
var BaseChatOpenAI = class extends BaseChatModel {
  temperature;
  topP;
  frequencyPenalty;
  presencePenalty;
  n;
  logitBias;
  model = "gpt-3.5-turbo";
  modelKwargs;
  stop;
  stopSequences;
  user;
  timeout;
  streaming = false;
  streamUsage = true;
  maxTokens;
  logprobs;
  topLogprobs;
  apiKey;
  organization;
  __includeRawResponse;
  /** @internal */
  client;
  /** @internal */
  clientConfig;
  /**
  * Whether the model supports the `strict` argument when passing in tools.
  * If `undefined` the `strict` argument will not be passed to OpenAI.
  */
  supportsStrictToolCalling;
  audio;
  modalities;
  reasoning;
  /**
  * Must be set to `true` in tenancies with Zero Data Retention. Setting to `true` will disable
  * output storage in the Responses API, but this DOES NOT enable Zero Data Retention in your
  * OpenAI organization or project. This must be configured directly with OpenAI.
  *
  * See:
  * https://platform.openai.com/docs/guides/your-data
  * https://platform.openai.com/docs/api-reference/responses/create#responses-create-store
  *
  * @default false
  */
  zdrEnabled;
  /**
  * Service tier to use for this request. Can be "auto", "default", or "flex" or "priority".
  * Specifies the service tier for prioritization and latency optimization.
  */
  service_tier;
  /**
  * Used by OpenAI to cache responses for similar requests to optimize your cache
  * hit rates.
  * [Learn more](https://platform.openai.com/docs/guides/prompt-caching).
  */
  promptCacheKey;
  /**
  * Used by OpenAI to set cache retention time
  */
  promptCacheRetention;
  /**
  * The verbosity of the model's response.
  */
  verbosity;
  defaultOptions;
  _llmType() {
    return "openai";
  }
  static lc_name() {
    return "ChatOpenAI";
  }
  get callKeys() {
    return [
      ...super.callKeys,
      "options",
      "function_call",
      "functions",
      "tools",
      "tool_choice",
      "promptIndex",
      "response_format",
      "seed",
      "reasoning",
      "reasoning_effort",
      "service_tier"
    ];
  }
  lc_serializable = true;
  get lc_secrets() {
    return {
      apiKey: "OPENAI_API_KEY",
      organization: "OPENAI_ORGANIZATION"
    };
  }
  get lc_aliases() {
    return {
      apiKey: "openai_api_key",
      modelName: "model"
    };
  }
  get lc_serializable_keys() {
    return [
      "configuration",
      "logprobs",
      "topLogprobs",
      "prefixMessages",
      "supportsStrictToolCalling",
      "modalities",
      "audio",
      "temperature",
      "maxTokens",
      "topP",
      "frequencyPenalty",
      "presencePenalty",
      "n",
      "logitBias",
      "user",
      "streaming",
      "streamUsage",
      "model",
      "modelName",
      "modelKwargs",
      "stop",
      "stopSequences",
      "timeout",
      "apiKey",
      "cache",
      "maxConcurrency",
      "maxRetries",
      "verbose",
      "callbacks",
      "tags",
      "metadata",
      "disableStreaming",
      "zdrEnabled",
      "reasoning",
      "promptCacheKey",
      "promptCacheRetention",
      "verbosity"
    ];
  }
  getLsParams(options) {
    const params = this.invocationParams(options);
    return {
      ls_provider: "openai",
      ls_model_name: this.model,
      ls_model_type: "chat",
      ls_temperature: params.temperature ?? void 0,
      ls_max_tokens: params.max_tokens ?? void 0,
      ls_stop: options.stop
    };
  }
  /** @ignore */
  _identifyingParams() {
    return {
      model_name: this.model,
      ...this.invocationParams(),
      ...this.clientConfig
    };
  }
  /**
  * Get the identifying parameters for the model
  */
  identifyingParams() {
    return this._identifyingParams();
  }
  constructor(fields) {
    super(fields ?? {});
    const configApiKey = typeof fields?.configuration?.apiKey === "string" || typeof fields?.configuration?.apiKey === "function" ? fields?.configuration?.apiKey : void 0;
    this.apiKey = fields?.apiKey ?? configApiKey ?? getEnvironmentVariable("OPENAI_API_KEY");
    this.organization = fields?.configuration?.organization ?? getEnvironmentVariable("OPENAI_ORGANIZATION");
    this.model = fields?.model ?? fields?.modelName ?? this.model;
    this.modelKwargs = fields?.modelKwargs ?? {};
    this.timeout = fields?.timeout;
    this.temperature = fields?.temperature ?? this.temperature;
    this.topP = fields?.topP ?? this.topP;
    this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;
    this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;
    this.logprobs = fields?.logprobs;
    this.topLogprobs = fields?.topLogprobs;
    this.n = fields?.n ?? this.n;
    this.logitBias = fields?.logitBias;
    this.stop = fields?.stopSequences ?? fields?.stop;
    this.stopSequences = this.stop;
    this.user = fields?.user;
    this.__includeRawResponse = fields?.__includeRawResponse;
    this.audio = fields?.audio;
    this.modalities = fields?.modalities;
    this.reasoning = fields?.reasoning;
    this.maxTokens = fields?.maxCompletionTokens ?? fields?.maxTokens;
    this.promptCacheKey = fields?.promptCacheKey ?? this.promptCacheKey;
    this.promptCacheRetention = fields?.promptCacheRetention ?? this.promptCacheRetention;
    this.verbosity = fields?.verbosity ?? this.verbosity;
    this.disableStreaming = fields?.disableStreaming === true;
    this.streaming = fields?.streaming === true;
    if (this.disableStreaming) this.streaming = false;
    if (fields?.streaming === false) this.disableStreaming = true;
    this.streamUsage = fields?.streamUsage ?? this.streamUsage;
    if (this.disableStreaming) this.streamUsage = false;
    this.clientConfig = {
      apiKey: this.apiKey,
      organization: this.organization,
      dangerouslyAllowBrowser: true,
      ...fields?.configuration
    };
    if (fields?.supportsStrictToolCalling !== void 0) this.supportsStrictToolCalling = fields.supportsStrictToolCalling;
    if (fields?.service_tier !== void 0) this.service_tier = fields.service_tier;
    this.zdrEnabled = fields?.zdrEnabled ?? false;
  }
  /**
  * Returns backwards compatible reasoning parameters from constructor params and call options
  * @internal
  */
  _getReasoningParams(options) {
    if (!isReasoningModel(this.model)) return;
    let reasoning;
    if (this.reasoning !== void 0) reasoning = {
      ...reasoning,
      ...this.reasoning
    };
    if (options?.reasoning !== void 0) reasoning = {
      ...reasoning,
      ...options.reasoning
    };
    if (options?.reasoningEffort !== void 0 && reasoning?.effort === void 0) reasoning = {
      ...reasoning,
      effort: options.reasoningEffort
    };
    return reasoning;
  }
  /**
  * Returns an openai compatible response format from a set of options
  * @internal
  */
  _getResponseFormat(resFormat) {
    if (resFormat && resFormat.type === "json_schema" && resFormat.json_schema.schema && isInteropZodSchema(resFormat.json_schema.schema)) return interopZodResponseFormat(resFormat.json_schema.schema, resFormat.json_schema.name, { description: resFormat.json_schema.description });
    return resFormat;
  }
  _combineCallOptions(additionalOptions) {
    return {
      ...this.defaultOptions,
      ...additionalOptions ?? {}
    };
  }
  /** @internal */
  _getClientOptions(options) {
    if (!this.client) {
      const endpoint = getEndpoint({ baseURL: this.clientConfig.baseURL });
      const params = {
        ...this.clientConfig,
        baseURL: endpoint,
        timeout: this.timeout,
        maxRetries: 0
      };
      if (!params.baseURL) delete params.baseURL;
      params.defaultHeaders = getHeadersWithUserAgent(params.defaultHeaders);
      this.client = new OpenAI(params);
    }
    return {
      ...this.clientConfig,
      ...options
    };
  }
  _convertChatOpenAIToolToCompletionsTool(tool2, fields) {
    if (isCustomTool(tool2)) return convertResponsesCustomTool(tool2.metadata.customTool);
    if (isOpenAITool(tool2)) {
      if (fields?.strict !== void 0) return {
        ...tool2,
        function: {
          ...tool2.function,
          strict: fields.strict
        }
      };
      return tool2;
    }
    return _convertToOpenAITool(tool2, fields);
  }
  bindTools(tools2, kwargs) {
    let strict;
    if (kwargs?.strict !== void 0) strict = kwargs.strict;
    else if (this.supportsStrictToolCalling !== void 0) strict = this.supportsStrictToolCalling;
    return this.withConfig({
      tools: tools2.map((tool2) => {
        if (isBuiltInTool(tool2) || isCustomTool(tool2)) return tool2;
        if (hasProviderToolDefinition(tool2)) return tool2.extras.providerToolDefinition;
        return this._convertChatOpenAIToolToCompletionsTool(tool2, { strict });
      }),
      ...kwargs
    });
  }
  async stream(input, options) {
    return super.stream(input, this._combineCallOptions(options));
  }
  async invoke(input, options) {
    return super.invoke(input, this._combineCallOptions(options));
  }
  /** @ignore */
  _combineLLMOutput(...llmOutputs) {
    return llmOutputs.reduce((acc, llmOutput) => {
      if (llmOutput && llmOutput.tokenUsage) {
        acc.tokenUsage.completionTokens += llmOutput.tokenUsage.completionTokens ?? 0;
        acc.tokenUsage.promptTokens += llmOutput.tokenUsage.promptTokens ?? 0;
        acc.tokenUsage.totalTokens += llmOutput.tokenUsage.totalTokens ?? 0;
      }
      return acc;
    }, { tokenUsage: {
      completionTokens: 0,
      promptTokens: 0,
      totalTokens: 0
    } });
  }
  async getNumTokensFromMessages(messages) {
    let totalCount = 0;
    let tokensPerMessage = 0;
    let tokensPerName = 0;
    if (this.model === "gpt-3.5-turbo-0301") {
      tokensPerMessage = 4;
      tokensPerName = -1;
    } else {
      tokensPerMessage = 3;
      tokensPerName = 1;
    }
    const countPerMessage = await Promise.all(messages.map(async (message) => {
      const [textCount, roleCount] = await Promise.all([this.getNumTokens(message.content), this.getNumTokens(messageToOpenAIRole(message))]);
      const nameCount = message.name !== void 0 ? tokensPerName + await this.getNumTokens(message.name) : 0;
      let count = textCount + tokensPerMessage + roleCount + nameCount;
      const openAIMessage = message;
      if (openAIMessage._getType() === "function") count -= 2;
      if (openAIMessage.additional_kwargs?.function_call) count += 3;
      if (openAIMessage?.additional_kwargs.function_call?.name) count += await this.getNumTokens(openAIMessage.additional_kwargs.function_call?.name);
      if (openAIMessage.additional_kwargs.function_call?.arguments) try {
        count += await this.getNumTokens(JSON.stringify(JSON.parse(openAIMessage.additional_kwargs.function_call?.arguments)));
      } catch (error) {
        console.error("Error parsing function arguments", error, JSON.stringify(openAIMessage.additional_kwargs.function_call));
        count += await this.getNumTokens(openAIMessage.additional_kwargs.function_call?.arguments);
      }
      totalCount += count;
      return count;
    }));
    totalCount += 3;
    return {
      totalCount,
      countPerMessage
    };
  }
  /** @internal */
  async _getNumTokensFromGenerations(generations) {
    return (await Promise.all(generations.map(async (generation) => {
      if (generation.message.additional_kwargs?.function_call) return (await this.getNumTokensFromMessages([generation.message])).countPerMessage[0];
      else return await this.getNumTokens(generation.message.content);
    }))).reduce((a, b) => a + b, 0);
  }
  /** @internal */
  async _getEstimatedTokenCountFromPrompt(messages, functions, function_call) {
    let tokens = (await this.getNumTokensFromMessages(messages)).totalCount;
    if (functions && function_call !== "auto") {
      const promptDefinitions = formatFunctionDefinitions(functions);
      tokens += await this.getNumTokens(promptDefinitions);
      tokens += 9;
    }
    if (functions && messages.find((m) => m._getType() === "system")) tokens -= 4;
    if (function_call === "none") tokens += 1;
    else if (typeof function_call === "object") tokens += await this.getNumTokens(function_call.name) + 4;
    return tokens;
  }
  /**
  * Moderate content using OpenAI's Moderation API.
  *
  * This method checks whether content violates OpenAI's content policy by
  * analyzing text for categories such as hate, harassment, self-harm,
  * sexual content, violence, and more.
  *
  * @param input - The text or array of texts to moderate
  * @param params - Optional parameters for the moderation request
  * @param params.model - The moderation model to use. Defaults to "omni-moderation-latest".
  * @param params.options - Additional options to pass to the underlying request
  * @returns A promise that resolves to the moderation response containing results for each input
  *
  * @example
  * ```typescript
  * const model = new ChatOpenAI({ model: "gpt-4o-mini" });
  *
  * // Moderate a single text
  * const result = await model.moderateContent("This is a test message");
  * console.log(result.results[0].flagged); // false
  * console.log(result.results[0].categories); // { hate: false, harassment: false, ... }
  *
  * // Moderate multiple texts
  * const results = await model.moderateContent([
  *   "Hello, how are you?",
  *   "This is inappropriate content"
  * ]);
  * results.results.forEach((result, index) => {
  *   console.log(`Text ${index + 1} flagged:`, result.flagged);
  * });
  *
  * // Use a specific moderation model
  * const stableResult = await model.moderateContent(
  *   "Test content",
  *   { model: "omni-moderation-latest" }
  * );
  * ```
  */
  async moderateContent(input, params) {
    const clientOptions = this._getClientOptions(params?.options);
    const moderationRequest = {
      input,
      model: params?.model ?? "omni-moderation-latest"
    };
    return this.caller.call(async () => {
      try {
        return await this.client.moderations.create(moderationRequest, clientOptions);
      } catch (e) {
        throw wrapOpenAIClientError(e);
      }
    });
  }
  /**
  * Return profiling information for the model.
  *
  * Provides information about the model's capabilities and constraints,
  * including token limits, multimodal support, and advanced features like
  * tool calling and structured output.
  *
  * @returns {ModelProfile} An object describing the model's capabilities and constraints
  *
  * @example
  * ```typescript
  * const model = new ChatOpenAI({ model: "gpt-4o" });
  * const profile = model.profile;
  * console.log(profile.maxInputTokens); // 128000
  * console.log(profile.imageInputs); // true
  * ```
  */
  get profile() {
    return PROFILES[this.model] ?? {};
  }
  /** @internal */
  _getStructuredOutputMethod(config2) {
    const ensuredConfig = { ...config2 };
    if (!this.model.startsWith("gpt-3") && !this.model.startsWith("gpt-4-") && this.model !== "gpt-4") {
      if (ensuredConfig?.method === void 0) return "jsonSchema";
    } else if (ensuredConfig.method === "jsonSchema") console.warn(`[WARNING]: JSON Schema is not supported for model "${this.model}". Falling back to tool calling.`);
    return ensuredConfig.method;
  }
  /**
  * Add structured output to the model.
  *
  * The OpenAI model family supports the following structured output methods:
  * - `jsonSchema`: Use the `response_format` field in the response to return a JSON schema. Only supported with the `gpt-4o-mini`,
  *   `gpt-4o-mini-2024-07-18`, and `gpt-4o-2024-08-06` model snapshots and later.
  * - `functionCalling`: Function calling is useful when you are building an application that bridges the models and functionality
  *   of your application.
  * - `jsonMode`: JSON mode is a more basic version of the Structured Outputs feature. While JSON mode ensures that model
  *   output is valid JSON, Structured Outputs reliably matches the model's output to the schema you specify.
  *   We recommend you use `functionCalling` or `jsonSchema` if it is supported for your use case.
  *
  * The default method is `functionCalling`.
  *
  * @see https://platform.openai.com/docs/guides/structured-outputs
  * @param outputSchema - The schema to use for structured output.
  * @param config - The structured output method options.
  * @returns The model with structured output.
  */
  withStructuredOutput(outputSchema, config2) {
    let llm;
    let outputParser;
    const { schema, name, includeRaw } = {
      ...config2,
      schema: outputSchema
    };
    if (config2?.strict !== void 0 && config2.method === "jsonMode") throw new Error("Argument `strict` is only supported for `method` = 'function_calling'");
    const method = getStructuredOutputMethod(this.model, config2?.method);
    if (method === "jsonMode") {
      if (isInteropZodSchema(schema)) outputParser = StructuredOutputParser.fromZodSchema(schema);
      else outputParser = new JsonOutputParser();
      const asJsonSchema = toJsonSchema(schema);
      llm = this.withConfig({
        outputVersion: "v0",
        response_format: { type: "json_object" },
        ls_structured_output_format: {
          kwargs: { method: "json_mode" },
          schema: {
            title: name ?? "extract",
            ...asJsonSchema
          }
        }
      });
    } else if (method === "jsonSchema") {
      const openaiJsonSchemaParams = {
        name: name ?? "extract",
        description: getSchemaDescription(schema),
        schema,
        strict: config2?.strict
      };
      const asJsonSchema = toJsonSchema(openaiJsonSchemaParams.schema);
      llm = this.withConfig({
        outputVersion: "v0",
        response_format: {
          type: "json_schema",
          json_schema: openaiJsonSchemaParams
        },
        ls_structured_output_format: {
          kwargs: { method: "json_schema" },
          schema: {
            title: openaiJsonSchemaParams.name,
            description: openaiJsonSchemaParams.description,
            ...asJsonSchema
          }
        }
      });
      if (isInteropZodSchema(schema)) {
        const altParser = StructuredOutputParser.fromZodSchema(schema);
        outputParser = RunnableLambda.from((aiMessage) => {
          if ("parsed" in aiMessage.additional_kwargs) return aiMessage.additional_kwargs.parsed;
          return altParser;
        });
      } else outputParser = new JsonOutputParser();
    } else {
      let functionName = name ?? "extract";
      if (isInteropZodSchema(schema)) {
        const asJsonSchema = toJsonSchema(schema);
        llm = this.withConfig({
          outputVersion: "v0",
          tools: [{
            type: "function",
            function: {
              name: functionName,
              description: asJsonSchema.description,
              parameters: asJsonSchema
            }
          }],
          tool_choice: {
            type: "function",
            function: { name: functionName }
          },
          ls_structured_output_format: {
            kwargs: { method: "function_calling" },
            schema: {
              title: functionName,
              ...asJsonSchema
            }
          },
          ...config2?.strict !== void 0 ? { strict: config2.strict } : {}
        });
        outputParser = new JsonOutputKeyToolsParser({
          returnSingle: true,
          keyName: functionName,
          zodSchema: schema
        });
      } else {
        let openAIFunctionDefinition;
        if (typeof schema.name === "string" && typeof schema.parameters === "object" && schema.parameters != null) {
          openAIFunctionDefinition = schema;
          functionName = schema.name;
        } else {
          functionName = schema.title ?? functionName;
          openAIFunctionDefinition = {
            name: functionName,
            description: schema.description ?? "",
            parameters: schema
          };
        }
        const asJsonSchema = toJsonSchema(schema);
        llm = this.withConfig({
          outputVersion: "v0",
          tools: [{
            type: "function",
            function: openAIFunctionDefinition
          }],
          tool_choice: {
            type: "function",
            function: { name: functionName }
          },
          ls_structured_output_format: {
            kwargs: { method: "function_calling" },
            schema: {
              title: functionName,
              ...asJsonSchema
            }
          },
          ...config2?.strict !== void 0 ? { strict: config2.strict } : {}
        });
        outputParser = new JsonOutputKeyToolsParser({
          returnSingle: true,
          keyName: functionName
        });
      }
    }
    if (!includeRaw) return llm.pipe(outputParser);
    const parserAssign = RunnablePassthrough.assign({ parsed: (input, config3) => outputParser.invoke(input.raw, config3) });
    const parserNone = RunnablePassthrough.assign({ parsed: () => null });
    const parsedWithFallback = parserAssign.withFallbacks({ fallbacks: [parserNone] });
    return RunnableSequence.from([{ raw: llm }, parsedWithFallback]);
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/converters/completions.js
var completionsApiContentBlockConverter = {
  providerName: "ChatOpenAI",
  fromStandardTextBlock(block) {
    return {
      type: "text",
      text: block.text
    };
  },
  fromStandardImageBlock(block) {
    if (block.source_type === "url") return {
      type: "image_url",
      image_url: {
        url: block.url,
        ...block.metadata?.detail ? { detail: block.metadata.detail } : {}
      }
    };
    if (block.source_type === "base64") return {
      type: "image_url",
      image_url: {
        url: `data:${block.mime_type ?? ""};base64,${block.data}`,
        ...block.metadata?.detail ? { detail: block.metadata.detail } : {}
      }
    };
    throw new Error(`Image content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
  },
  fromStandardAudioBlock(block) {
    if (block.source_type === "url") {
      const data = parseBase64DataUrl({ dataUrl: block.url });
      if (!data) throw new Error(`URL audio blocks with source_type ${block.source_type} must be formatted as a data URL for ChatOpenAI`);
      const rawMimeType = data.mime_type || block.mime_type || "";
      let mimeType;
      try {
        mimeType = parseMimeType(rawMimeType);
      } catch {
        throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
      }
      if (mimeType.type !== "audio" || mimeType.subtype !== "wav" && mimeType.subtype !== "mp3") throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
      return {
        type: "input_audio",
        input_audio: {
          format: mimeType.subtype,
          data: data.data
        }
      };
    }
    if (block.source_type === "base64") {
      let mimeType;
      try {
        mimeType = parseMimeType(block.mime_type ?? "");
      } catch {
        throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
      }
      if (mimeType.type !== "audio" || mimeType.subtype !== "wav" && mimeType.subtype !== "mp3") throw new Error(`Audio blocks with source_type ${block.source_type} must have mime type of audio/wav or audio/mp3`);
      return {
        type: "input_audio",
        input_audio: {
          format: mimeType.subtype,
          data: block.data
        }
      };
    }
    throw new Error(`Audio content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
  },
  fromStandardFileBlock(block) {
    if (block.source_type === "url") {
      const data = parseBase64DataUrl({ dataUrl: block.url });
      const filename = getRequiredFilenameFromMetadata(block);
      if (!data) throw new Error(`URL file blocks with source_type ${block.source_type} must be formatted as a data URL for ChatOpenAI`);
      return {
        type: "file",
        file: {
          file_data: block.url,
          ...block.metadata?.filename || block.metadata?.name ? { filename } : {}
        }
      };
    }
    if (block.source_type === "base64") {
      const filename = getRequiredFilenameFromMetadata(block);
      return {
        type: "file",
        file: {
          file_data: `data:${block.mime_type ?? ""};base64,${block.data}`,
          ...block.metadata?.filename || block.metadata?.name || block.metadata?.title ? { filename } : {}
        }
      };
    }
    if (block.source_type === "id") return {
      type: "file",
      file: { file_id: block.id }
    };
    throw new Error(`File content blocks with source_type ${block.source_type} are not supported for ChatOpenAI`);
  }
};
var convertCompletionsMessageToBaseMessage = ({ message, rawResponse, includeRawResponse }) => {
  const rawToolCalls = message.tool_calls;
  switch (message.role) {
    case "assistant": {
      const toolCalls = [];
      const invalidToolCalls = [];
      for (const rawToolCall of rawToolCalls ?? []) try {
        toolCalls.push(parseToolCall3(rawToolCall, { returnId: true }));
      } catch (e) {
        invalidToolCalls.push(makeInvalidToolCall(rawToolCall, e.message));
      }
      const additional_kwargs = {
        function_call: message.function_call,
        tool_calls: rawToolCalls
      };
      if (includeRawResponse !== void 0) additional_kwargs.__raw_response = rawResponse;
      const response_metadata = {
        model_provider: "openai",
        model_name: rawResponse.model,
        ...rawResponse.system_fingerprint ? {
          usage: { ...rawResponse.usage },
          system_fingerprint: rawResponse.system_fingerprint
        } : {}
      };
      if (message.audio) additional_kwargs.audio = message.audio;
      return new AIMessage({
        content: handleMultiModalOutput(message.content || "", rawResponse.choices?.[0]?.message),
        tool_calls: toolCalls,
        invalid_tool_calls: invalidToolCalls,
        additional_kwargs,
        response_metadata,
        id: rawResponse.id
      });
    }
    default:
      return new ChatMessage(message.content || "", message.role ?? "unknown");
  }
};
var convertCompletionsDeltaToBaseMessageChunk = ({ delta, rawResponse, includeRawResponse, defaultRole }) => {
  const role = delta.role ?? defaultRole;
  const content = delta.content ?? "";
  let additional_kwargs;
  if (delta.function_call) additional_kwargs = { function_call: delta.function_call };
  else if (delta.tool_calls) additional_kwargs = { tool_calls: delta.tool_calls };
  else additional_kwargs = {};
  if (includeRawResponse) additional_kwargs.__raw_response = rawResponse;
  if (delta.audio) additional_kwargs.audio = {
    ...delta.audio,
    index: rawResponse.choices[0].index
  };
  const response_metadata = {
    model_provider: "openai",
    usage: { ...rawResponse.usage }
  };
  if (role === "user") return new HumanMessageChunk({
    content,
    response_metadata
  });
  else if (role === "assistant") {
    const toolCallChunks = [];
    if (Array.isArray(delta.tool_calls)) for (const rawToolCall of delta.tool_calls) toolCallChunks.push({
      name: rawToolCall.function?.name,
      args: rawToolCall.function?.arguments,
      id: rawToolCall.id,
      index: rawToolCall.index,
      type: "tool_call_chunk"
    });
    return new AIMessageChunk({
      content,
      tool_call_chunks: toolCallChunks,
      additional_kwargs,
      id: rawResponse.id,
      response_metadata
    });
  } else if (role === "system") return new SystemMessageChunk({
    content,
    response_metadata
  });
  else if (role === "developer") return new SystemMessageChunk({
    content,
    response_metadata,
    additional_kwargs: { __openai_role__: "developer" }
  });
  else if (role === "function") return new FunctionMessageChunk({
    content,
    additional_kwargs,
    name: delta.name,
    response_metadata
  });
  else if (role === "tool") return new ToolMessageChunk({
    content,
    additional_kwargs,
    tool_call_id: delta.tool_call_id,
    response_metadata
  });
  else return new ChatMessageChunk({
    content,
    role,
    response_metadata
  });
};
var convertStandardContentBlockToCompletionsContentPart = (block) => {
  if (block.type === "image") {
    if (block.url) return {
      type: "image_url",
      image_url: { url: block.url }
    };
    else if (block.data) return {
      type: "image_url",
      image_url: { url: `data:${block.mimeType};base64,${block.data}` }
    };
  }
  if (block.type === "audio") {
    if (block.data) {
      const format = iife(() => {
        const [, format2] = block.mimeType.split("/");
        if (format2 === "wav" || format2 === "mp3") return format2;
        return "wav";
      });
      return {
        type: "input_audio",
        input_audio: {
          data: block.data.toString(),
          format
        }
      };
    }
  }
  if (block.type === "file") {
    if (block.data) {
      const filename = getRequiredFilenameFromMetadata(block);
      return {
        type: "file",
        file: {
          file_data: `data:${block.mimeType};base64,${block.data}`,
          filename
        }
      };
    }
    if (block.fileId) return {
      type: "file",
      file: { file_id: block.fileId }
    };
  }
};
var convertStandardContentMessageToCompletionsMessage = ({ message, model }) => {
  let role = messageToOpenAIRole(message);
  if (role === "system" && isReasoningModel(model)) role = "developer";
  if (role === "developer") return {
    role: "developer",
    content: message.contentBlocks.filter((block) => block.type === "text")
  };
  else if (role === "system") return {
    role: "system",
    content: message.contentBlocks.filter((block) => block.type === "text")
  };
  else if (role === "assistant") return {
    role: "assistant",
    content: message.contentBlocks.filter((block) => block.type === "text")
  };
  else if (role === "tool" && ToolMessage.isInstance(message)) return {
    role: "tool",
    tool_call_id: message.tool_call_id,
    content: message.contentBlocks.filter((block) => block.type === "text")
  };
  else if (role === "function") return {
    role: "function",
    name: message.name ?? "",
    content: message.contentBlocks.filter((block) => block.type === "text").join("")
  };
  function* iterateUserContent(blocks2) {
    for (const block of blocks2) {
      if (block.type === "text") yield {
        type: "text",
        text: block.text
      };
      const data = convertStandardContentBlockToCompletionsContentPart(block);
      if (data) yield data;
    }
  }
  return {
    role: "user",
    content: Array.from(iterateUserContent(message.contentBlocks))
  };
};
var convertMessagesToCompletionsMessageParams = ({ messages, model }) => {
  return messages.flatMap((message) => {
    if ("output_version" in message.response_metadata && message.response_metadata?.output_version === "v1") return convertStandardContentMessageToCompletionsMessage({ message });
    let role = messageToOpenAIRole(message);
    if (role === "system" && isReasoningModel(model)) role = "developer";
    const content = typeof message.content === "string" ? message.content : message.content.flatMap((m) => {
      if (isDataContentBlock(m)) return convertToProviderContentBlock(m, completionsApiContentBlockConverter);
      if (typeof m === "object" && m !== null && "type" in m && m.type === "tool_use") return [];
      return m;
    });
    const completionParam = {
      role,
      content
    };
    if (message.name != null) completionParam.name = message.name;
    if (message.additional_kwargs.function_call != null) completionParam.function_call = message.additional_kwargs.function_call;
    if (AIMessage.isInstance(message) && !!message.tool_calls?.length) completionParam.tool_calls = message.tool_calls.map(convertLangChainToolCallToOpenAI);
    else {
      if (message.additional_kwargs.tool_calls != null) completionParam.tool_calls = message.additional_kwargs.tool_calls;
      if (ToolMessage.isInstance(message) && message.tool_call_id != null) completionParam.tool_call_id = message.tool_call_id;
    }
    if (message.additional_kwargs.audio && typeof message.additional_kwargs.audio === "object" && "id" in message.additional_kwargs.audio) return [completionParam, {
      role: "assistant",
      audio: { id: message.additional_kwargs.audio.id }
    }];
    return completionParam;
  });
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/chat_models/completions.js
var ChatOpenAICompletions = class extends BaseChatOpenAI {
  constructor(modelOrFields, fieldsArg) {
    super(getChatOpenAIModelParams(modelOrFields, fieldsArg));
  }
  /** @internal */
  invocationParams(options, extra) {
    let strict;
    if (options?.strict !== void 0) strict = options.strict;
    else if (this.supportsStrictToolCalling !== void 0) strict = this.supportsStrictToolCalling;
    let streamOptionsConfig = {};
    if (options?.stream_options !== void 0) streamOptionsConfig = { stream_options: options.stream_options };
    else if (this.streamUsage && (this.streaming || extra?.streaming)) streamOptionsConfig = { stream_options: { include_usage: true } };
    const params = {
      model: this.model,
      temperature: this.temperature,
      top_p: this.topP,
      frequency_penalty: this.frequencyPenalty,
      presence_penalty: this.presencePenalty,
      logprobs: this.logprobs,
      top_logprobs: this.topLogprobs,
      n: this.n,
      logit_bias: this.logitBias,
      stop: options?.stop ?? this.stopSequences,
      user: this.user,
      stream: this.streaming,
      functions: options?.functions,
      function_call: options?.function_call,
      tools: options?.tools?.length ? options.tools.map((tool2) => this._convertChatOpenAIToolToCompletionsTool(tool2, { strict })) : void 0,
      tool_choice: formatToOpenAIToolChoice(options?.tool_choice),
      response_format: this._getResponseFormat(options?.response_format),
      seed: options?.seed,
      ...streamOptionsConfig,
      parallel_tool_calls: options?.parallel_tool_calls,
      ...this.audio || options?.audio ? { audio: this.audio || options?.audio } : {},
      ...this.modalities || options?.modalities ? { modalities: this.modalities || options?.modalities } : {},
      ...this.modelKwargs,
      prompt_cache_key: options?.promptCacheKey ?? this.promptCacheKey,
      prompt_cache_retention: options?.promptCacheRetention ?? this.promptCacheRetention,
      verbosity: options?.verbosity ?? this.verbosity
    };
    if (options?.prediction !== void 0) params.prediction = options.prediction;
    if (this.service_tier !== void 0) params.service_tier = this.service_tier;
    if (options?.service_tier !== void 0) params.service_tier = options.service_tier;
    const reasoning = this._getReasoningParams(options);
    if (reasoning !== void 0 && reasoning.effort !== void 0) params.reasoning_effort = reasoning.effort;
    if (isReasoningModel(params.model)) params.max_completion_tokens = this.maxTokens === -1 ? void 0 : this.maxTokens;
    else params.max_tokens = this.maxTokens === -1 ? void 0 : this.maxTokens;
    return params;
  }
  async _generate(messages, options, runManager) {
    options.signal?.throwIfAborted();
    const usageMetadata = {};
    const params = this.invocationParams(options);
    const messagesMapped = convertMessagesToCompletionsMessageParams({
      messages,
      model: this.model
    });
    if (params.stream) {
      const stream = this._streamResponseChunks(messages, options, runManager);
      const finalChunks = {};
      for await (const chunk of stream) {
        chunk.message.response_metadata = {
          ...chunk.generationInfo,
          ...chunk.message.response_metadata
        };
        const index = chunk.generationInfo?.completion ?? 0;
        if (finalChunks[index] === void 0) finalChunks[index] = chunk;
        else finalChunks[index] = finalChunks[index].concat(chunk);
      }
      const generations = Object.entries(finalChunks).sort(([aKey], [bKey]) => parseInt(aKey, 10) - parseInt(bKey, 10)).map(([_, value]) => value);
      const { functions, function_call } = this.invocationParams(options);
      const promptTokenUsage = await this._getEstimatedTokenCountFromPrompt(messages, functions, function_call);
      const completionTokenUsage = await this._getNumTokensFromGenerations(generations);
      usageMetadata.input_tokens = promptTokenUsage;
      usageMetadata.output_tokens = completionTokenUsage;
      usageMetadata.total_tokens = promptTokenUsage + completionTokenUsage;
      return {
        generations,
        llmOutput: { estimatedTokenUsage: {
          promptTokens: usageMetadata.input_tokens,
          completionTokens: usageMetadata.output_tokens,
          totalTokens: usageMetadata.total_tokens
        } }
      };
    } else {
      const data = await this.completionWithRetry({
        ...params,
        stream: false,
        messages: messagesMapped
      }, {
        signal: options?.signal,
        ...options?.options
      });
      const { completion_tokens: completionTokens, prompt_tokens: promptTokens, total_tokens: totalTokens, prompt_tokens_details: promptTokensDetails, completion_tokens_details: completionTokensDetails } = data?.usage ?? {};
      if (completionTokens) usageMetadata.output_tokens = (usageMetadata.output_tokens ?? 0) + completionTokens;
      if (promptTokens) usageMetadata.input_tokens = (usageMetadata.input_tokens ?? 0) + promptTokens;
      if (totalTokens) usageMetadata.total_tokens = (usageMetadata.total_tokens ?? 0) + totalTokens;
      if (promptTokensDetails?.audio_tokens !== null || promptTokensDetails?.cached_tokens !== null) usageMetadata.input_token_details = {
        ...promptTokensDetails?.audio_tokens !== null && { audio: promptTokensDetails?.audio_tokens },
        ...promptTokensDetails?.cached_tokens !== null && { cache_read: promptTokensDetails?.cached_tokens }
      };
      if (completionTokensDetails?.audio_tokens !== null || completionTokensDetails?.reasoning_tokens !== null) usageMetadata.output_token_details = {
        ...completionTokensDetails?.audio_tokens !== null && { audio: completionTokensDetails?.audio_tokens },
        ...completionTokensDetails?.reasoning_tokens !== null && { reasoning: completionTokensDetails?.reasoning_tokens }
      };
      const generations = [];
      for (const part of data?.choices ?? []) {
        const generation = {
          text: part.message?.content ?? "",
          message: this._convertCompletionsMessageToBaseMessage(part.message ?? { role: "assistant" }, data)
        };
        generation.generationInfo = {
          ...part.finish_reason ? { finish_reason: part.finish_reason } : {},
          ...part.logprobs ? { logprobs: part.logprobs } : {}
        };
        if (isAIMessage(generation.message)) generation.message.usage_metadata = usageMetadata;
        generation.message = new AIMessage(Object.fromEntries(Object.entries(generation.message).filter(([key]) => !key.startsWith("lc_"))));
        generations.push(generation);
      }
      return {
        generations,
        llmOutput: { tokenUsage: {
          promptTokens: usageMetadata.input_tokens,
          completionTokens: usageMetadata.output_tokens,
          totalTokens: usageMetadata.total_tokens
        } }
      };
    }
  }
  async *_streamResponseChunks(messages, options, runManager) {
    const messagesMapped = convertMessagesToCompletionsMessageParams({
      messages,
      model: this.model
    });
    const params = {
      ...this.invocationParams(options, { streaming: true }),
      messages: messagesMapped,
      stream: true
    };
    let defaultRole;
    const streamIterable = await this.completionWithRetry(params, options);
    let usage;
    for await (const data of streamIterable) {
      if (options.signal?.aborted) return;
      const choice = data?.choices?.[0];
      if (data.usage) usage = data.usage;
      if (!choice) continue;
      const { delta } = choice;
      if (!delta) continue;
      const chunk = this._convertCompletionsDeltaToBaseMessageChunk(delta, data, defaultRole);
      defaultRole = delta.role ?? defaultRole;
      const newTokenIndices = {
        prompt: options.promptIndex ?? 0,
        completion: choice.index ?? 0
      };
      if (typeof chunk.content !== "string") {
        console.log("[WARNING]: Received non-string content from OpenAI. This is currently not supported.");
        continue;
      }
      const generationInfo = { ...newTokenIndices };
      if (choice.finish_reason != null) {
        generationInfo.finish_reason = choice.finish_reason;
        generationInfo.system_fingerprint = data.system_fingerprint;
        generationInfo.model_name = data.model;
        generationInfo.service_tier = data.service_tier;
      }
      if (this.logprobs) generationInfo.logprobs = choice.logprobs;
      const generationChunk = new ChatGenerationChunk({
        message: chunk,
        text: chunk.content,
        generationInfo
      });
      yield generationChunk;
      await runManager?.handleLLMNewToken(generationChunk.text ?? "", newTokenIndices, void 0, void 0, void 0, { chunk: generationChunk });
    }
    if (usage) {
      const inputTokenDetails = {
        ...usage.prompt_tokens_details?.audio_tokens !== null && { audio: usage.prompt_tokens_details?.audio_tokens },
        ...usage.prompt_tokens_details?.cached_tokens !== null && { cache_read: usage.prompt_tokens_details?.cached_tokens }
      };
      const outputTokenDetails = {
        ...usage.completion_tokens_details?.audio_tokens !== null && { audio: usage.completion_tokens_details?.audio_tokens },
        ...usage.completion_tokens_details?.reasoning_tokens !== null && { reasoning: usage.completion_tokens_details?.reasoning_tokens }
      };
      const generationChunk = new ChatGenerationChunk({
        message: new AIMessageChunk({
          content: "",
          response_metadata: { usage: { ...usage } },
          usage_metadata: {
            input_tokens: usage.prompt_tokens,
            output_tokens: usage.completion_tokens,
            total_tokens: usage.total_tokens,
            ...Object.keys(inputTokenDetails).length > 0 && { input_token_details: inputTokenDetails },
            ...Object.keys(outputTokenDetails).length > 0 && { output_token_details: outputTokenDetails }
          }
        }),
        text: ""
      });
      yield generationChunk;
      await runManager?.handleLLMNewToken(generationChunk.text ?? "", {
        prompt: 0,
        completion: 0
      }, void 0, void 0, void 0, { chunk: generationChunk });
    }
    if (options.signal?.aborted) throw new Error("AbortError");
  }
  async completionWithRetry(request, requestOptions) {
    const clientOptions = this._getClientOptions(requestOptions);
    const isParseableFormat = request.response_format && request.response_format.type === "json_schema";
    return this.caller.call(async () => {
      try {
        if (isParseableFormat && !request.stream) return await this.client.chat.completions.parse(request, clientOptions);
        else return await this.client.chat.completions.create(request, clientOptions);
      } catch (e) {
        throw wrapOpenAIClientError(e);
      }
    });
  }
  /**
  * @deprecated
  * This function was hoisted into a publicly accessible function from a
  * different export, but to maintain backwards compatibility with chat models
  * that depend on ChatOpenAICompletions, we'll keep it here as an overridable
  * method. This will be removed in a future release
  */
  _convertCompletionsDeltaToBaseMessageChunk(delta, rawResponse, defaultRole) {
    return convertCompletionsDeltaToBaseMessageChunk({
      delta,
      rawResponse,
      includeRawResponse: this.__includeRawResponse,
      defaultRole
    });
  }
  /**
  * @deprecated
  * This function was hoisted into a publicly accessible function from a
  * different export, but to maintain backwards compatibility with chat models
  * that depend on ChatOpenAICompletions, we'll keep it here as an overridable
  * method. This will be removed in a future release
  */
  _convertCompletionsMessageToBaseMessage(message, rawResponse) {
    return convertCompletionsMessageToBaseMessage({
      message,
      rawResponse,
      includeRawResponse: this.__includeRawResponse
    });
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/azure/chat_models/common.js
var AZURE_ALIASES = {
  openAIApiKey: "openai_api_key",
  openAIApiVersion: "openai_api_version",
  openAIBasePath: "openai_api_base",
  deploymentName: "deployment_name",
  azureOpenAIEndpoint: "azure_endpoint",
  azureOpenAIApiVersion: "openai_api_version",
  azureOpenAIBasePath: "openai_api_base",
  azureOpenAIApiDeploymentName: "deployment_name"
};
var AZURE_SECRETS = { azureOpenAIApiKey: "AZURE_OPENAI_API_KEY" };
var AZURE_SERIALIZABLE_KEYS = [
  "azureOpenAIApiKey",
  "azureOpenAIApiVersion",
  "azureOpenAIBasePath",
  "azureOpenAIEndpoint",
  "azureOpenAIApiInstanceName",
  "azureOpenAIApiDeploymentName",
  "deploymentName",
  "openAIApiKey",
  "openAIApiVersion"
];
function getAzureChatOpenAIParams(modelOrFields, fieldsArg) {
  if (typeof modelOrFields === "string") return {
    model: modelOrFields,
    deploymentName: modelOrFields,
    azureOpenAIApiDeploymentName: modelOrFields,
    ...fieldsArg ?? {}
  };
  if (modelOrFields == null) return fieldsArg;
  return modelOrFields;
}
function _constructAzureFields(fields) {
  this.azureOpenAIApiKey = fields?.azureOpenAIApiKey ?? (typeof fields?.openAIApiKey === "string" ? fields?.openAIApiKey : void 0) ?? (typeof fields?.apiKey === "string" ? fields?.apiKey : void 0) ?? getEnvironmentVariable("AZURE_OPENAI_API_KEY");
  this.azureOpenAIApiInstanceName = fields?.azureOpenAIApiInstanceName ?? getEnvironmentVariable("AZURE_OPENAI_API_INSTANCE_NAME");
  this.azureOpenAIApiDeploymentName = fields?.azureOpenAIApiDeploymentName ?? fields?.deploymentName ?? getEnvironmentVariable("AZURE_OPENAI_API_DEPLOYMENT_NAME");
  this.azureOpenAIApiVersion = fields?.azureOpenAIApiVersion ?? fields?.openAIApiVersion ?? getEnvironmentVariable("AZURE_OPENAI_API_VERSION");
  this.azureOpenAIBasePath = fields?.azureOpenAIBasePath ?? getEnvironmentVariable("AZURE_OPENAI_BASE_PATH");
  this.azureOpenAIEndpoint = fields?.azureOpenAIEndpoint ?? getEnvironmentVariable("AZURE_OPENAI_ENDPOINT");
  this.azureADTokenProvider = fields?.azureADTokenProvider;
  if (!this.azureOpenAIApiKey && !this.apiKey && !this.azureADTokenProvider) throw new Error("Azure OpenAI API key or Token Provider not found");
}
function _getAzureClientOptions(options) {
  if (!this.client) {
    const openAIEndpointConfig = {
      azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,
      azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,
      azureOpenAIApiKey: this.azureOpenAIApiKey,
      azureOpenAIBasePath: this.azureOpenAIBasePath,
      azureADTokenProvider: this.azureADTokenProvider,
      baseURL: this.clientConfig.baseURL,
      azureOpenAIEndpoint: this.azureOpenAIEndpoint
    };
    const endpoint = getEndpoint(openAIEndpointConfig);
    const { apiKey: existingApiKey, ...clientConfigRest } = this.clientConfig;
    const params = {
      ...clientConfigRest,
      baseURL: endpoint,
      timeout: this.timeout,
      maxRetries: 0
    };
    if (!this.azureADTokenProvider) params.apiKey = openAIEndpointConfig.azureOpenAIApiKey;
    if (!params.baseURL) delete params.baseURL;
    params.defaultHeaders = getHeadersWithUserAgent(params.defaultHeaders, true, "2.0.0");
    this.client = new AzureOpenAI({
      apiVersion: this.azureOpenAIApiVersion,
      azureADTokenProvider: this.azureADTokenProvider,
      deployment: this.azureOpenAIApiDeploymentName,
      ...params
    });
  }
  const requestOptions = {
    ...this.clientConfig,
    ...options
  };
  if (this.azureOpenAIApiKey) {
    requestOptions.headers = {
      "api-key": this.azureOpenAIApiKey,
      ...requestOptions.headers
    };
    requestOptions.query = {
      "api-version": this.azureOpenAIApiVersion,
      ...requestOptions.query
    };
  }
  return requestOptions;
}
function _serializeAzureChat(input) {
  const json2 = input;
  function isRecord(obj) {
    return typeof obj === "object" && obj != null;
  }
  if (isRecord(json2) && isRecord(json2.kwargs)) {
    delete json2.kwargs.azure_openai_base_path;
    delete json2.kwargs.azure_openai_api_deployment_name;
    delete json2.kwargs.azure_openai_api_key;
    delete json2.kwargs.azure_openai_api_version;
    delete json2.kwargs.azure_open_ai_base_path;
    if (!json2.kwargs.azure_endpoint && this.azureOpenAIEndpoint) json2.kwargs.azure_endpoint = this.azureOpenAIEndpoint;
    if (!json2.kwargs.azure_endpoint && this.azureOpenAIBasePath) {
      const parts = this.azureOpenAIBasePath.split("/openai/deployments/");
      if (parts.length === 2 && parts[0].startsWith("http")) {
        const [endpoint] = parts;
        json2.kwargs.azure_endpoint = endpoint;
      }
    }
    if (!json2.kwargs.azure_endpoint && this.azureOpenAIApiInstanceName) json2.kwargs.azure_endpoint = `https://${this.azureOpenAIApiInstanceName}.openai.azure.com/`;
    if (!json2.kwargs.deployment_name && this.azureOpenAIApiDeploymentName) json2.kwargs.deployment_name = this.azureOpenAIApiDeploymentName;
    if (!json2.kwargs.deployment_name && this.azureOpenAIBasePath) {
      const parts = this.azureOpenAIBasePath.split("/openai/deployments/");
      if (parts.length === 2) {
        const [, deployment] = parts;
        json2.kwargs.deployment_name = deployment;
      }
    }
    if (json2.kwargs.azure_endpoint && json2.kwargs.deployment_name && json2.kwargs.openai_api_base) delete json2.kwargs.openai_api_base;
    if (json2.kwargs.azure_openai_api_instance_name && json2.kwargs.azure_endpoint) delete json2.kwargs.azure_openai_api_instance_name;
  }
  return json2;
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/azure/chat_models/completions.js
var AzureChatOpenAICompletions = class extends ChatOpenAICompletions {
  azureOpenAIApiVersion;
  azureOpenAIApiKey;
  azureADTokenProvider;
  azureOpenAIApiInstanceName;
  azureOpenAIApiDeploymentName;
  azureOpenAIBasePath;
  azureOpenAIEndpoint;
  _llmType() {
    return "azure_openai";
  }
  get lc_aliases() {
    return {
      ...super.lc_aliases,
      ...AZURE_ALIASES
    };
  }
  get lc_secrets() {
    return {
      ...super.lc_secrets,
      ...AZURE_SECRETS
    };
  }
  get lc_serializable_keys() {
    return [...super.lc_serializable_keys, ...AZURE_SERIALIZABLE_KEYS];
  }
  getLsParams(options) {
    const params = super.getLsParams(options);
    params.ls_provider = "azure";
    return params;
  }
  constructor(deploymentOrFields, fieldsArg) {
    const fields = getAzureChatOpenAIParams(deploymentOrFields, fieldsArg);
    super(fields);
    _constructAzureFields.call(this, fields);
  }
  _getClientOptions(options) {
    return _getAzureClientOptions.call(this, options);
  }
  toJSON() {
    return _serializeAzureChat.call(this, super.toJSON());
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/converters/responses.js
var _FUNCTION_CALL_IDS_MAP_KEY = "__openai_function_call_ids__";
function convertOpenAIAnnotationToLangChain(annotation) {
  if (annotation.type === "url_citation") return {
    type: "citation",
    source: "url_citation",
    url: annotation.url,
    title: annotation.title,
    startIndex: annotation.start_index,
    endIndex: annotation.end_index
  };
  if (annotation.type === "file_citation") return {
    type: "citation",
    source: "file_citation",
    title: annotation.filename,
    startIndex: annotation.index,
    file_id: annotation.file_id
  };
  if (annotation.type === "container_file_citation") return {
    type: "citation",
    source: "container_file_citation",
    title: annotation.filename,
    startIndex: annotation.start_index,
    endIndex: annotation.end_index,
    file_id: annotation.file_id,
    container_id: annotation.container_id
  };
  if (annotation.type === "file_path") return {
    type: "citation",
    source: "file_path",
    startIndex: annotation.index,
    file_id: annotation.file_id
  };
  return {
    type: "non_standard",
    value: annotation
  };
}
function convertLangChainAnnotationToOpenAI(annotation) {
  if (annotation.type === "url_citation" || annotation.type === "file_citation" || annotation.type === "container_file_citation" || annotation.type === "file_path") return annotation;
  if (annotation.type === "citation") {
    const citation = annotation;
    if (citation.source === "url_citation") return {
      type: "url_citation",
      url: citation.url ?? "",
      title: citation.title ?? "",
      start_index: citation.startIndex ?? 0,
      end_index: citation.endIndex ?? 0
    };
    if (citation.source === "file_citation") return {
      type: "file_citation",
      file_id: citation.file_id ?? "",
      filename: citation.title ?? "",
      index: citation.startIndex ?? 0
    };
    if (citation.source === "container_file_citation") return {
      type: "container_file_citation",
      file_id: citation.file_id ?? "",
      filename: citation.title ?? "",
      container_id: citation.container_id ?? "",
      start_index: citation.startIndex ?? 0,
      end_index: citation.endIndex ?? 0
    };
    if (citation.source === "file_path") return {
      type: "file_path",
      file_id: citation.file_id ?? "",
      index: citation.startIndex ?? 0
    };
  }
  if (annotation.type === "non_standard") return annotation.value;
  return annotation;
}
var convertResponsesUsageToUsageMetadata = (usage) => {
  const inputTokenDetails = { ...usage?.input_tokens_details?.cached_tokens != null && { cache_read: usage?.input_tokens_details?.cached_tokens } };
  const outputTokenDetails = { ...usage?.output_tokens_details?.reasoning_tokens != null && { reasoning: usage?.output_tokens_details?.reasoning_tokens } };
  return {
    input_tokens: usage?.input_tokens ?? 0,
    output_tokens: usage?.output_tokens ?? 0,
    total_tokens: usage?.total_tokens ?? 0,
    input_token_details: inputTokenDetails,
    output_token_details: outputTokenDetails
  };
};
var convertResponsesMessageToAIMessage = (response) => {
  if (response.error) {
    const error = new Error(response.error.message);
    error.name = response.error.code;
    throw error;
  }
  let messageId;
  const content = [];
  const tool_calls = [];
  const invalid_tool_calls = [];
  const cleanedOutput = response.output.map((item) => {
    if (item.type === "function_call" && "parsed_arguments" in item) {
      const cleaned = { ...item };
      delete cleaned.parsed_arguments;
      return cleaned;
    }
    return item;
  });
  const response_metadata = {
    model_provider: "openai",
    model: response.model,
    created_at: response.created_at,
    id: response.id,
    incomplete_details: response.incomplete_details,
    metadata: response.metadata,
    object: response.object,
    output: cleanedOutput,
    status: response.status,
    user: response.user,
    service_tier: response.service_tier,
    model_name: response.model
  };
  const additional_kwargs = {};
  for (const item of response.output) if (item.type === "message") {
    messageId = item.id;
    content.push(...item.content.flatMap((part) => {
      if (part.type === "output_text") {
        if ("parsed" in part && part.parsed != null) additional_kwargs.parsed = part.parsed;
        return {
          type: "text",
          text: part.text,
          annotations: part.annotations.map(convertOpenAIAnnotationToLangChain)
        };
      }
      if (part.type === "refusal") {
        additional_kwargs.refusal = part.refusal;
        return [];
      }
      return part;
    }));
  } else if (item.type === "function_call") {
    const fnAdapter = {
      function: {
        name: item.name,
        arguments: item.arguments
      },
      id: item.call_id
    };
    try {
      tool_calls.push(parseToolCall3(fnAdapter, { returnId: true }));
    } catch (e) {
      let errMessage;
      if (typeof e === "object" && e != null && "message" in e && typeof e.message === "string") errMessage = e.message;
      invalid_tool_calls.push(makeInvalidToolCall(fnAdapter, errMessage));
    }
    additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY] ??= {};
    if (item.id) additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY][item.call_id] = item.id;
  } else if (item.type === "reasoning") {
    additional_kwargs.reasoning = item;
    const reasoningText = item.summary?.map((s) => s.text).filter(Boolean).join("");
    if (reasoningText) content.push({
      type: "reasoning",
      reasoning: reasoningText
    });
  } else if (item.type === "custom_tool_call") {
    const parsed = parseCustomToolCall(item);
    if (parsed) tool_calls.push(parsed);
    else invalid_tool_calls.push(makeInvalidToolCall(item, "Malformed custom tool call"));
  } else if (item.type === "computer_call") {
    const parsed = parseComputerCall(item);
    if (parsed) tool_calls.push(parsed);
    else invalid_tool_calls.push(makeInvalidToolCall(item, "Malformed computer call"));
  } else if (item.type === "image_generation_call") {
    if (item.result) content.push({
      type: "image",
      mimeType: "image/png",
      data: item.result,
      id: item.id,
      metadata: { status: item.status }
    });
    additional_kwargs.tool_outputs ??= [];
    additional_kwargs.tool_outputs.push(item);
  } else {
    additional_kwargs.tool_outputs ??= [];
    additional_kwargs.tool_outputs.push(item);
  }
  return new AIMessage({
    id: messageId,
    content,
    tool_calls,
    invalid_tool_calls,
    usage_metadata: convertResponsesUsageToUsageMetadata(response.usage),
    additional_kwargs,
    response_metadata
  });
};
var convertReasoningSummaryToResponsesReasoningItem = (reasoning) => {
  const summary = (reasoning.summary.length > 1 ? reasoning.summary.reduce((acc, curr) => {
    const last = acc[acc.length - 1];
    if (last.index === curr.index) last.text += curr.text;
    else acc.push(curr);
    return acc;
  }, [{ ...reasoning.summary[0] }]) : reasoning.summary).map((s) => Object.fromEntries(Object.entries(s).filter(([k]) => k !== "index")));
  return {
    ...reasoning,
    summary
  };
};
var convertResponsesDeltaToChatGenerationChunk = (event) => {
  const content = [];
  let generationInfo = {};
  let usage_metadata;
  const tool_call_chunks = [];
  const response_metadata = { model_provider: "openai" };
  const additional_kwargs = {};
  let id;
  if (event.type === "response.output_text.delta") content.push({
    type: "text",
    text: event.delta,
    index: event.content_index
  });
  else if (event.type === "response.output_text.annotation.added") content.push({
    type: "text",
    text: "",
    annotations: [convertOpenAIAnnotationToLangChain(event.annotation)],
    index: event.content_index
  });
  else if (event.type === "response.output_item.added" && event.item.type === "message") id = event.item.id;
  else if (event.type === "response.output_item.added" && event.item.type === "function_call") {
    tool_call_chunks.push({
      type: "tool_call_chunk",
      name: event.item.name,
      args: event.item.arguments,
      id: event.item.call_id,
      index: event.output_index
    });
    additional_kwargs[_FUNCTION_CALL_IDS_MAP_KEY] = { [event.item.call_id]: event.item.id };
  } else if (event.type === "response.output_item.done" && event.item.type === "computer_call") {
    tool_call_chunks.push({
      type: "tool_call_chunk",
      name: "computer_use",
      args: JSON.stringify({ action: event.item.action }),
      id: event.item.call_id,
      index: event.output_index
    });
    additional_kwargs.tool_outputs = [event.item];
  } else if (event.type === "response.output_item.done" && event.item.type === "image_generation_call") {
    if (event.item.result) content.push({
      type: "image",
      mimeType: "image/png",
      data: event.item.result,
      id: event.item.id,
      metadata: { status: event.item.status }
    });
    additional_kwargs.tool_outputs = [event.item];
  } else if (event.type === "response.output_item.done" && [
    "web_search_call",
    "file_search_call",
    "code_interpreter_call",
    "shell_call",
    "local_shell_call",
    "mcp_call",
    "mcp_list_tools",
    "mcp_approval_request",
    "custom_tool_call"
  ].includes(event.item.type)) additional_kwargs.tool_outputs = [event.item];
  else if (event.type === "response.created") {
    response_metadata.id = event.response.id;
    response_metadata.model_name = event.response.model;
    response_metadata.model = event.response.model;
  } else if (event.type === "response.completed") {
    const msg = convertResponsesMessageToAIMessage(event.response);
    usage_metadata = convertResponsesUsageToUsageMetadata(event.response.usage);
    if (event.response.text?.format?.type === "json_schema") additional_kwargs.parsed ??= JSON.parse(msg.text);
    for (const [key, value] of Object.entries(event.response)) {
      if (key === "id") continue;
      if (key === "output") response_metadata[key] = msg.response_metadata.output;
      else response_metadata[key] = value;
    }
  } else if (event.type === "response.function_call_arguments.delta" || event.type === "response.custom_tool_call_input.delta") tool_call_chunks.push({
    type: "tool_call_chunk",
    args: event.delta,
    index: event.output_index
  });
  else if (event.type === "response.web_search_call.completed" || event.type === "response.file_search_call.completed") generationInfo = { tool_outputs: {
    id: event.item_id,
    type: event.type.replace("response.", "").replace(".completed", ""),
    status: "completed"
  } };
  else if (event.type === "response.refusal.done") additional_kwargs.refusal = event.refusal;
  else if (event.type === "response.output_item.added" && "item" in event && event.item.type === "reasoning") {
    const summary = event.item.summary ? event.item.summary.map((s, index) => ({
      ...s,
      index
    })) : void 0;
    additional_kwargs.reasoning = {
      id: event.item.id,
      type: event.item.type,
      ...summary ? { summary } : {}
    };
    const reasoningText = event.item.summary?.map((s) => s.text).filter(Boolean).join("");
    if (reasoningText) content.push({
      type: "reasoning",
      reasoning: reasoningText
    });
  } else if (event.type === "response.reasoning_summary_part.added") {
    additional_kwargs.reasoning = {
      type: "reasoning",
      summary: [{
        ...event.part,
        index: event.summary_index
      }]
    };
    if (event.part.text) content.push({
      type: "reasoning",
      reasoning: event.part.text
    });
  } else if (event.type === "response.reasoning_summary_text.delta") {
    additional_kwargs.reasoning = {
      type: "reasoning",
      summary: [{
        text: event.delta,
        type: "summary_text",
        index: event.summary_index
      }]
    };
    if (event.delta) content.push({
      type: "reasoning",
      reasoning: event.delta
    });
  } else if (event.type === "response.image_generation_call.partial_image") return null;
  else return null;
  return new ChatGenerationChunk({
    text: content.map((part) => part.text).join(""),
    message: new AIMessageChunk({
      id,
      content,
      tool_call_chunks,
      usage_metadata,
      additional_kwargs,
      response_metadata
    }),
    generationInfo
  });
};
var convertStandardContentMessageToResponsesInput = (message) => {
  const isResponsesMessage = AIMessage.isInstance(message) && message.response_metadata?.model_provider === "openai";
  function* iterateItems() {
    const messageRole = iife$1(() => {
      try {
        const role = messageToOpenAIRole(message);
        if (role === "system" || role === "developer" || role === "assistant" || role === "user") return role;
        return "assistant";
      } catch {
        return "assistant";
      }
    });
    let currentMessage = void 0;
    const functionCallIdsWithBlocks = /* @__PURE__ */ new Set();
    const serverFunctionCallIdsWithBlocks = /* @__PURE__ */ new Set();
    const pendingFunctionChunks = /* @__PURE__ */ new Map();
    const pendingServerFunctionChunks = /* @__PURE__ */ new Map();
    function* flushMessage() {
      if (!currentMessage) return;
      const content = currentMessage.content;
      if (typeof content === "string" && content.length > 0 || Array.isArray(content) && content.length > 0) yield currentMessage;
      currentMessage = void 0;
    }
    const pushMessageContent = (content) => {
      if (!currentMessage) currentMessage = {
        type: "message",
        role: messageRole,
        content: []
      };
      if (typeof currentMessage.content === "string") currentMessage.content = currentMessage.content.length > 0 ? [{
        type: "input_text",
        text: currentMessage.content
      }, ...content] : [...content];
      else currentMessage.content.push(...content);
    };
    const toJsonString = (value) => {
      if (typeof value === "string") return value;
      try {
        return JSON.stringify(value ?? {});
      } catch {
        return "{}";
      }
    };
    const resolveImageItem = (block) => {
      const detail = iife$1(() => {
        const raw = block.metadata?.detail;
        if (raw === "low" || raw === "high" || raw === "auto") return raw;
        return "auto";
      });
      if (block.fileId) return {
        type: "input_image",
        detail,
        file_id: block.fileId
      };
      if (block.url) return {
        type: "input_image",
        detail,
        image_url: block.url
      };
      if (block.data) {
        const base64Data = typeof block.data === "string" ? block.data : Buffer.from(block.data).toString("base64");
        return {
          type: "input_image",
          detail,
          image_url: `data:${block.mimeType ?? "image/png"};base64,${base64Data}`
        };
      }
    };
    const resolveFileItem = (block) => {
      if (block.fileId) {
        const filename = getFilenameFromMetadata(block);
        return {
          type: "input_file",
          file_id: block.fileId,
          ...filename ? { filename } : {}
        };
      }
      if (block.url) {
        const filename = getFilenameFromMetadata(block);
        return {
          ...filename ? { filename } : {},
          type: "input_file",
          file_url: block.url
        };
      }
      if (block.data) {
        const filename = getRequiredFilenameFromMetadata(block);
        const encoded = typeof block.data === "string" ? block.data : Buffer.from(block.data).toString("base64");
        return {
          type: "input_file",
          file_data: `data:${block.mimeType ?? "application/octet-stream"};base64,${encoded}`,
          ...filename ? { filename } : {}
        };
      }
    };
    const convertReasoningBlock = (block) => {
      const summaryEntries = iife$1(() => {
        if (Array.isArray(block.summary)) {
          const mapped = block.summary?.map((item) => item?.text).filter((text) => typeof text === "string") ?? [];
          if (mapped.length > 0) return mapped;
        }
        return block.reasoning ? [block.reasoning] : [];
      });
      const summary = summaryEntries.length > 0 ? summaryEntries.map((text) => ({
        type: "summary_text",
        text
      })) : [{
        type: "summary_text",
        text: ""
      }];
      const reasoningItem = {
        type: "reasoning",
        id: block.id ?? "",
        summary
      };
      if (block.reasoning) reasoningItem.content = [{
        type: "reasoning_text",
        text: block.reasoning
      }];
      return reasoningItem;
    };
    const convertFunctionCall = (block) => ({
      type: "function_call",
      name: block.name ?? "",
      call_id: block.id ?? "",
      arguments: toJsonString(block.args)
    });
    const convertFunctionCallOutput = (block) => {
      const output = toJsonString(block.output);
      const status = block.status === "success" ? "completed" : block.status === "error" ? "incomplete" : void 0;
      return {
        type: "function_call_output",
        call_id: block.toolCallId ?? "",
        output,
        ...status ? { status } : {}
      };
    };
    for (const block of message.contentBlocks) if (block.type === "text") pushMessageContent([{
      type: "input_text",
      text: block.text
    }]);
    else if (block.type === "invalid_tool_call") {
    } else if (block.type === "reasoning") {
      yield* flushMessage();
      yield convertReasoningBlock(block);
    } else if (block.type === "tool_call") {
      yield* flushMessage();
      const id = block.id ?? "";
      if (id) {
        functionCallIdsWithBlocks.add(id);
        pendingFunctionChunks.delete(id);
      }
      yield convertFunctionCall(block);
    } else if (block.type === "tool_call_chunk") {
      if (block.id) {
        const existing = pendingFunctionChunks.get(block.id) ?? {
          name: block.name,
          args: []
        };
        if (block.name) existing.name = block.name;
        if (block.args) existing.args.push(block.args);
        pendingFunctionChunks.set(block.id, existing);
      }
    } else if (block.type === "server_tool_call") {
      yield* flushMessage();
      const id = block.id ?? "";
      if (id) {
        serverFunctionCallIdsWithBlocks.add(id);
        pendingServerFunctionChunks.delete(id);
      }
      yield convertFunctionCall(block);
    } else if (block.type === "server_tool_call_chunk") {
      if (block.id) {
        const existing = pendingServerFunctionChunks.get(block.id) ?? {
          name: block.name,
          args: []
        };
        if (block.name) existing.name = block.name;
        if (block.args) existing.args.push(block.args);
        pendingServerFunctionChunks.set(block.id, existing);
      }
    } else if (block.type === "server_tool_call_result") {
      yield* flushMessage();
      yield convertFunctionCallOutput(block);
    } else if (block.type === "audio") {
    } else if (block.type === "file") {
      const fileItem = resolveFileItem(block);
      if (fileItem) pushMessageContent([fileItem]);
    } else if (block.type === "image") {
      const imageItem = resolveImageItem(block);
      if (imageItem) pushMessageContent([imageItem]);
    } else if (block.type === "video") {
      const videoItem = resolveFileItem(block);
      if (videoItem) pushMessageContent([videoItem]);
    } else if (block.type === "text-plain") {
      if (block.text) pushMessageContent([{
        type: "input_text",
        text: block.text
      }]);
    } else if (block.type === "non_standard" && isResponsesMessage) {
      yield* flushMessage();
      yield block.value;
    }
    yield* flushMessage();
    for (const [id, chunk] of pendingFunctionChunks) {
      if (!id || functionCallIdsWithBlocks.has(id)) continue;
      const args = chunk.args.join("");
      if (!chunk.name && !args) continue;
      yield {
        type: "function_call",
        call_id: id,
        name: chunk.name ?? "",
        arguments: args
      };
    }
    for (const [id, chunk] of pendingServerFunctionChunks) {
      if (!id || serverFunctionCallIdsWithBlocks.has(id)) continue;
      const args = chunk.args.join("");
      if (!chunk.name && !args) continue;
      yield {
        type: "function_call",
        call_id: id,
        name: chunk.name ?? "",
        arguments: args
      };
    }
  }
  return Array.from(iterateItems());
};
var convertMessagesToResponsesInput = ({ messages, zdrEnabled, model }) => {
  return messages.flatMap((lcMsg) => {
    const responseMetadata = lcMsg.response_metadata;
    if (responseMetadata?.output_version === "v1") return convertStandardContentMessageToResponsesInput(lcMsg);
    const additional_kwargs = lcMsg.additional_kwargs;
    let role = messageToOpenAIRole(lcMsg);
    if (role === "system" && isReasoningModel(model)) role = "developer";
    if (role === "function") throw new Error("Function messages are not supported in Responses API");
    if (role === "tool") {
      const toolMessage = lcMsg;
      if (additional_kwargs?.type === "computer_call_output")
        return {
          type: "computer_call_output",
          output: (() => {
            if (typeof toolMessage.content === "string") return {
              type: "input_image",
              image_url: toolMessage.content
            };
            if (Array.isArray(toolMessage.content)) {
              const inputImage = toolMessage.content.find((i) => i.type === "input_image");
              if (inputImage) return inputImage;
              const oaiScreenshot = toolMessage.content.find((i) => i.type === "computer_screenshot");
              if (oaiScreenshot) return oaiScreenshot;
              const lcImage = toolMessage.content.find((i) => i.type === "image_url");
              if (lcImage) return {
                type: "input_image",
                image_url: typeof lcImage.image_url === "string" ? lcImage.image_url : lcImage.image_url.url
              };
            }
            throw new Error("Invalid computer call output");
          })(),
          call_id: toolMessage.tool_call_id
        };
      if (toolMessage.additional_kwargs?.customTool) return {
        type: "custom_tool_call_output",
        call_id: toolMessage.tool_call_id,
        output: toolMessage.content
      };
      const isProviderNativeContent = Array.isArray(toolMessage.content) && toolMessage.content.every((item) => typeof item === "object" && item !== null && "type" in item && (item.type === "input_file" || item.type === "input_image" || item.type === "input_text"));
      return {
        type: "function_call_output",
        call_id: toolMessage.tool_call_id,
        id: toolMessage.id?.startsWith("fc_") ? toolMessage.id : void 0,
        output: isProviderNativeContent ? toolMessage.content : typeof toolMessage.content !== "string" ? JSON.stringify(toolMessage.content) : toolMessage.content
      };
    }
    if (role === "assistant") {
      if (!zdrEnabled && responseMetadata?.output != null && Array.isArray(responseMetadata?.output) && responseMetadata?.output.length > 0 && responseMetadata?.output.every((item) => "type" in item)) return responseMetadata?.output;
      const input = [];
      const reasoning = additional_kwargs?.reasoning;
      const hasEncryptedContent = !!reasoning?.encrypted_content;
      if (reasoning && (!zdrEnabled || hasEncryptedContent)) {
        const reasoningItem = convertReasoningSummaryToResponsesReasoningItem(reasoning);
        input.push(reasoningItem);
      }
      let { content } = lcMsg;
      if (additional_kwargs?.refusal) {
        if (typeof content === "string") content = [{
          type: "output_text",
          text: content,
          annotations: []
        }];
        content = [...content, {
          type: "refusal",
          refusal: additional_kwargs.refusal
        }];
      }
      if (typeof content === "string" || content.length > 0) input.push({
        type: "message",
        role: "assistant",
        ...lcMsg.id && !zdrEnabled && lcMsg.id.startsWith("msg_") ? { id: lcMsg.id } : {},
        content: iife$1(() => {
          if (typeof content === "string") return content;
          return content.flatMap((item) => {
            if (item.type === "text") return {
              type: "output_text",
              text: item.text,
              annotations: (item.annotations ?? []).map(convertLangChainAnnotationToOpenAI)
            };
            if (item.type === "output_text" || item.type === "refusal") return item;
            return [];
          });
        })
      });
      const functionCallIds = additional_kwargs?.[_FUNCTION_CALL_IDS_MAP_KEY];
      if (AIMessage.isInstance(lcMsg) && !!lcMsg.tool_calls?.length) input.push(...lcMsg.tool_calls.map((toolCall) => {
        if (isCustomToolCall(toolCall)) return {
          type: "custom_tool_call",
          id: toolCall.call_id,
          call_id: toolCall.id ?? "",
          input: toolCall.args.input,
          name: toolCall.name
        };
        if (isComputerToolCall(toolCall)) return {
          type: "computer_call",
          id: toolCall.call_id,
          call_id: toolCall.id ?? "",
          action: toolCall.args.action
        };
        return {
          type: "function_call",
          name: toolCall.name,
          arguments: JSON.stringify(toolCall.args),
          call_id: toolCall.id,
          ...!zdrEnabled ? { id: functionCallIds?.[toolCall.id] } : {}
        };
      }));
      else if (additional_kwargs?.tool_calls) input.push(...additional_kwargs.tool_calls.map((toolCall) => ({
        type: "function_call",
        name: toolCall.function.name,
        call_id: toolCall.id,
        arguments: toolCall.function.arguments,
        ...!zdrEnabled ? { id: functionCallIds?.[toolCall.id] } : {}
      })));
      const toolOutputs = responseMetadata?.output?.length ? responseMetadata?.output : additional_kwargs.tool_outputs;
      const fallthroughCallTypes = [
        "computer_call",
        "mcp_call",
        "code_interpreter_call",
        "image_generation_call",
        "shell_call",
        "local_shell_call"
      ];
      if (toolOutputs != null) {
        const fallthroughCalls = toolOutputs?.filter((item) => fallthroughCallTypes.includes(item.type));
        if (fallthroughCalls.length > 0) input.push(...fallthroughCalls);
      }
      return input;
    }
    if (role === "user" || role === "system" || role === "developer") {
      if (typeof lcMsg.content === "string") return {
        type: "message",
        role,
        content: lcMsg.content
      };
      const messages2 = [];
      const content = lcMsg.content.flatMap((item) => {
        if (item.type === "mcp_approval_response") messages2.push({
          type: "mcp_approval_response",
          approval_request_id: item.approval_request_id,
          approve: item.approve
        });
        if (isDataContentBlock(item)) return convertToProviderContentBlock(item, completionsApiContentBlockConverter);
        if (item.type === "text") return {
          type: "input_text",
          text: item.text
        };
        if (item.type === "image_url") return {
          type: "input_image",
          image_url: iife$1(() => {
            if (typeof item.image_url === "string") return item.image_url;
            else if (typeof item.image_url === "object" && item.image_url !== null && "url" in item.image_url) return item.image_url.url;
          }),
          detail: iife$1(() => {
            if (typeof item.image_url === "string") return "auto";
            else if (typeof item.image_url === "object" && item.image_url !== null && "detail" in item.image_url) return item.image_url.detail;
          })
        };
        if (item.type === "input_text" || item.type === "input_image" || item.type === "input_file") return item;
        return [];
      });
      if (content.length > 0) messages2.push({
        type: "message",
        role,
        content
      });
      return messages2;
    }
    console.warn(`Unsupported role found when converting to OpenAI Responses API: ${role}`);
    return [];
  });
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/chat_models/responses.js
var ChatOpenAIResponses = class extends BaseChatOpenAI {
  constructor(modelOrFields, fieldsArg) {
    super(getChatOpenAIModelParams(modelOrFields, fieldsArg));
  }
  invocationParams(options) {
    let strict;
    if (options?.strict !== void 0) strict = options.strict;
    if (strict === void 0 && this.supportsStrictToolCalling !== void 0) strict = this.supportsStrictToolCalling;
    const params = {
      model: this.model,
      temperature: this.temperature,
      top_p: this.topP,
      user: this.user,
      service_tier: this.service_tier,
      stream: this.streaming,
      previous_response_id: options?.previous_response_id,
      truncation: options?.truncation,
      include: options?.include,
      tools: options?.tools?.length ? this._reduceChatOpenAITools(options.tools, {
        stream: this.streaming,
        strict
      }) : void 0,
      tool_choice: isBuiltInToolChoice(options?.tool_choice) ? options?.tool_choice : (() => {
        const formatted = formatToOpenAIToolChoice(options?.tool_choice);
        if (typeof formatted === "object" && "type" in formatted) {
          if (formatted.type === "function") return {
            type: "function",
            name: formatted.function.name
          };
          else if (formatted.type === "allowed_tools") return {
            type: "allowed_tools",
            mode: formatted.allowed_tools.mode,
            tools: formatted.allowed_tools.tools
          };
          else if (formatted.type === "custom") return {
            type: "custom",
            name: formatted.custom.name
          };
        }
      })(),
      text: (() => {
        if (options?.text) return options.text;
        const format = this._getResponseFormat(options?.response_format);
        if (format?.type === "json_schema") {
          if (format.json_schema.schema != null) return {
            format: {
              type: "json_schema",
              schema: format.json_schema.schema,
              description: format.json_schema.description,
              name: format.json_schema.name,
              strict: format.json_schema.strict
            },
            verbosity: options?.verbosity
          };
          return;
        }
        return {
          format,
          verbosity: options?.verbosity
        };
      })(),
      parallel_tool_calls: options?.parallel_tool_calls,
      max_output_tokens: this.maxTokens === -1 ? void 0 : this.maxTokens,
      prompt_cache_key: options?.promptCacheKey ?? this.promptCacheKey,
      prompt_cache_retention: options?.promptCacheRetention ?? this.promptCacheRetention,
      ...this.zdrEnabled ? { store: false } : {},
      ...this.modelKwargs
    };
    const reasoning = this._getReasoningParams(options);
    if (reasoning !== void 0) params.reasoning = reasoning;
    return params;
  }
  async _generate(messages, options, runManager) {
    options.signal?.throwIfAborted();
    const invocationParams = this.invocationParams(options);
    if (invocationParams.stream) {
      const stream = this._streamResponseChunks(messages, options, runManager);
      let finalChunk;
      for await (const chunk of stream) {
        chunk.message.response_metadata = {
          ...chunk.generationInfo,
          ...chunk.message.response_metadata
        };
        finalChunk = finalChunk?.concat(chunk) ?? chunk;
      }
      return {
        generations: finalChunk ? [finalChunk] : [],
        llmOutput: { estimatedTokenUsage: finalChunk?.message?.usage_metadata }
      };
    } else {
      const data = await this.completionWithRetry({
        input: convertMessagesToResponsesInput({
          messages,
          zdrEnabled: this.zdrEnabled ?? false,
          model: this.model
        }),
        ...invocationParams,
        stream: false
      }, {
        signal: options?.signal,
        ...options?.options
      });
      return {
        generations: [{
          text: data.output_text,
          message: convertResponsesMessageToAIMessage(data)
        }],
        llmOutput: {
          id: data.id,
          estimatedTokenUsage: data.usage ? {
            promptTokens: data.usage.input_tokens,
            completionTokens: data.usage.output_tokens,
            totalTokens: data.usage.total_tokens
          } : void 0
        }
      };
    }
  }
  async *_streamResponseChunks(messages, options, runManager) {
    const streamIterable = await this.completionWithRetry({
      ...this.invocationParams(options),
      input: convertMessagesToResponsesInput({
        messages,
        zdrEnabled: this.zdrEnabled ?? false,
        model: this.model
      }),
      stream: true
    }, options);
    for await (const data of streamIterable) {
      if (options.signal?.aborted) return;
      const chunk = convertResponsesDeltaToChatGenerationChunk(data);
      if (chunk == null) continue;
      yield chunk;
      await runManager?.handleLLMNewToken(chunk.text || "", {
        prompt: options.promptIndex ?? 0,
        completion: 0
      }, void 0, void 0, void 0, { chunk });
    }
  }
  async completionWithRetry(request, requestOptions) {
    return this.caller.call(async () => {
      const clientOptions = this._getClientOptions(requestOptions);
      try {
        if (request.text?.format?.type === "json_schema" && !request.stream) return await this.client.responses.parse(request, clientOptions);
        return await this.client.responses.create(request, clientOptions);
      } catch (e) {
        throw wrapOpenAIClientError(e);
      }
    });
  }
  /** @internal */
  _reduceChatOpenAITools(tools2, fields) {
    const reducedTools = [];
    for (const tool2 of tools2) if (isBuiltInTool(tool2)) {
      if (tool2.type === "image_generation" && fields?.stream) tool2.partial_images = 1;
      reducedTools.push(tool2);
    } else if (isCustomTool(tool2)) {
      const customToolData = tool2.metadata.customTool;
      reducedTools.push({
        type: "custom",
        name: customToolData.name,
        description: customToolData.description,
        format: customToolData.format
      });
    } else if (isOpenAITool(tool2)) reducedTools.push({
      type: "function",
      name: tool2.function.name,
      parameters: tool2.function.parameters,
      description: tool2.function.description,
      strict: fields?.strict ?? null
    });
    else if (isOpenAICustomTool(tool2)) reducedTools.push(convertCompletionsCustomTool(tool2));
    return reducedTools;
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/azure/chat_models/responses.js
var AzureChatOpenAIResponses = class extends ChatOpenAIResponses {
  azureOpenAIApiVersion;
  azureOpenAIApiKey;
  azureADTokenProvider;
  azureOpenAIApiInstanceName;
  azureOpenAIApiDeploymentName;
  azureOpenAIBasePath;
  azureOpenAIEndpoint;
  _llmType() {
    return "azure_openai";
  }
  get lc_aliases() {
    return {
      ...super.lc_aliases,
      ...AZURE_ALIASES
    };
  }
  get lc_secrets() {
    return {
      ...super.lc_secrets,
      ...AZURE_SECRETS
    };
  }
  get lc_serializable_keys() {
    return [...super.lc_serializable_keys, ...AZURE_SERIALIZABLE_KEYS];
  }
  getLsParams(options) {
    const params = super.getLsParams(options);
    params.ls_provider = "azure";
    return params;
  }
  constructor(deploymentOrFields, fieldsArg) {
    const fields = getAzureChatOpenAIParams(deploymentOrFields, fieldsArg);
    super(fields);
    _constructAzureFields.call(this, fields);
  }
  _getClientOptions(options) {
    return _getAzureClientOptions.call(this, options);
  }
  toJSON() {
    return _serializeAzureChat.call(this, super.toJSON());
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/chat_models/index.js
var ChatOpenAI = class ChatOpenAI2 extends BaseChatOpenAI {
  /**
  * Whether to use the responses API for all requests. If `false` the responses API will be used
  * only when required in order to fulfill the request.
  */
  useResponsesApi = false;
  responses;
  completions;
  get lc_serializable_keys() {
    return [...super.lc_serializable_keys, "useResponsesApi"];
  }
  get callKeys() {
    return [...super.callKeys, "useResponsesApi"];
  }
  fields;
  constructor(modelOrFields, fieldsArg) {
    const fields = getChatOpenAIModelParams(modelOrFields, fieldsArg);
    super(fields);
    this.fields = fields;
    this.useResponsesApi = fields?.useResponsesApi ?? false;
    this.responses = fields?.responses ?? new ChatOpenAIResponses(fields);
    this.completions = fields?.completions ?? new ChatOpenAICompletions(fields);
  }
  _useResponsesApi(options) {
    const usesBuiltInTools = options?.tools?.some(isBuiltInTool);
    const hasResponsesOnlyKwargs = options?.previous_response_id != null || options?.text != null || options?.truncation != null || options?.include != null || options?.reasoning?.summary != null || this.reasoning?.summary != null;
    const hasCustomTools = options?.tools?.some(isOpenAICustomTool) || options?.tools?.some(isCustomTool);
    return this.useResponsesApi || usesBuiltInTools || hasResponsesOnlyKwargs || hasCustomTools || _modelPrefersResponsesAPI(this.model);
  }
  getLsParams(options) {
    const optionsWithDefaults = this._combineCallOptions(options);
    if (this._useResponsesApi(options)) return this.responses.getLsParams(optionsWithDefaults);
    return this.completions.getLsParams(optionsWithDefaults);
  }
  invocationParams(options) {
    const optionsWithDefaults = this._combineCallOptions(options);
    if (this._useResponsesApi(options)) return this.responses.invocationParams(optionsWithDefaults);
    return this.completions.invocationParams(optionsWithDefaults);
  }
  /** @ignore */
  async _generate(messages, options, runManager) {
    if (this._useResponsesApi(options)) return this.responses._generate(messages, options, runManager);
    return this.completions._generate(messages, options, runManager);
  }
  async *_streamResponseChunks(messages, options, runManager) {
    if (this._useResponsesApi(options)) {
      yield* this.responses._streamResponseChunks(messages, this._combineCallOptions(options), runManager);
      return;
    }
    yield* this.completions._streamResponseChunks(messages, this._combineCallOptions(options), runManager);
  }
  withConfig(config2) {
    const newModel = new ChatOpenAI2(this.fields);
    newModel.defaultOptions = {
      ...this.defaultOptions,
      ...config2
    };
    return newModel;
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/azure/chat_models/index.js
var AzureChatOpenAI = class extends ChatOpenAI {
  azureOpenAIApiVersion;
  azureOpenAIApiKey;
  azureADTokenProvider;
  azureOpenAIApiInstanceName;
  azureOpenAIApiDeploymentName;
  azureOpenAIBasePath;
  azureOpenAIEndpoint;
  _llmType() {
    return "azure_openai";
  }
  get lc_aliases() {
    return {
      ...super.lc_aliases,
      ...AZURE_ALIASES
    };
  }
  get lc_secrets() {
    return {
      ...super.lc_secrets,
      ...AZURE_SECRETS
    };
  }
  get lc_serializable_keys() {
    return [...super.lc_serializable_keys, ...AZURE_SERIALIZABLE_KEYS];
  }
  getLsParams(options) {
    const params = super.getLsParams(options);
    params.ls_provider = "azure";
    return params;
  }
  constructor(deploymentOrFields, fieldsArg) {
    const fields = getAzureChatOpenAIParams(deploymentOrFields, fieldsArg);
    super({
      ...fields,
      completions: new AzureChatOpenAICompletions(fields),
      responses: new AzureChatOpenAIResponses(fields)
    });
    _constructAzureFields.call(this, fields);
  }
  /** @internal */
  _getStructuredOutputMethod(config2) {
    const ensuredConfig = { ...config2 };
    if (this.model.startsWith("gpt-4o")) {
      if (ensuredConfig?.method === void 0) return "functionCalling";
    }
    return super._getStructuredOutputMethod(ensuredConfig);
  }
  toJSON() {
    return _serializeAzureChat.call(this, super.toJSON());
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/language_models/llms.js
var llms_exports = __exportAll({
  BaseLLM: () => BaseLLM,
  LLM: () => LLM
});
var BaseLLM = class BaseLLM2 extends BaseLanguageModel {
  lc_namespace = [
    "langchain",
    "llms",
    this._llmType()
  ];
  /**
  * This method takes an input and options, and returns a string. It
  * converts the input to a prompt value and generates a result based on
  * the prompt.
  * @param input Input for the LLM.
  * @param options Options for the LLM call.
  * @returns A string result based on the prompt.
  */
  async invoke(input, options) {
    const promptValue = BaseLLM2._convertInputToPromptValue(input);
    return (await this.generatePrompt([promptValue], options, options?.callbacks)).generations[0][0].text;
  }
  async *_streamResponseChunks(_input, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  async *_streamIterator(input, options) {
    if (this._streamResponseChunks === BaseLLM2.prototype._streamResponseChunks) yield this.invoke(input, options);
    else {
      const prompt = BaseLLM2._convertInputToPromptValue(input);
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this?.invocationParams(callOptions),
        batch_size: 1
      };
      const runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), [prompt.toString()], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName);
      let generation = new GenerationChunk({ text: "" });
      try {
        for await (const chunk of this._streamResponseChunks(prompt.toString(), callOptions, runManagers?.[0])) {
          if (!generation) generation = chunk;
          else generation = generation.concat(chunk);
          if (typeof chunk.text === "string") yield chunk.text;
        }
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));
        throw err;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({ generations: [[generation]] })));
    }
  }
  /**
  * This method takes prompt values, options, and callbacks, and generates
  * a result based on the prompts.
  * @param promptValues Prompt values for the LLM.
  * @param options Options for the LLM call.
  * @param callbacks Callbacks for the LLM call.
  * @returns An LLMResult based on the prompts.
  */
  async generatePrompt(promptValues, options, callbacks) {
    const prompts = promptValues.map((promptValue) => promptValue.toString());
    return this.generate(prompts, options, callbacks);
  }
  /**
  * Get the parameters used to invoke the model
  */
  invocationParams(_options) {
    return {};
  }
  _flattenLLMResult(llmResult) {
    const llmResults = [];
    for (let i = 0; i < llmResult.generations.length; i += 1) {
      const genList = llmResult.generations[i];
      if (i === 0) llmResults.push({
        generations: [genList],
        llmOutput: llmResult.llmOutput
      });
      else {
        const llmOutput = llmResult.llmOutput ? {
          ...llmResult.llmOutput,
          tokenUsage: {}
        } : void 0;
        llmResults.push({
          generations: [genList],
          llmOutput
        });
      }
    }
    return llmResults;
  }
  /** @ignore */
  async _generateUncached(prompts, parsedOptions, handledOptions, startedRunManagers) {
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === prompts.length) runManagers = startedRunManagers;
    else {
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this?.invocationParams(parsedOptions),
        batch_size: prompts.length
      };
      runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), prompts, handledOptions.runId, void 0, extra, void 0, void 0, handledOptions?.runName);
    }
    const hasStreamingHandler = !!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming);
    let output;
    if (hasStreamingHandler && prompts.length === 1 && this._streamResponseChunks !== BaseLLM2.prototype._streamResponseChunks) try {
      const stream = await this._streamResponseChunks(prompts[0], parsedOptions, runManagers?.[0]);
      let aggregated;
      for await (const chunk of stream) if (aggregated === void 0) aggregated = chunk;
      else aggregated = concat(aggregated, chunk);
      if (aggregated === void 0) throw new Error("Received empty response from chat model call.");
      output = {
        generations: [[aggregated]],
        llmOutput: {}
      };
      await runManagers?.[0].handleLLMEnd(output);
    } catch (e) {
      await runManagers?.[0].handleLLMError(e);
      throw e;
    }
    else {
      try {
        output = await this._generate(prompts, parsedOptions, runManagers?.[0]);
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));
        throw err;
      }
      const flattenedOutputs = this._flattenLLMResult(output);
      await Promise.all((runManagers ?? []).map((runManager, i) => runManager?.handleLLMEnd(flattenedOutputs[i])));
    }
    const runIds = runManagers?.map((manager) => manager.runId) || void 0;
    Object.defineProperty(output, RUN_KEY, {
      value: runIds ? { runIds } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ prompts, cache: cache2, llmStringKey, parsedOptions, handledOptions, runId }) {
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this?.invocationParams(parsedOptions),
      batch_size: prompts.length
    };
    const runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), prompts, runId, void 0, extra, void 0, void 0, handledOptions?.runName);
    const missingPromptIndices = [];
    const cachedResults = (await Promise.allSettled(prompts.map(async (prompt, index) => {
      const result = await cache2.lookup(prompt, llmStringKey);
      if (result == null) missingPromptIndices.push(index);
      return result;
    }))).map((result, index) => ({
      result,
      runManager: runManagers?.[index]
    })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i] = result.map((result2) => {
          result2.generationInfo = {
            ...result2.generationInfo,
            tokenUsage: {}
          };
          return result2;
        });
        if (result.length) await runManager?.handleLLMNewToken(result[0].text);
        return runManager?.handleLLMEnd({ generations: [result] }, void 0, void 0, void 0, { cached: true });
      } else {
        await runManager?.handleLLMError(promiseResult.reason, void 0, void 0, void 0, { cached: true });
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
  * Run the LLM on the given prompts and input, handling caching.
  */
  async generate(prompts, options, callbacks) {
    if (!Array.isArray(prompts)) throw new Error("Argument 'prompts' is expected to be a string[]");
    let parsedOptions;
    if (Array.isArray(options)) parsedOptions = { stop: options };
    else parsedOptions = options;
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) return this._generateUncached(prompts, callOptions, runnableConfig);
    const { cache: cache2 } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      prompts,
      cache: cache2,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig,
      runId: runnableConfig.runId
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i) => prompts[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers?.[i]) : void 0);
      await Promise.all(results.generations.map(async (generation, index) => {
        const promptIndex = missingPromptIndices[index];
        generations[promptIndex] = generation;
        return cache2.update(prompts[promptIndex], llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return {
      generations,
      llmOutput
    };
  }
  /**
  * Get the identifying parameters of the LLM.
  */
  _identifyingParams() {
    return {};
  }
  _modelType() {
    return "base_llm";
  }
};
var LLM = class extends BaseLLM {
  async _generate(prompts, options, runManager) {
    return { generations: await Promise.all(prompts.map((prompt, promptIndex) => this._call(prompt, {
      ...options,
      promptIndex
    }, runManager).then((text) => [{ text }]))) };
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/utils/chunk_array.js
var chunk_array_exports = __exportAll({ chunkArray: () => chunkArray });
var chunkArray = (arr, chunkSize) => arr.reduce((chunks, elem, index) => {
  const chunkIndex = Math.floor(index / chunkSize);
  chunks[chunkIndex] = (chunks[chunkIndex] || []).concat([elem]);
  return chunks;
}, []);

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/llms.js
var OpenAI$2 = class extends BaseLLM {
  static lc_name() {
    return "OpenAI";
  }
  get callKeys() {
    return [...super.callKeys, "options"];
  }
  lc_serializable = true;
  get lc_secrets() {
    return {
      openAIApiKey: "OPENAI_API_KEY",
      apiKey: "OPENAI_API_KEY",
      organization: "OPENAI_ORGANIZATION"
    };
  }
  get lc_aliases() {
    return {
      modelName: "model",
      openAIApiKey: "openai_api_key",
      apiKey: "openai_api_key"
    };
  }
  temperature;
  maxTokens;
  topP;
  frequencyPenalty;
  presencePenalty;
  n = 1;
  bestOf;
  logitBias;
  model = "gpt-3.5-turbo-instruct";
  /** @deprecated Use "model" instead */
  modelName;
  modelKwargs;
  batchSize = 20;
  timeout;
  stop;
  stopSequences;
  user;
  streaming = false;
  openAIApiKey;
  apiKey;
  organization;
  client;
  clientConfig;
  constructor(fields) {
    super(fields ?? {});
    this.openAIApiKey = fields?.apiKey ?? fields?.openAIApiKey ?? getEnvironmentVariable("OPENAI_API_KEY");
    this.apiKey = this.openAIApiKey;
    this.organization = fields?.configuration?.organization ?? getEnvironmentVariable("OPENAI_ORGANIZATION");
    this.model = fields?.model ?? fields?.modelName ?? this.model;
    if ((this.model?.startsWith("gpt-3.5-turbo") || this.model?.startsWith("gpt-4") || this.model?.startsWith("o1")) && !this.model?.includes("-instruct")) throw new Error([
      `Your chosen OpenAI model, "${this.model}", is a chat model and not a text-in/text-out LLM.`,
      `Passing it into the "OpenAI" class is no longer supported.`,
      `Please use the "ChatOpenAI" class instead.`,
      "",
      `See this page for more information:`,
      "|",
      `> https://js.langchain.com/docs/integrations/chat/openai`
    ].join("\n"));
    this.modelName = this.model;
    this.modelKwargs = fields?.modelKwargs ?? {};
    this.batchSize = fields?.batchSize ?? this.batchSize;
    this.timeout = fields?.timeout;
    this.temperature = fields?.temperature ?? this.temperature;
    this.maxTokens = fields?.maxTokens ?? this.maxTokens;
    this.topP = fields?.topP ?? this.topP;
    this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;
    this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;
    this.n = fields?.n ?? this.n;
    this.bestOf = fields?.bestOf ?? this.bestOf;
    this.logitBias = fields?.logitBias;
    this.stop = fields?.stopSequences ?? fields?.stop;
    this.stopSequences = this.stop;
    this.user = fields?.user;
    this.streaming = fields?.streaming ?? false;
    if (this.streaming && this.bestOf && this.bestOf > 1) throw new Error("Cannot stream results when bestOf > 1");
    this.clientConfig = {
      apiKey: this.apiKey,
      organization: this.organization,
      dangerouslyAllowBrowser: true,
      ...fields?.configuration
    };
  }
  /**
  * Get the parameters used to invoke the model
  */
  invocationParams(options) {
    return {
      model: this.model,
      temperature: this.temperature,
      max_tokens: this.maxTokens,
      top_p: this.topP,
      frequency_penalty: this.frequencyPenalty,
      presence_penalty: this.presencePenalty,
      n: this.n,
      best_of: this.bestOf,
      logit_bias: this.logitBias,
      stop: options?.stop ?? this.stopSequences,
      user: this.user,
      stream: this.streaming,
      ...this.modelKwargs
    };
  }
  /** @ignore */
  _identifyingParams() {
    return {
      model_name: this.model,
      ...this.invocationParams(),
      ...this.clientConfig
    };
  }
  /**
  * Get the identifying parameters for the model
  */
  identifyingParams() {
    return this._identifyingParams();
  }
  /**
  * Call out to OpenAI's endpoint with k unique prompts
  *
  * @param [prompts] - The prompts to pass into the model.
  * @param [options] - Optional list of stop words to use when generating.
  * @param [runManager] - Optional callback manager to use when generating.
  *
  * @returns The full LLM output.
  *
  * @example
  * ```ts
  * import { OpenAI } from "langchain/llms/openai";
  * const openai = new OpenAI();
  * const response = await openai.generate(["Tell me a joke."]);
  * ```
  */
  async _generate(prompts, options, runManager) {
    const subPrompts = chunkArray(prompts, this.batchSize);
    const choices = [];
    const tokenUsage = {};
    const params = this.invocationParams(options);
    if (params.max_tokens === -1) {
      if (prompts.length !== 1) throw new Error("max_tokens set to -1 not supported for multiple inputs");
      params.max_tokens = await calculateMaxTokens({
        prompt: prompts[0],
        modelName: this.model
      });
    }
    for (let i = 0; i < subPrompts.length; i += 1) {
      const data = params.stream ? await (async () => {
        const choices2 = [];
        let response;
        const stream = await this.completionWithRetry({
          ...params,
          stream: true,
          prompt: subPrompts[i]
        }, options);
        for await (const message of stream) {
          if (!response) response = {
            id: message.id,
            object: message.object,
            created: message.created,
            model: message.model
          };
          for (const part of message.choices) {
            if (!choices2[part.index]) choices2[part.index] = part;
            else {
              const choice = choices2[part.index];
              choice.text += part.text;
              choice.finish_reason = part.finish_reason;
              choice.logprobs = part.logprobs;
            }
            runManager?.handleLLMNewToken(part.text, {
              prompt: Math.floor(part.index / this.n),
              completion: part.index % this.n
            });
          }
        }
        if (options.signal?.aborted) throw new Error("AbortError");
        return {
          ...response,
          choices: choices2
        };
      })() : await this.completionWithRetry({
        ...params,
        stream: false,
        prompt: subPrompts[i]
      }, {
        signal: options.signal,
        ...options.options
      });
      choices.push(...data.choices);
      const { completion_tokens: completionTokens, prompt_tokens: promptTokens, total_tokens: totalTokens } = data.usage ? data.usage : {
        completion_tokens: void 0,
        prompt_tokens: void 0,
        total_tokens: void 0
      };
      if (completionTokens) tokenUsage.completionTokens = (tokenUsage.completionTokens ?? 0) + completionTokens;
      if (promptTokens) tokenUsage.promptTokens = (tokenUsage.promptTokens ?? 0) + promptTokens;
      if (totalTokens) tokenUsage.totalTokens = (tokenUsage.totalTokens ?? 0) + totalTokens;
    }
    return {
      generations: chunkArray(choices, this.n).map((promptChoices) => promptChoices.map((choice) => ({
        text: choice.text ?? "",
        generationInfo: {
          finishReason: choice.finish_reason,
          logprobs: choice.logprobs
        }
      }))),
      llmOutput: { tokenUsage }
    };
  }
  async *_streamResponseChunks(input, options, runManager) {
    const params = {
      ...this.invocationParams(options),
      prompt: input,
      stream: true
    };
    const stream = await this.completionWithRetry(params, options);
    for await (const data of stream) {
      const choice = data?.choices[0];
      if (!choice) continue;
      const chunk = new GenerationChunk({
        text: choice.text,
        generationInfo: { finishReason: choice.finish_reason }
      });
      yield chunk;
      runManager?.handleLLMNewToken(chunk.text ?? "");
    }
    if (options.signal?.aborted) throw new Error("AbortError");
  }
  async completionWithRetry(request, options) {
    const requestOptions = this._getClientOptions(options);
    return this.caller.call(async () => {
      try {
        return await this.client.completions.create(request, requestOptions);
      } catch (e) {
        throw wrapOpenAIClientError(e);
      }
    });
  }
  /**
  * Calls the OpenAI API with retry logic in case of failures.
  * @param request The request to send to the OpenAI API.
  * @param options Optional configuration for the API call.
  * @returns The response from the OpenAI API.
  */
  _getClientOptions(options) {
    if (!this.client) {
      const endpoint = getEndpoint({ baseURL: this.clientConfig.baseURL });
      const params = {
        ...this.clientConfig,
        baseURL: endpoint,
        timeout: this.timeout,
        maxRetries: 0
      };
      if (!params.baseURL) delete params.baseURL;
      params.defaultHeaders = getHeadersWithUserAgent(params.defaultHeaders);
      this.client = new OpenAI(params);
    }
    return {
      ...this.clientConfig,
      ...options
    };
  }
  _llmType() {
    return "openai";
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/azure/llms.js
var AzureOpenAI$1 = class extends OpenAI$2 {
  azureOpenAIApiVersion;
  azureOpenAIApiKey;
  azureADTokenProvider;
  azureOpenAIApiInstanceName;
  azureOpenAIApiDeploymentName;
  azureOpenAIBasePath;
  azureOpenAIEndpoint;
  get lc_aliases() {
    return {
      ...super.lc_aliases,
      openAIApiKey: "openai_api_key",
      openAIApiVersion: "openai_api_version",
      openAIBasePath: "openai_api_base",
      deploymentName: "deployment_name",
      azureOpenAIEndpoint: "azure_endpoint",
      azureOpenAIApiVersion: "openai_api_version",
      azureOpenAIBasePath: "openai_api_base",
      azureOpenAIApiDeploymentName: "deployment_name"
    };
  }
  get lc_secrets() {
    return {
      ...super.lc_secrets,
      azureOpenAIApiKey: "AZURE_OPENAI_API_KEY"
    };
  }
  constructor(fields) {
    super(fields);
    this.azureOpenAIApiDeploymentName = (fields?.azureOpenAIApiCompletionsDeploymentName || fields?.azureOpenAIApiDeploymentName) ?? (getEnvironmentVariable("AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME") || getEnvironmentVariable("AZURE_OPENAI_API_DEPLOYMENT_NAME"));
    this.azureOpenAIApiKey = fields?.azureOpenAIApiKey ?? (typeof fields?.openAIApiKey === "string" ? fields?.openAIApiKey : void 0) ?? (typeof fields?.apiKey === "string" ? fields?.apiKey : void 0) ?? getEnvironmentVariable("AZURE_OPENAI_API_KEY");
    this.azureOpenAIApiInstanceName = fields?.azureOpenAIApiInstanceName ?? getEnvironmentVariable("AZURE_OPENAI_API_INSTANCE_NAME");
    this.azureOpenAIApiVersion = fields?.azureOpenAIApiVersion ?? fields?.openAIApiVersion ?? getEnvironmentVariable("AZURE_OPENAI_API_VERSION");
    this.azureOpenAIBasePath = fields?.azureOpenAIBasePath ?? getEnvironmentVariable("AZURE_OPENAI_BASE_PATH");
    this.azureOpenAIEndpoint = fields?.azureOpenAIEndpoint ?? getEnvironmentVariable("AZURE_OPENAI_ENDPOINT");
    this.azureADTokenProvider = fields?.azureADTokenProvider;
    if (!this.azureOpenAIApiKey && !this.apiKey && !this.azureADTokenProvider) throw new Error("Azure OpenAI API key or Token Provider not found");
  }
  _getClientOptions(options) {
    if (!this.client) {
      const openAIEndpointConfig = {
        azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,
        azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,
        azureOpenAIApiKey: this.azureOpenAIApiKey,
        azureOpenAIBasePath: this.azureOpenAIBasePath,
        azureADTokenProvider: this.azureADTokenProvider,
        baseURL: this.clientConfig.baseURL
      };
      const endpoint = getEndpoint(openAIEndpointConfig);
      const { apiKey: existingApiKey, ...clientConfigRest } = this.clientConfig;
      const params = {
        ...clientConfigRest,
        baseURL: endpoint,
        timeout: this.timeout,
        maxRetries: 0
      };
      if (!this.azureADTokenProvider) params.apiKey = openAIEndpointConfig.azureOpenAIApiKey;
      if (!params.baseURL) delete params.baseURL;
      params.defaultHeaders = getHeadersWithUserAgent(params.defaultHeaders, true, "2.0.0");
      this.client = new AzureOpenAI({
        apiVersion: this.azureOpenAIApiVersion,
        azureADTokenProvider: this.azureADTokenProvider,
        ...params
      });
    }
    const requestOptions = {
      ...this.clientConfig,
      ...options
    };
    if (this.azureOpenAIApiKey) {
      requestOptions.headers = {
        "api-key": this.azureOpenAIApiKey,
        ...requestOptions.headers
      };
      requestOptions.query = {
        "api-version": this.azureOpenAIApiVersion,
        ...requestOptions.query
      };
    }
    return requestOptions;
  }
  toJSON() {
    const json2 = super.toJSON();
    function isRecord(obj) {
      return typeof obj === "object" && obj != null;
    }
    if (isRecord(json2) && isRecord(json2.kwargs)) {
      delete json2.kwargs.azure_openai_base_path;
      delete json2.kwargs.azure_openai_api_deployment_name;
      delete json2.kwargs.azure_openai_api_key;
      delete json2.kwargs.azure_openai_api_version;
      delete json2.kwargs.azure_open_ai_base_path;
    }
    return json2;
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/embeddings.js
var embeddings_exports = __exportAll({ Embeddings: () => Embeddings2 });
var Embeddings2 = class {
  /**
  * The async caller should be used by subclasses to make any async calls,
  * which will thus benefit from the concurrency and retry logic.
  */
  caller;
  constructor(params) {
    this.caller = new AsyncCaller(params ?? {});
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/embeddings.js
var OpenAIEmbeddings = class extends Embeddings2 {
  model = "text-embedding-ada-002";
  /** @deprecated Use "model" instead */
  modelName;
  batchSize = 512;
  stripNewLines = true;
  /**
  * The number of dimensions the resulting output embeddings should have.
  * Only supported in `text-embedding-3` and later models.
  */
  dimensions;
  timeout;
  organization;
  encodingFormat;
  client;
  clientConfig;
  apiKey;
  constructor(fields) {
    const fieldsWithDefaults = {
      maxConcurrency: 2,
      ...fields
    };
    super(fieldsWithDefaults);
    const apiKey = fieldsWithDefaults?.apiKey ?? fieldsWithDefaults?.openAIApiKey ?? getEnvironmentVariable("OPENAI_API_KEY");
    this.organization = fieldsWithDefaults?.configuration?.organization ?? getEnvironmentVariable("OPENAI_ORGANIZATION");
    this.model = fieldsWithDefaults?.model ?? fieldsWithDefaults?.modelName ?? this.model;
    this.modelName = this.model;
    this.batchSize = fieldsWithDefaults?.batchSize ?? this.batchSize;
    this.stripNewLines = fieldsWithDefaults?.stripNewLines ?? this.stripNewLines;
    this.timeout = fieldsWithDefaults?.timeout;
    this.dimensions = fieldsWithDefaults?.dimensions;
    this.encodingFormat = fieldsWithDefaults?.encodingFormat;
    this.clientConfig = {
      apiKey,
      organization: this.organization,
      dangerouslyAllowBrowser: true,
      ...fields?.configuration
    };
  }
  /**
  * Method to generate embeddings for an array of documents. Splits the
  * documents into batches and makes requests to the OpenAI API to generate
  * embeddings.
  * @param texts Array of documents to generate embeddings for.
  * @returns Promise that resolves to a 2D array of embeddings for each document.
  */
  async embedDocuments(texts) {
    const batches = chunkArray(this.stripNewLines ? texts.map((t) => t.replace(/\n/g, " ")) : texts, this.batchSize);
    const batchRequests = batches.map((batch) => {
      const params = {
        model: this.model,
        input: batch
      };
      if (this.dimensions) params.dimensions = this.dimensions;
      if (this.encodingFormat) params.encoding_format = this.encodingFormat;
      return this.embeddingWithRetry(params);
    });
    const batchResponses = await Promise.all(batchRequests);
    const embeddings = [];
    for (let i = 0; i < batchResponses.length; i += 1) {
      const batch = batches[i];
      const { data: batchResponse } = batchResponses[i];
      for (let j = 0; j < batch.length; j += 1) embeddings.push(batchResponse[j].embedding);
    }
    return embeddings;
  }
  /**
  * Method to generate an embedding for a single document. Calls the
  * embeddingWithRetry method with the document as the input.
  * @param text Document to generate an embedding for.
  * @returns Promise that resolves to an embedding for the document.
  */
  async embedQuery(text) {
    const params = {
      model: this.model,
      input: this.stripNewLines ? text.replace(/\n/g, " ") : text
    };
    if (this.dimensions) params.dimensions = this.dimensions;
    if (this.encodingFormat) params.encoding_format = this.encodingFormat;
    const { data } = await this.embeddingWithRetry(params);
    return data[0].embedding;
  }
  /**
  * Private method to make a request to the OpenAI API to generate
  * embeddings. Handles the retry logic and returns the response from the
  * API.
  * @param request Request to send to the OpenAI API.
  * @returns Promise that resolves to the response from the API.
  */
  async embeddingWithRetry(request) {
    if (!this.client) {
      const endpoint = getEndpoint({ baseURL: this.clientConfig.baseURL });
      const params = {
        ...this.clientConfig,
        baseURL: endpoint,
        timeout: this.timeout,
        maxRetries: 0
      };
      if (!params.baseURL) delete params.baseURL;
      params.defaultHeaders = getHeadersWithUserAgent(params.defaultHeaders);
      this.client = new OpenAI(params);
    }
    const requestOptions = {};
    return this.caller.call(async () => {
      try {
        return await this.client.embeddings.create(request, requestOptions);
      } catch (e) {
        throw wrapOpenAIClientError(e);
      }
    });
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/azure/embeddings.js
var AzureOpenAIEmbeddings = class extends OpenAIEmbeddings {
  azureOpenAIApiVersion;
  azureOpenAIApiKey;
  azureADTokenProvider;
  azureOpenAIApiInstanceName;
  azureOpenAIApiDeploymentName;
  azureOpenAIBasePath;
  constructor(fields) {
    super(fields);
    this.batchSize = fields?.batchSize ?? 1;
    this.azureOpenAIApiKey = fields?.azureOpenAIApiKey ?? (typeof fields?.apiKey === "string" ? fields?.apiKey : void 0) ?? getEnvironmentVariable("AZURE_OPENAI_API_KEY");
    this.azureOpenAIApiVersion = fields?.azureOpenAIApiVersion ?? fields?.openAIApiVersion ?? getEnvironmentVariable("AZURE_OPENAI_API_VERSION");
    this.azureOpenAIBasePath = fields?.azureOpenAIBasePath ?? getEnvironmentVariable("AZURE_OPENAI_BASE_PATH");
    this.azureOpenAIApiInstanceName = fields?.azureOpenAIApiInstanceName ?? getEnvironmentVariable("AZURE_OPENAI_API_INSTANCE_NAME");
    this.azureOpenAIApiDeploymentName = (fields?.azureOpenAIApiEmbeddingsDeploymentName || fields?.azureOpenAIApiDeploymentName) ?? (getEnvironmentVariable("AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME") || getEnvironmentVariable("AZURE_OPENAI_API_DEPLOYMENT_NAME"));
    this.azureADTokenProvider = fields?.azureADTokenProvider;
  }
  async embeddingWithRetry(request) {
    if (!this.client) {
      const openAIEndpointConfig = {
        azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,
        azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,
        azureOpenAIApiKey: this.azureOpenAIApiKey,
        azureOpenAIBasePath: this.azureOpenAIBasePath,
        azureADTokenProvider: this.azureADTokenProvider,
        baseURL: this.clientConfig.baseURL
      };
      const endpoint = getEndpoint(openAIEndpointConfig);
      const { apiKey: existingApiKey, ...clientConfigRest } = this.clientConfig;
      const params = {
        ...clientConfigRest,
        baseURL: endpoint,
        timeout: this.timeout,
        maxRetries: 0
      };
      if (!this.azureADTokenProvider) params.apiKey = openAIEndpointConfig.azureOpenAIApiKey;
      if (!params.baseURL) delete params.baseURL;
      params.defaultHeaders = getHeadersWithUserAgent(params.defaultHeaders, true, "2.0.0");
      this.client = new AzureOpenAI({
        apiVersion: this.azureOpenAIApiVersion,
        azureADTokenProvider: this.azureADTokenProvider,
        deployment: this.azureOpenAIApiDeploymentName,
        ...params
      });
    }
    const requestOptions = {};
    if (this.azureOpenAIApiKey) {
      requestOptions.headers = {
        "api-key": this.azureOpenAIApiKey,
        ...requestOptions.headers
      };
      requestOptions.query = {
        "api-version": this.azureOpenAIApiVersion,
        ...requestOptions.query
      };
    }
    return this.caller.call(async () => {
      try {
        return await this.client.embeddings.create(request, requestOptions);
      } catch (e) {
        throw wrapOpenAIClientError(e);
      }
    });
  }
};

// node_modules/.pnpm/@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6_/node_modules/@langchain/core/dist/tools/index.js
var tools_exports = __exportAll({
  BaseToolkit: () => BaseToolkit,
  DynamicStructuredTool: () => DynamicStructuredTool,
  DynamicTool: () => DynamicTool,
  StructuredTool: () => StructuredTool,
  Tool: () => Tool,
  ToolInputParsingException: () => ToolInputParsingException,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams,
  tool: () => tool
});
var StructuredTool = class extends BaseLangChain {
  /**
  * Optional provider-specific extra fields for the tool.
  *
  * This is used to pass provider-specific configuration that doesn't fit into
  * standard tool fields.
  */
  extras;
  /**
  * Whether to return the tool's output directly.
  *
  * Setting this to true means that after the tool is called,
  * an agent should stop looping.
  */
  returnDirect = false;
  verboseParsingErrors = false;
  get lc_namespace() {
    return ["langchain", "tools"];
  }
  /**
  * The tool response format.
  *
  * If "content" then the output of the tool is interpreted as the contents of a
  * ToolMessage. If "content_and_artifact" then the output is expected to be a
  * two-tuple corresponding to the (content, artifact) of a ToolMessage.
  *
  * @default "content"
  */
  responseFormat = "content";
  /**
  * Default config object for the tool runnable.
  */
  defaultConfig;
  constructor(fields) {
    super(fields ?? {});
    this.verboseParsingErrors = fields?.verboseParsingErrors ?? this.verboseParsingErrors;
    this.responseFormat = fields?.responseFormat ?? this.responseFormat;
    this.defaultConfig = fields?.defaultConfig ?? this.defaultConfig;
    this.metadata = fields?.metadata ?? this.metadata;
    this.extras = fields?.extras ?? this.extras;
  }
  /**
  * Invokes the tool with the provided input and configuration.
  * @param input The input for the tool.
  * @param config Optional configuration for the tool.
  * @returns A Promise that resolves with the tool's output.
  */
  async invoke(input, config2) {
    let toolInput;
    let enrichedConfig = ensureConfig(mergeConfigs(this.defaultConfig, config2));
    if (_isToolCall(input)) {
      toolInput = input.args;
      enrichedConfig = {
        ...enrichedConfig,
        toolCall: input
      };
    } else toolInput = input;
    return this.call(toolInput, enrichedConfig);
  }
  /**
  * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
  *
  * Calls the tool with the provided argument, configuration, and tags. It
  * parses the input according to the schema, handles any errors, and
  * manages callbacks.
  * @param arg The input argument for the tool.
  * @param configArg Optional configuration or callbacks for the tool.
  * @param tags Optional tags for the tool.
  * @returns A Promise that resolves with a string.
  */
  async call(arg, configArg, tags) {
    const inputForValidation = _isToolCall(arg) ? arg.args : arg;
    let parsed;
    if (isInteropZodSchema(this.schema)) try {
      parsed = await interopParseAsync(this.schema, inputForValidation);
    } catch (e) {
      let message = `Received tool input did not match expected schema`;
      if (this.verboseParsingErrors) message = `${message}
Details: ${e.message}`;
      if (isInteropZodError(e)) message = `${message}

${external_exports2.prettifyError(e)}`;
      throw new ToolInputParsingException(message, JSON.stringify(arg));
    }
    else {
      const result2 = validate(inputForValidation, this.schema);
      if (!result2.valid) {
        let message = `Received tool input did not match expected schema`;
        if (this.verboseParsingErrors) message = `${message}
Details: ${result2.errors.map((e) => `${e.keywordLocation}: ${e.error}`).join("\n")}`;
        throw new ToolInputParsingException(message, JSON.stringify(arg));
      }
      parsed = inputForValidation;
    }
    const config2 = parseCallbackConfigArg(configArg);
    const callbackManager_ = CallbackManager.configure(config2.callbacks, this.callbacks, config2.tags || tags, this.tags, config2.metadata, this.metadata, { verbose: this.verbose });
    let toolCallId;
    if (_isToolCall(arg)) toolCallId = arg.id;
    if (!toolCallId && _configHasToolCallId(config2)) toolCallId = config2.toolCall.id;
    const runManager = await callbackManager_?.handleToolStart(this.toJSON(), typeof arg === "string" ? arg : JSON.stringify(arg), config2.runId, void 0, void 0, void 0, config2.runName, toolCallId);
    delete config2.runId;
    let result;
    try {
      const raw = await this._call(parsed, runManager, config2);
      result = isAsyncGenerator(raw) ? await consumeAsyncGenerator(raw, async (chunk) => {
        try {
          await runManager?.handleToolEvent(chunk);
        } catch (streamError) {
          await runManager?.handleToolError(streamError);
        }
      }) : raw;
    } catch (e) {
      await runManager?.handleToolError(e);
      throw e;
    }
    let content;
    let artifact;
    if (this.responseFormat === "content_and_artifact") if (Array.isArray(result) && result.length === 2) [content, artifact] = result;
    else throw new Error(`Tool response format is "content_and_artifact" but the output was not a two-tuple.
Result: ${JSON.stringify(result)}`);
    else content = result;
    const formattedOutput = _formatToolOutput({
      content,
      artifact,
      toolCallId,
      name: this.name,
      metadata: this.metadata
    });
    await runManager?.handleToolEnd(formattedOutput);
    return formattedOutput;
  }
};
var Tool = class extends StructuredTool {
  schema = external_exports.object({ input: external_exports.string().optional() }).transform((obj) => obj.input);
  constructor(fields) {
    super(fields);
  }
  /**
  * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
  *
  * Calls the tool with the provided argument and callbacks. It handles
  * string inputs specifically.
  * @param arg The input argument for the tool, which can be a string, undefined, or an input of the tool's schema.
  * @param callbacks Optional callbacks for the tool.
  * @returns A Promise that resolves with a string.
  */
  call(arg, callbacks) {
    const structuredArg = typeof arg === "string" || arg == null ? { input: arg } : arg;
    return super.call(structuredArg, callbacks);
  }
};
var DynamicTool = class extends Tool {
  static lc_name() {
    return "DynamicTool";
  }
  name;
  description;
  func;
  constructor(fields) {
    super(fields);
    this.name = fields.name;
    this.description = fields.description;
    this.func = fields.func;
    this.returnDirect = fields.returnDirect ?? this.returnDirect;
  }
  /**
  * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
  */
  async call(arg, configArg) {
    const config2 = parseCallbackConfigArg(configArg);
    if (config2.runName === void 0) config2.runName = this.name;
    return super.call(arg, config2);
  }
  /** @ignore */
  _call(input, runManager, parentConfig) {
    return this.func(input, runManager, parentConfig);
  }
};
var DynamicStructuredTool = class extends StructuredTool {
  static lc_name() {
    return "DynamicStructuredTool";
  }
  description;
  func;
  schema;
  constructor(fields) {
    super(fields);
    this.name = fields.name;
    this.description = fields.description;
    this.func = fields.func;
    this.returnDirect = fields.returnDirect ?? this.returnDirect;
    this.schema = fields.schema;
  }
  /**
  * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
  */
  async call(arg, configArg, tags) {
    const config2 = parseCallbackConfigArg(configArg);
    if (config2.runName === void 0) config2.runName = this.name;
    return super.call(arg, config2, tags);
  }
  _call(arg, runManager, parentConfig) {
    return this.func(arg, runManager, parentConfig);
  }
};
var BaseToolkit = class {
  getTools() {
    return this.tools;
  }
};
function tool(func, fields) {
  const isSimpleStringSchema = isSimpleStringZodSchema(fields.schema);
  const isStringJSONSchema = validatesOnlyStrings(fields.schema);
  if (!fields.schema || isSimpleStringSchema || isStringJSONSchema) return new DynamicTool({
    ...fields,
    description: fields.description ?? fields.schema?.description ?? `${fields.name} tool`,
    func: async (input, runManager, config2) => {
      return new Promise((resolve, reject) => {
        const childConfig = patchConfig(config2, { callbacks: runManager?.getChild() });
        AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
          try {
            resolve(func(input, childConfig));
          } catch (e) {
            reject(e);
          }
        });
      });
    }
  });
  const schema = fields.schema;
  const description = fields.description ?? fields.schema.description ?? `${fields.name} tool`;
  return new DynamicStructuredTool({
    ...fields,
    description,
    schema,
    func: async (input, runManager, config2) => {
      return new Promise((resolve, reject) => {
        let listener;
        const cleanup = () => {
          if (config2?.signal && listener) config2.signal.removeEventListener("abort", listener);
        };
        if (config2?.signal) {
          listener = () => {
            cleanup();
            reject(getAbortSignalError(config2.signal));
          };
          config2.signal.addEventListener("abort", listener, { once: true });
        }
        const childConfig = patchConfig(config2, { callbacks: runManager?.getChild() });
        AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
          try {
            const result = await func(input, childConfig);
            if (config2?.signal?.aborted) {
              cleanup();
              return;
            }
            cleanup();
            resolve(result);
          } catch (e) {
            cleanup();
            reject(e);
          }
        });
      });
    }
  });
}
function _formatToolOutput(params) {
  const { content, artifact, toolCallId, metadata } = params;
  if (toolCallId && !isDirectToolOutput(content)) if (typeof content === "string" || Array.isArray(content) && content.every((item) => typeof item === "object")) return new ToolMessage({
    status: "success",
    content,
    artifact,
    tool_call_id: toolCallId,
    name: params.name,
    metadata
  });
  else return new ToolMessage({
    status: "success",
    content: _stringify(content),
    artifact,
    tool_call_id: toolCallId,
    name: params.name,
    metadata
  });
  else return content;
}
function _stringify(content) {
  try {
    return JSON.stringify(content) ?? "";
  } catch (_noOp) {
    return `${content}`;
  }
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/dalle.js
var DallEAPIWrapper = class extends Tool {
  static lc_name() {
    return "DallEAPIWrapper";
  }
  name = "dalle_api_wrapper";
  description = "A wrapper around OpenAI DALL-E API. Useful for when you need to generate images from a text description. Input should be an image description.";
  client;
  static toolName = "dalle_api_wrapper";
  model = "dall-e-3";
  style = "vivid";
  quality = "standard";
  n = 1;
  size = "1024x1024";
  dallEResponseFormat = "url";
  user;
  constructor(fields) {
    if (fields?.responseFormat !== void 0 && ["url", "b64_json"].includes(fields.responseFormat)) {
      fields.dallEResponseFormat = fields.responseFormat;
      fields.responseFormat = "content";
    }
    super(fields);
    this.client = new OpenAI({
      apiKey: fields?.apiKey ?? fields?.openAIApiKey ?? getEnvironmentVariable("OPENAI_API_KEY"),
      organization: fields?.organization ?? getEnvironmentVariable("OPENAI_ORGANIZATION"),
      dangerouslyAllowBrowser: true,
      baseURL: fields?.baseUrl
    });
    this.model = fields?.model ?? fields?.modelName ?? this.model;
    this.style = fields?.style ?? this.style;
    this.quality = fields?.quality ?? this.quality;
    this.n = fields?.n ?? this.n;
    this.size = fields?.size ?? this.size;
    this.dallEResponseFormat = fields?.dallEResponseFormat ?? this.dallEResponseFormat;
    this.user = fields?.user;
  }
  /**
  * Processes the API response if multiple images are generated.
  * Returns a list of MessageContentImageUrl objects. If the response
  * format is `url`, then the `image_url` field will contain the URL.
  * If it is `b64_json`, then the `image_url` field will contain an object
  * with a `url` field with the base64 encoded image.
  *
  * @param {OpenAIClient.Images.ImagesResponse[]} response The API response
  * @returns {MessageContentImageUrl[]}
  */
  processMultipleGeneratedUrls(response) {
    if (this.dallEResponseFormat === "url") return response.flatMap((res) => {
      return res.data?.flatMap((item) => {
        if (!item.url) return [];
        return {
          type: "image_url",
          image_url: item.url
        };
      }).filter((item) => item !== void 0 && item.type === "image_url" && typeof item.image_url === "string" && item.image_url !== void 0) ?? [];
    });
    else return response.flatMap((res) => {
      return res.data?.flatMap((item) => {
        if (!item.b64_json) return [];
        return {
          type: "image_url",
          image_url: { url: item.b64_json }
        };
      }).filter((item) => item !== void 0 && item.type === "image_url" && typeof item.image_url === "object" && "url" in item.image_url && typeof item.image_url.url === "string" && item.image_url.url !== void 0) ?? [];
    });
  }
  /** @ignore */
  async _call(input) {
    const generateImageFields = {
      model: this.model,
      prompt: input,
      n: 1,
      size: this.size,
      response_format: this.dallEResponseFormat,
      style: this.style,
      quality: this.quality,
      user: this.user
    };
    if (this.n > 1) {
      const results = await Promise.all(Array.from({ length: this.n }).map(() => this.client.images.generate(generateImageFields)));
      return this.processMultipleGeneratedUrls(results);
    }
    const response = await this.client.images.generate(generateImageFields);
    let data = "";
    if (this.dallEResponseFormat === "url") [data] = response.data?.map((item) => item.url).filter((url2) => url2 !== "undefined") ?? [];
    else [data] = response.data?.map((item) => item.b64_json).filter((b64_json) => b64_json !== "undefined") ?? [];
    return data;
  }
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/webSearch.js
function webSearch(options) {
  return {
    type: "web_search",
    filters: options?.filters?.allowedDomains ? { allowed_domains: options.filters.allowedDomains } : void 0,
    user_location: options?.userLocation,
    search_context_size: options?.search_context_size
  };
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/mcp.js
function convertToolFilter(filter) {
  return {
    tool_names: filter.toolNames,
    read_only: filter.readOnly
  };
}
function convertAllowedTools(allowedTools) {
  if (!allowedTools) return void 0;
  if (Array.isArray(allowedTools)) return allowedTools;
  return convertToolFilter(allowedTools);
}
function convertRequireApproval(requireApproval) {
  if (!requireApproval) return void 0;
  if (typeof requireApproval === "string") return requireApproval;
  return {
    always: requireApproval.always ? convertToolFilter(requireApproval.always) : void 0,
    never: requireApproval.never ? convertToolFilter(requireApproval.never) : void 0
  };
}
function mcp(options) {
  const baseConfig = {
    type: "mcp",
    server_label: options.serverLabel,
    allowed_tools: convertAllowedTools(options.allowedTools),
    authorization: options.authorization,
    headers: options.headers,
    require_approval: convertRequireApproval(options.requireApproval),
    server_description: options.serverDescription
  };
  if ("serverUrl" in options) return {
    ...baseConfig,
    server_url: options.serverUrl
  };
  return {
    ...baseConfig,
    connector_id: options.connectorId
  };
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/codeInterpreter.js
function convertContainer(container) {
  if (typeof container === "string") return container;
  return {
    type: "auto",
    file_ids: container?.fileIds,
    memory_limit: container?.memoryLimit
  };
}
function codeInterpreter(options) {
  return {
    type: "code_interpreter",
    container: convertContainer(options?.container)
  };
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/fileSearch.js
function convertRankingOptions(options) {
  if (!options) return void 0;
  return {
    ranker: options.ranker,
    score_threshold: options.scoreThreshold,
    hybrid_search: options.hybridSearch ? {
      embedding_weight: options.hybridSearch.embeddingWeight,
      text_weight: options.hybridSearch.textWeight
    } : void 0
  };
}
function fileSearch(options) {
  return {
    type: "file_search",
    vector_store_ids: options.vectorStoreIds,
    max_num_results: options.maxNumResults,
    filters: options.filters,
    ranking_options: convertRankingOptions(options.rankingOptions)
  };
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/imageGeneration.js
function convertInputImageMask(mask) {
  if (!mask) return void 0;
  return {
    image_url: mask.imageUrl,
    file_id: mask.fileId
  };
}
function imageGeneration(options) {
  return {
    type: "image_generation",
    action: options?.action,
    background: options?.background,
    input_fidelity: options?.inputFidelity,
    input_image_mask: convertInputImageMask(options?.inputImageMask),
    model: options?.model,
    moderation: options?.moderation,
    output_compression: options?.outputCompression,
    output_format: options?.outputFormat,
    partial_images: options?.partialImages,
    quality: options?.quality,
    size: options?.size
  };
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/computerUse.js
var ComputerUseScreenshotActionSchema = external_exports2.object({ type: external_exports2.literal("screenshot") });
var ComputerUseClickActionSchema = external_exports2.object({
  type: external_exports2.literal("click"),
  x: external_exports2.number(),
  y: external_exports2.number(),
  button: external_exports2.enum([
    "left",
    "right",
    "wheel",
    "back",
    "forward"
  ]).default("left")
});
var ComputerUseDoubleClickActionSchema = external_exports2.object({
  type: external_exports2.literal("double_click"),
  x: external_exports2.number(),
  y: external_exports2.number(),
  button: external_exports2.enum([
    "left",
    "right",
    "wheel",
    "back",
    "forward"
  ]).default("left")
});
var ComputerUseDragActionSchema = external_exports2.object({
  type: external_exports2.literal("drag"),
  path: external_exports2.array(external_exports2.object({
    x: external_exports2.number(),
    y: external_exports2.number()
  }))
});
var ComputerUseKeypressActionSchema = external_exports2.object({
  type: external_exports2.literal("keypress"),
  keys: external_exports2.array(external_exports2.string())
});
var ComputerUseMoveActionSchema = external_exports2.object({
  type: external_exports2.literal("move"),
  x: external_exports2.number(),
  y: external_exports2.number()
});
var ComputerUseScrollActionSchema = external_exports2.object({
  type: external_exports2.literal("scroll"),
  x: external_exports2.number(),
  y: external_exports2.number(),
  scroll_x: external_exports2.number(),
  scroll_y: external_exports2.number()
});
var ComputerUseTypeActionSchema = external_exports2.object({
  type: external_exports2.literal("type"),
  text: external_exports2.string()
});
var ComputerUseWaitActionSchema = external_exports2.object({
  type: external_exports2.literal("wait"),
  duration: external_exports2.number().optional()
});
var ComputerUseActionUnionSchema = external_exports2.union([
  ComputerUseScreenshotActionSchema,
  ComputerUseClickActionSchema,
  ComputerUseDoubleClickActionSchema,
  ComputerUseDragActionSchema,
  ComputerUseKeypressActionSchema,
  ComputerUseMoveActionSchema,
  ComputerUseScrollActionSchema,
  ComputerUseTypeActionSchema,
  ComputerUseWaitActionSchema
]);
var ComputerUseActionSchema = external_exports2.object({ action: ComputerUseActionUnionSchema });
var TOOL_NAME = "computer_use";
function computerUse(options) {
  const computerTool = tool(async (input, runtime) => {
    const computerToolCallId = runtime.state?.messages.at(-1)?.tool_calls?.find((tc) => tc.name === "computer_use")?.id;
    if (!computerToolCallId) throw new Error("Computer use call id not found");
    const result = await options.execute(input.action, runtime);
    if (typeof result === "string") return new ToolMessage({
      content: result,
      tool_call_id: computerToolCallId,
      additional_kwargs: { type: "computer_call_output" }
    });
    return new ToolMessage({
      ...result,
      tool_call_id: computerToolCallId,
      additional_kwargs: {
        type: "computer_call_output",
        ...result.additional_kwargs
      }
    });
  }, {
    name: TOOL_NAME,
    description: "Control a computer interface by executing mouse clicks, keyboard input, scrolling, and other actions.",
    schema: ComputerUseActionSchema
  });
  computerTool.extras = {
    ...computerTool.extras ?? {},
    providerToolDefinition: {
      type: "computer_use_preview",
      display_width: options.displayWidth,
      display_height: options.displayHeight,
      environment: options.environment
    }
  };
  return computerTool;
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/localShell.js
var LocalShellExecActionSchema = external_exports2.object({
  type: external_exports2.literal("exec"),
  command: external_exports2.array(external_exports2.string()),
  env: external_exports2.record(external_exports2.string(), external_exports2.string()).optional(),
  working_directory: external_exports2.string().optional(),
  timeout_ms: external_exports2.number().optional(),
  user: external_exports2.string().optional()
});
var LocalShellActionSchema = external_exports2.union([LocalShellExecActionSchema]);
var TOOL_NAME2 = "local_shell";
function localShell(options) {
  const shellTool = tool(options.execute, {
    name: TOOL_NAME2,
    description: "Execute shell commands locally on the machine. Commands are provided as argv tokens.",
    schema: LocalShellActionSchema
  });
  shellTool.extras = {
    ...shellTool.extras ?? {},
    providerToolDefinition: { type: "local_shell" }
  };
  return shellTool;
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/shell.js
var ShellActionSchema = external_exports2.object({
  commands: external_exports2.array(external_exports2.string()).describe("Array of shell commands to execute"),
  timeout_ms: external_exports2.number().optional().describe("Optional timeout in milliseconds for the commands"),
  max_output_length: external_exports2.number().optional().describe("Optional maximum number of characters to return from each command")
});
var TOOL_NAME3 = "shell";
function shell(options) {
  const executeWrapper = async (action) => {
    const result = await options.execute(action);
    return JSON.stringify({
      output: result.output,
      max_output_length: result.maxOutputLength
    });
  };
  const shellTool = tool(executeWrapper, {
    name: TOOL_NAME3,
    description: "Execute shell commands in a managed environment. Commands can be run concurrently.",
    schema: ShellActionSchema
  });
  shellTool.extras = {
    ...shellTool.extras ?? {},
    providerToolDefinition: { type: "shell" }
  };
  return shellTool;
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/applyPatch.js
var ApplyPatchCreateFileOperationSchema = external_exports2.object({
  type: external_exports2.literal("create_file"),
  path: external_exports2.string(),
  diff: external_exports2.string()
});
var ApplyPatchUpdateFileOperationSchema = external_exports2.object({
  type: external_exports2.literal("update_file"),
  path: external_exports2.string(),
  diff: external_exports2.string()
});
var ApplyPatchDeleteFileOperationSchema = external_exports2.object({
  type: external_exports2.literal("delete_file"),
  path: external_exports2.string()
});
var ApplyPatchOperationSchema = external_exports2.union([
  ApplyPatchCreateFileOperationSchema,
  ApplyPatchUpdateFileOperationSchema,
  ApplyPatchDeleteFileOperationSchema
]);
var TOOL_NAME4 = "apply_patch";
function applyPatch2(options) {
  const patchTool = tool(options.execute, {
    name: TOOL_NAME4,
    description: "Apply structured diffs to create, update, or delete files in the codebase.",
    schema: ApplyPatchOperationSchema
  });
  patchTool.extras = {
    ...patchTool.extras ?? {},
    providerToolDefinition: { type: "apply_patch" }
  };
  return patchTool;
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/index.js
var tools = {
  webSearch,
  mcp,
  codeInterpreter,
  fileSearch,
  imageGeneration,
  computerUse,
  localShell,
  shell,
  applyPatch: applyPatch2
};

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/tools/custom.js
function customTool(func, fields) {
  return new DynamicTool({
    ...fields,
    description: "",
    metadata: { customTool: fields },
    func: async (input, runManager, config2) => new Promise((resolve, reject) => {
      const childConfig = patchConfig(config2, { callbacks: runManager?.getChild() });
      AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
        try {
          resolve(func(input, childConfig));
        } catch (e) {
          reject(e);
        }
      });
    })
  });
}

// node_modules/.pnpm/@langchain+openai@1.2.10_@langchain+core@1.1.28_openai@6.25.0_ws@8.19.0_zod@4.3.6___ws@8.19.0/node_modules/@langchain/openai/dist/utils/prompts.js
function convertPromptToOpenAI(formattedPrompt) {
  return { messages: convertMessagesToCompletionsMessageParams({ messages: formattedPrompt.toChatMessages() }) };
}
export {
  AzureChatOpenAI,
  AzureChatOpenAICompletions,
  AzureChatOpenAIResponses,
  AzureOpenAI$1 as AzureOpenAI,
  AzureOpenAIEmbeddings,
  BaseChatOpenAI,
  ChatOpenAI,
  ChatOpenAICompletions,
  ChatOpenAIResponses,
  DallEAPIWrapper,
  OpenAI$2 as OpenAI,
  OpenAI as OpenAIClient,
  OpenAIEmbeddings,
  completionsApiContentBlockConverter,
  convertCompletionsDeltaToBaseMessageChunk,
  convertCompletionsMessageToBaseMessage,
  convertMessagesToCompletionsMessageParams,
  convertMessagesToResponsesInput,
  convertPromptToOpenAI,
  convertReasoningSummaryToResponsesReasoningItem,
  convertResponsesDeltaToChatGenerationChunk,
  convertResponsesMessageToAIMessage,
  convertResponsesUsageToUsageMetadata,
  convertStandardContentBlockToCompletionsContentPart,
  convertStandardContentMessageToCompletionsMessage,
  convertStandardContentMessageToResponsesInput,
  customTool,
  getEndpoint,
  getFormattedEnv,
  getHeadersWithUserAgent,
  isHeaders,
  messageToOpenAIRole,
  normalizeHeaders,
  toFile,
  tools,
  wrapOpenAIClientError
};
//# sourceMappingURL=@langchain_openai.js.map
